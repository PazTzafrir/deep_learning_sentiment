{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f030776-9d62-4763-986b-e33ea203c71f",
   "metadata": {},
   "source": [
    "# BERT - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717afa7-9892-40c7-9897-e353a52bc9a5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a207c87d-2e15-4358-afe8-85747ab64c37",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52983362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52983362",
    "outputId": "650c1535-cba2-42b9-908b-42e369716b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q optuna\n",
    "!pip install -q evaluate\n",
    "!pip install -q emoji==0.6.0\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8caf727",
   "metadata": {
    "id": "d8caf727"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import *\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_scheduler\n",
    "\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5a77b-70fe-4646-ac46-56c781920053",
   "metadata": {},
   "source": [
    "### Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296be31e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "296be31e",
    "outputId": "f7074c88-2051-4506-df6c-b92377e925d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244d7e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5244d7e5",
    "outputId": "0097279c-ae78-46d0-b390-48b5fc39033d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmayachn3\u001b[0m (\u001b[33mmayachn3-maya-bondar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Weights & Biases Setup\n",
    "\n",
    "wandb.login(key=\"<wandb key>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c6cdd5",
   "metadata": {
    "id": "b6c6cdd5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b06ab-f85b-4354-a574-dacfb125c1ea",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a0a73c",
   "metadata": {
    "id": "d3a0a73c"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"OOT_train.csv\", encoding='latin-1')\n",
    "val = pd.read_csv(\"OOT_val.csv\", encoding='latin-1')\n",
    "test = pd.read_csv(\"OOT_test.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cadc1a",
   "metadata": {
    "id": "38cadc1a"
   },
   "outputs": [],
   "source": [
    "# train = train.head(100)\n",
    "# val = val.head(100)\n",
    "# test = test.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687deaa",
   "metadata": {
    "id": "4687deaa"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9966ecc5",
   "metadata": {
    "id": "9966ecc5"
   },
   "outputs": [],
   "source": [
    "#encoding the labels numerically from Sentiment\n",
    "ordinal_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "# map to ordinal labels\n",
    "train[\"label_id\"] = train[\"Sentiment\"].map(ordinal_mapping)\n",
    "val[\"label_id\"] = val[\"Sentiment\"].map(ordinal_mapping)\n",
    "test[\"label_id\"] = test[\"Sentiment\"].map(ordinal_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b78e181",
   "metadata": {
    "id": "2b78e181"
   },
   "outputs": [],
   "source": [
    "# Concat the relevant columns into one string with seperation.\n",
    "# for example: \"Tweet: my food stock is low | Location: Canada | Date: 2020-03-17 | URL: https://t.co/abcd\"\n",
    "\n",
    "# Function to build the input string from multiple columns\n",
    "def build_augmented_input(row):\n",
    "    parts = []\n",
    "\n",
    "    if pd.notna(row.get('clean_tweet')):\n",
    "        parts.append(f\"{row['clean_tweet']}\")\n",
    "\n",
    "    if pd.notna(row.get('Location_standardized')) and row['Location_standardized'].lower() != 'unknown':\n",
    "        parts.append(f\"{row['Location_standardized']}\")\n",
    "\n",
    "    if pd.notna(row.get('TweetAt')):\n",
    "        parts.append(f\"{row['TweetAt']}\")\n",
    "\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# Apply to the DataFrames\n",
    "train['model_input'] = train.apply(build_augmented_input, axis=1)\n",
    "val['model_input'] = val.apply(build_augmented_input, axis=1)\n",
    "test['model_input'] = test.apply(build_augmented_input, axis=1)\n",
    "\n",
    "# Create new DataFrames with only what's needed for modeling\n",
    "formatted_train = train[['model_input', 'label_id']].copy()\n",
    "formatted_val = val[['model_input', 'label_id']].copy()\n",
    "formatted_test = test[['model_input', 'label_id']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ad0dc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1ad0dc3",
    "outputId": "fbe7d5fb-a738-44f5-c1f1-3acacd5ab7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "label_id\n",
      "0     5175\n",
      "1     9230\n",
      "2     6784\n",
      "3    10140\n",
      "4     5845\n",
      "Name: count, dtype: int64\n",
      "Class 0: 5000 samples (undersampled)\n",
      "Class 1: 5000 samples (undersampled)\n",
      "Class 2: 5000 samples (undersampled)\n",
      "Class 3: 5000 samples (undersampled)\n",
      "Class 4: 5000 samples (undersampled)\n",
      "Balanced dataset: 25000 total samples\n",
      "New distribution:\n",
      "label_id\n",
      "0    5000\n",
      "1    5000\n",
      "2    5000\n",
      "3    5000\n",
      "4    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(df, target_samples_per_class=5000):\n",
    "    \"\"\"Balance dataset by undersampling\"\"\"\n",
    "    balanced_dfs = []\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    print(df['label_id'].value_counts().sort_index())\n",
    "\n",
    "    for class_id in range(5):\n",
    "        class_data = df[df['label_id'] == class_id]\n",
    "\n",
    "        if len(class_data) > target_samples_per_class:\n",
    "            class_data = class_data.sample(n=target_samples_per_class, random_state=42)\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (undersampled)\")\n",
    "        else:\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (kept all)\")\n",
    "\n",
    "        balanced_dfs.append(class_data)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "    print(f\"Balanced dataset: {len(balanced_df)} total samples\")\n",
    "    print(\"New distribution:\")\n",
    "    print(balanced_df['label_id'].value_counts().sort_index())\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing to training data\n",
    "formatted_train = balance_dataset(formatted_train, target_samples_per_class=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13dad1",
   "metadata": {
    "id": "6c13dad1"
   },
   "source": [
    "## Tokenization and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3b916d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279,
     "referenced_widgets": [
      "9ab0859342134e9790f3a25298d410dc",
      "0d123104f1c94fc7aeca0379bd4cf89f",
      "9e50434ecc9c40938281391881e811dc",
      "a85c8479c5ef4ea89bf9c232ff866aad",
      "53ff43592b8e4dda8f5f615db5583a6c",
      "498e7f4dbd8f4d2c8a0f75d57ef23fc6",
      "e7bb540823674f6a8d4c1493e22b31b8",
      "13feaf9ad6724ea188a1ba405e08392d",
      "24111e81d7884d1fba4ad2db372cc50f",
      "3265bfa4994747d0a0bcbba7124fc760",
      "8df85062cabb4049b6747ef23ad3698c",
      "8da16dd4572d4236824cfa2a5b2310cc",
      "560897643dbd464bb29cffcc2af894b5",
      "b2246c43b2454d7ba9975af4d375ed93",
      "57994cfce6ce41e7bdb80ab12f62828e",
      "006900248ab044bb94aedfa8a64b2d7a",
      "2dbe7d6f29f44265920ae349e6799e63",
      "915e2981f56a4fbba9de15fb714ae145",
      "906ed3473d534f95af0ca0a59a0116fc",
      "7d78543c851c4a76a3c167b4ea2794c9",
      "5d943ba338a446ef81e1ac65339f92e0",
      "cbad80f213a5437c884eb1d7a6ffe1b6",
      "9b807e5466604d858e7c3471bc78c640",
      "72a724691df4442c947c5e02151d5e05",
      "55c28984848741ddb4ae005c278c491e",
      "42bf7fe8ab0849069990771c1635842a",
      "f64080fc8e5f4da99590da1a63d2e8f1",
      "6e9ee454831f4a0b8a64b1c8111c0e28",
      "e10a812f7be542ca8f1a7f8fc5b80d10",
      "0370530f965b436c8653e8ac911fbbfc",
      "095cba7d8b754a2abc9be0a0e5598f93",
      "305f91a1665d43b4988c73e034a93bc5",
      "be536f4ec2b147d4b7fdc33fb20a1eaa",
      "89b03e781b6d4dd68c40fb895a0c2e09",
      "845de3a718484277a8f4619b0e94448b",
      "eed1e9ab6356430993407915403cef6b",
      "7d50020689b94a0fb1180d7f7d7741cd",
      "98fbe14bbc144c66bba463ef15352628",
      "9f5f09dcd01d4d9bad9f673b8c18d4f0",
      "1d79fc89547f4bc08c4ce2a4e6ace4e1",
      "714ba282fe51486aa60d2442f6ce4c6d",
      "8027714395d84a00b278b3c2f533d10a",
      "2af65b536632441080017da7137d8a52",
      "d9ef9051b4fb4395b76b9a01b8ea2153",
      "3ac2eb670ad7463f9487748fc7b1c0dc",
      "c4895799049d49cea9d4bd98c3211ce3",
      "50d4d2004a7843c0a2161369f830df60",
      "9b05323233b440618348691aab0f2082",
      "829d16b388a4493d95a7657e273da264",
      "e92f2da1db7847628561da9f63a27307",
      "c837e987955a436e8e889c87f277c281",
      "fa21ad2599f8442fb9a655077c16bd58",
      "4a35771d315c46da9ee6552e4e48b7b8",
      "356a4342c81743399fb66600b064cb99",
      "692271fe5a804d589ef167c9884f31f9"
     ]
    },
    "id": "cc3b916d",
    "outputId": "fec012d2-2bfb-4361-ba85-fc7f14f23972"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab0859342134e9790f3a25298d410dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da16dd4572d4236824cfa2a5b2310cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b807e5466604d858e7c3471bc78c640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b03e781b6d4dd68c40fb895a0c2e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac2eb670ad7463f9487748fc7b1c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_data(data, max_length=128):\n",
    "    return tokenizer(\n",
    "        data['model_input'].tolist(),\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_data(formatted_train)\n",
    "val_encodings = tokenize_data(formatted_val)\n",
    "test_encodings = tokenize_data(formatted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576ecae",
   "metadata": {
    "id": "0576ecae"
   },
   "outputs": [],
   "source": [
    "## define a PyTorch Dataset\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])  # For training\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Convert labels to integers if not already\n",
    "train_labels = formatted_train['label_id'].tolist()\n",
    "val_labels = formatted_val['label_id'].tolist()\n",
    "test_labels = formatted_test['label_id'].tolist()\n",
    "\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3460f26b",
   "metadata": {
    "id": "3460f26b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define mapping between label id and sentiment for later use and conveniency\n",
    "ordinal_label2id = ordinal_mapping\n",
    "ordinal_id2label = {v: k for k, v in ordinal_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef394b35",
   "metadata": {
    "id": "ef394b35"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "xs3PTvj6lvs_",
   "metadata": {
    "id": "xs3PTvj6lvs_"
   },
   "outputs": [],
   "source": [
    "def save_training_checkpoint(model, optimizer, scheduler, epoch, loss, trial_params, filepath, trial_number, current_score, best_score, model_name=\"finiteautomata/bertweet-base-sentiment-analysis\"):\n",
    "    \"\"\"Save complete training checkpoint and handle best model updates\"\"\"\n",
    "    global global_best_qwk, global_best_model_state\n",
    "\n",
    "    # Get the trial directory from filepath\n",
    "    trial_dir = os.path.dirname(filepath)\n",
    "\n",
    "    # Save trial checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'loss': loss,\n",
    "        'trial_params': trial_params,\n",
    "        'model_config': model.config.to_dict(),\n",
    "        'model_name': model_name,\n",
    "        'current_score': current_score,\n",
    "        'trial_number': trial_number,\n",
    "    }\n",
    "\n",
    "    # Save all trial files in the same directory\n",
    "    torch.save(checkpoint, filepath)\n",
    "    torch.save(model.state_dict(), os.path.join(trial_dir, 'model_bert_weights.pt'))\n",
    "    torch.save(model, os.path.join(trial_dir, 'model_bert.pt'))\n",
    "\n",
    "    print(f\"✅ Trial checkpoint saved: {filepath}\")\n",
    "    print(f\"✅ Model files saved in: {trial_dir}\")\n",
    "\n",
    "    # Update best model if needed\n",
    "    if current_score > best_score:\n",
    "        best_model_path = \"./best_bert_model_so_far\"\n",
    "\n",
    "        # Ensure best model directory exists\n",
    "        os.makedirs(best_model_path, exist_ok=True)\n",
    "\n",
    "        # Save our custom .pt files in best model directory\n",
    "        best_checkpoint_path = os.path.join(best_model_path, 'best_checkpoint.ckpt')\n",
    "        best_weights_path = os.path.join(best_model_path, 'model_bert_weights.pt')\n",
    "        best_model_file_path = os.path.join(best_model_path, 'model_bert.pt')\n",
    "\n",
    "        torch.save(checkpoint, best_checkpoint_path)\n",
    "        torch.save(model.state_dict(), best_weights_path)\n",
    "        torch.save(model, best_model_file_path)\n",
    "\n",
    "        # Update global variables\n",
    "        global_best_qwk = current_score\n",
    "        global_best_model_state = model.state_dict().copy()\n",
    "\n",
    "        print(f\"🏆 New best model saved! Score: {current_score:.4f} (Trial {trial_number})\")\n",
    "        print(f\"🏆 Best model files saved in: {best_model_path}\")\n",
    "\n",
    "        return True  # Indicates new best model\n",
    "    else:\n",
    "        print(f\"📊 Trial {trial_number} score: {current_score:.4f} (Best: {best_score:.4f})\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mySRBv5iuu0N",
   "metadata": {
    "id": "mySRBv5iuu0N"
   },
   "outputs": [],
   "source": [
    "def calculate_per_class_metrics(y_true, y_pred, class_names):\n",
    "    \"\"\"Calculate detailed per-class metrics\"\"\"\n",
    "    # Get per-class precision, recall, f1\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=list(range(len(class_names))), zero_division=0\n",
    "    )\n",
    "\n",
    "    # Calculate per-class accuracy (correct predictions for each class)\n",
    "    per_class_accuracy = []\n",
    "    for class_id in range(len(class_names)):\n",
    "        class_mask = (y_true == class_id)\n",
    "        if class_mask.sum() > 0:  # If class exists in true labels\n",
    "            class_acc = ((y_pred == class_id) & (y_true == class_id)).sum() / class_mask.sum()\n",
    "        else:\n",
    "            class_acc = 0.0\n",
    "        per_class_accuracy.append(class_acc)\n",
    "\n",
    "    return precision, recall, f1, per_class_accuracy\n",
    "\n",
    "\n",
    "def print_epoch_summary_table(epoch, train_loss, train_accuracy, val_loss, val_accuracy,\n",
    "                             val_precision, val_recall, val_f1, val_mae, val_adjacent_accuracy,\n",
    "                             val_qwk, per_class_metrics, class_names, epoch_time):\n",
    "    \"\"\"Print a comprehensive epoch summary table\"\"\"\n",
    "\n",
    "    precision, recall, f1, per_class_accuracy = per_class_metrics\n",
    "\n",
    "    print(f\"\\nEPOCH {epoch} DETAILED SUMMARY\")\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    # Overall metrics\n",
    "    print(f\"Epoch Time: {epoch_time:.1f}s\")\n",
    "    print(f\"Training   - Loss: {train_loss:.6f} | Accuracy: {train_accuracy:.6f}\")\n",
    "    print(f\"Validation - Loss: {val_loss:.6f} | Accuracy: {val_accuracy:.6f}\")\n",
    "    print(f\"Overall    - F1: {val_f1:.6f} | Precision: {val_precision:.6f} | Recall: {val_recall:.6f}\")\n",
    "    print(f\"Metrics    - MAE: {val_mae:.6f} | Adjacent Acc: {val_adjacent_accuracy:.6f} | QWK: {val_qwk:.6f}\")\n",
    "\n",
    "    print(\"\\n\" + \"─\" * 120)\n",
    "    print(\"PER-CLASS BREAKDOWN:\")\n",
    "    print(\"─\" * 120)\n",
    "\n",
    "    # Header\n",
    "    print(f\"{'Class':<20} {'F1':<10} {'Precision':<12} {'Recall':<10} {'Accuracy':<10}\")\n",
    "    print(\"─\" * 65)\n",
    "\n",
    "    # Per-class rows\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<20} {f1[i]:<10.6f} {precision[i]:<12.6f} {recall[i]:<10.6f} {per_class_accuracy[i]:<10.6f}\")\n",
    "\n",
    "    print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcc570",
   "metadata": {
    "id": "fbfcc570"
   },
   "source": [
    "### Training and Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05Pz-IxQJLEe",
   "metadata": {
    "id": "05Pz-IxQJLEe"
   },
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    \"\"\"Get total number of parameters\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "\n",
    "def measure_inference_time(model, sample_batch, device, num_runs=10):\n",
    "    \"\"\"Measure average inference time\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Warm up\n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            _ = model(sample_batch['input_ids'].to(device),\n",
    "                     attention_mask=sample_batch['attention_mask'].to(device))\n",
    "\n",
    "    # Measure inference time\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            _ = model(sample_batch['input_ids'].to(device),\n",
    "                     attention_mask=sample_batch['attention_mask'].to(device))\n",
    "\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    end_time = time.time()\n",
    "\n",
    "    avg_inference_time = (end_time - start_time) / num_runs * 1000  # Convert to milliseconds\n",
    "    return avg_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9575d145",
   "metadata": {
    "id": "9575d145"
   },
   "outputs": [],
   "source": [
    "def early_stop_check(patience, best_val_qwk, best_val_qwk_epoch, current_val_qwk, current_val_qwk_epoch):\n",
    "    early_stop_flag = False\n",
    "    if current_val_qwk > best_val_qwk:\n",
    "        best_val_qwk = current_val_qwk\n",
    "        best_val_qwk_epoch = current_val_qwk_epoch\n",
    "    else:\n",
    "        if current_val_qwk_epoch - best_val_qwk_epoch > patience:\n",
    "            early_stop_flag = True\n",
    "    return best_val_qwk, best_val_qwk_epoch, early_stop_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f798b13",
   "metadata": {
    "id": "3f798b13"
   },
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, trial, scheduler=None, max_grad_norm=None, save_checkpoints=True):\n",
    "    # GPU Setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    trial_number = trial.number if trial else 0\n",
    "    checkpoint_dir = None\n",
    "    if save_checkpoints:\n",
    "        checkpoint_dir = Path(f\"./checkpoints_bert/trial_{trial_number}\")\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Calculate model analysis after moving to device\n",
    "    model_size_mb = get_model_size(model)\n",
    "    total_params, trainable_params = get_model_parameters(model)\n",
    "\n",
    "    # Get a sample batch for inference timing\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    inference_time_ms = measure_inference_time(model, sample_batch, device)\n",
    "\n",
    "    best_val_qwk = 0.0\n",
    "    best_val_qwk_epoch = 0\n",
    "    early_stop_flag = False\n",
    "    best_model_state = None\n",
    "    best_checkpoint_path = None\n",
    "\n",
    "    # Print training configuration with model info\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Training Configuration:\")\n",
    "    print(f\"   • Device: {device}\")\n",
    "    print(f\"   • Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"   • Total Parameters: {total_params:,}\")\n",
    "    print(f\"   • Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"   • Avg Inference Time: {inference_time_ms:.2f} ms\")\n",
    "    print(f\"   • Total Epochs: {epochs}\")\n",
    "    print(f\"   • Train Batches: {len(train_loader)}\")\n",
    "    print(f\"   • Validation Batches: {len(val_loader)}\")\n",
    "    print(f\"   • Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"   • Batch Size: {train_loader.batch_size}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Continue with the rest of training loop\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training Phase\n",
    "        print(f\"\\nEPOCH {epoch}/{epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Training loop with speed optimizations\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train_predictions = 0\n",
    "\n",
    "        # Initialize mixed precision scaler\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Training\",\n",
    "                         bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}',\n",
    "                         ncols=100)\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_pbar):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "\n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if max_grad_norm is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            # Accumulate metrics (less frequently for speed)\n",
    "            if batch_idx % 10 == 0 or batch_idx == len(train_loader) - 1:\n",
    "                batch_size = input_ids.size(0)\n",
    "                train_loss += loss.item() * batch_size\n",
    "                total_train_samples += batch_size\n",
    "                with torch.no_grad():\n",
    "                    correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                current_train_loss = train_loss / total_train_samples\n",
    "                current_train_acc = correct_train_predictions / total_train_samples\n",
    "\n",
    "                train_pbar.set_postfix({\n",
    "                    'Loss': f'{current_train_loss:.4f}',\n",
    "                    'Acc': f'{current_train_acc:.3f}',\n",
    "                    'LR': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "                })\n",
    "\n",
    "        train_loss /= total_train_samples\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        ###  Validation loop  ###\n",
    "        print(f\"\\n📋 Validation Phase...\")\n",
    "\n",
    "        # Faster validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val_predictions = 0\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Validation\",\n",
    "                       bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}',\n",
    "                       ncols=100)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "                labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "                # Use mixed precision for validation too\n",
    "                with autocast():\n",
    "                    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                    logits = outputs.logits\n",
    "                    loss = criterion(logits, labels)\n",
    "\n",
    "                batch_size = input_ids.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                total_val_samples += batch_size\n",
    "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "                current_val_loss = val_loss / total_val_samples\n",
    "                current_val_acc = correct_val_predictions / total_val_samples\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{current_val_loss:.4f}',\n",
    "                    'Acc': f'{current_val_acc:.3f}'\n",
    "                })\n",
    "\n",
    "        # calculate metrics\n",
    "        all_val_preds = np.array(all_val_preds)\n",
    "        all_val_labels = np.array(all_val_labels)\n",
    "        val_loss /= total_val_samples\n",
    "        val_accuracy = correct_val_predictions / total_val_samples\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='macro') #### change macro\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='macro')#### change macro\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')#### change macro\n",
    "        val_mae = np.mean(np.abs(all_val_preds - all_val_labels))\n",
    "        val_adjacent_accuracy = np.sum(np.abs(all_val_preds - all_val_labels) <= 1) / len(all_val_labels)\n",
    "        val_qwk = cohen_kappa_score(all_val_labels, all_val_preds, weights='quadratic')\n",
    "\n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        # Calculate per-class metrics\n",
    "        class_names = list(ordinal_id2label.values())\n",
    "        per_class_metrics = calculate_per_class_metrics(all_val_labels, all_val_preds, class_names)\n",
    "\n",
    "        # Print comprehensive epoch summary\n",
    "        print_epoch_summary_table(\n",
    "            epoch, train_loss, train_accuracy, val_loss, val_accuracy,\n",
    "            val_precision, val_recall, val_f1, val_mae, val_adjacent_accuracy,\n",
    "            val_qwk, per_class_metrics, class_names, epoch_time\n",
    "        )\n",
    "\n",
    "        # Check for early stopping\n",
    "        patience = 2\n",
    "        best_val_qwk, best_val_qwk_epoch, early_stop_flag = early_stop_check(patience, best_val_qwk, best_val_qwk_epoch, val_qwk, epoch)\n",
    "\n",
    "        # Save the best model under the best_model_state parameter\n",
    "        if val_qwk == best_val_qwk:\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"New best QWK: {val_qwk:.4f} (saved model)\")\n",
    "        else:\n",
    "            print(f\"QWK: {val_qwk:.4f} (best: {best_val_qwk:.4f} at epoch {best_val_qwk_epoch})\")\n",
    "\n",
    "        detailed_metrics = {\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,  # Usually not computed during training\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Precision\": val_precision,\n",
    "            \"Validation Recall\": val_recall,\n",
    "            \"Model Size (MB)\": model_size_mb,\n",
    "            \"Total Parameters\": total_params,\n",
    "            \"Trainable Parameters\": trainable_params,\n",
    "            \"Inference Time (ms)\": inference_time_ms,\n",
    "            \"Parameters per MB\": total_params / model_size_mb if model_size_mb > 0 else 0,\n",
    "            \"Validation F1\": val_f1,\n",
    "            \"Validation MAE\": val_mae,\n",
    "            \"Validation Adjacent Accuracy\": val_adjacent_accuracy,\n",
    "            \"Validation QWK\": val_qwk,\n",
    "            \"Learning_Rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"Epoch_Time\": epoch_time  # Added epoch time to wandb logging\n",
    "        }\n",
    "\n",
    "        # Log metrics to Weights & Biases\n",
    "        wandb.log(detailed_metrics)\n",
    "\n",
    "        patience = 2\n",
    "        best_val_qwk, best_val_qwk_epoch, early_stop_flag = early_stop_check(\n",
    "            patience, best_val_qwk, best_val_qwk_epoch, val_qwk, epoch\n",
    "        )\n",
    "\n",
    "        if val_qwk == best_val_qwk:\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"🌟 New best QWK: {val_qwk:.4f} (saved model)\")\n",
    "        else:\n",
    "            print(f\"📉 QWK: {val_qwk:.4f} (best: {best_val_qwk:.4f} at epoch {best_val_qwk_epoch})\")\n",
    "\n",
    "        if early_stop_flag:  # Checks whether the early stopping condition has been met, as indicated by the early_stop_flag\n",
    "            print(f\"\\n⏹️  EARLY STOPPING triggered at epoch {epoch}\")\n",
    "            print(f\"    No improvement in QWK for {patience} epochs\")\n",
    "            break# Exits the training loop immediately if the early stopping condition is satisfied\n",
    "\n",
    "    # Training completion summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best QWK: {best_val_qwk:.4f} (Epoch {best_val_qwk_epoch})\")\n",
    "    print(f\"Total Epochs: {epoch}\")\n",
    "    print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"Parameters: {total_params:,} total, {trainable_params:,} trainable\")\n",
    "    print(f\"Inference Time: {inference_time_ms:.2f} ms per sample\")\n",
    "    print(f\"Efficiency: {total_params/1000000:.1f}M params, {inference_time_ms:.1f}ms\")\n",
    "    if best_checkpoint_path:\n",
    "        print(f\"Best Checkpoint: {best_checkpoint_path}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return best_val_qwk, best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d2126c",
   "metadata": {
    "id": "37d2126c"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global global_best_qwk, global_best_model_state\n",
    "\n",
    "    # new HP and wider range\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 3e-5, 5e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.05, 0.15)\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 15)\n",
    "    # Advanced optimization parameters\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.15)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.05, 0.15)\n",
    "    # Model architecture parameters\n",
    "    attention_dropout = trial.suggest_float(\"attention_dropout\", 0.3, 0.4)\n",
    "    hidden_dropout = trial.suggest_float(\"hidden_dropout\", 0.3, 0.4)\n",
    "\n",
    "    # Save trial configuration\n",
    "    trial_config = {\n",
    "        'trial_number': trial.number,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'label_smoothing': label_smoothing,\n",
    "        'epochs': epochs,\n",
    "        'warmup_ratio': warmup_ratio,\n",
    "        'weight_decay': weight_decay,\n",
    "        'attention_dropout': attention_dropout,\n",
    "        'hidden_dropout': hidden_dropout,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,  # Parallel data loading\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        persistent_workers=True  # Keep workers alive\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=5,\n",
    "        id2label=ordinal_id2label,\n",
    "        label2id=ordinal_label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    model_size_mb = get_model_size(model)\n",
    "    total_params, trainable_params = get_model_parameters(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # dropout configutation:\n",
    "    model.config.hidden_dropout_prob = hidden_dropout\n",
    "    model.config.attention_probs_dropout_prob = attention_dropout\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        betas=(0.9, 0.999),  # Default values, but explicit\n",
    "        eps=1e-8,            # Better numerical stability\n",
    "        amsgrad=False        # Standard setting\n",
    "    )\n",
    "\n",
    "    scheduler = None\n",
    "    if warmup_ratio > 0:\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        warmup_steps = int(total_steps * warmup_ratio)\n",
    "\n",
    "        scheduler = get_scheduler(\n",
    "            \"cosine\",  # Linear warmup then decay\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "    wandb.init(project=\"sentiment-full-bert\",\n",
    "                group=model_name.split('/')[-1],\n",
    "                config={\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"label_smoothing\": label_smoothing,\n",
    "                    \"warmup_ratio\": warmup_ratio,\n",
    "                    \"attention_dropout\": attention_dropout,\n",
    "                    \"hidden_dropout\": hidden_dropout,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"model\": model_name},\n",
    "                name=f\"{model_name.split('/')[-1]}_trial_{trial.number}\")\n",
    "\n",
    "    best_val_qwk, best_model_state = train_model_with_hyperparams(\n",
    "        model, train_loader, val_loader, optimizer, criterion, epochs, trial=trial, scheduler=scheduler, max_grad_norm = max_grad_norm, save_checkpoints=True\n",
    "    )\n",
    "\n",
    "    trial_dir = f\"./checkpoints_bert/trial_{trial.number}\"\n",
    "    os.makedirs(trial_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(trial_dir, f'final_epoch_{epochs}.ckpt')\n",
    "\n",
    "    # Prepare trial parameters\n",
    "    trial_params = {\n",
    "        'trial_number': trial.number,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'label_smoothing': label_smoothing,\n",
    "        'epochs': epochs,\n",
    "        'warmup_ratio': warmup_ratio,\n",
    "        'weight_decay': weight_decay,\n",
    "        'attention_dropout': attention_dropout,\n",
    "        'hidden_dropout': hidden_dropout,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "    # Save checkpoint and update best model if needed\n",
    "    is_new_best = save_training_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        epoch=epochs,\n",
    "        loss=0.0,  # track final loss\n",
    "        trial_params=trial_params,\n",
    "        filepath=checkpoint_path,\n",
    "        trial_number=trial.number,\n",
    "        current_score=best_val_qwk,\n",
    "        best_score=global_best_qwk,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    # Update global variables if new best\n",
    "    if is_new_best:\n",
    "        global_best_qwk = best_val_qwk\n",
    "        global_best_model_state = best_model_state.copy()\n",
    "\n",
    "    wandb.finish()\n",
    "    return best_val_qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00463d80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "eaff056b30be4bb4b4b60a0d2bebef0b",
      "3d9491215c0a471f87d32083030e5ea9",
      "dece572d8755490abc564e29ffe540a1",
      "30e85081d3f14e71a5f0db06c5eb4a3d",
      "0d8463be55df462ba54cfb61aaf104e1",
      "9d9e305c443244698e8ea57f91298c6f",
      "10134821bf254743ad96bc3f02a4f9f8",
      "57e4d681649d4e498f7552e670d09d8d",
      "cd644400d9e043fb8628a3376c7f303b",
      "603b27009a234abdaa946080e4486e47",
      "8438931fee98450e9835804f4366d3cb",
      "50ae317e621743aa9b5cff652166e3a4",
      "eddbecafc0e14ac1a1c7b026237c7322",
      "5441b398a6b3406fbd61655b05dbf4d3",
      "f71be797887b4052a6b5e3dd0cde9d6d",
      "d53ddf7de05b4409ace7e43b939229c8",
      "778696b04de643af9376c7d2dded756f",
      "3fcafcce6b544d38b4262965bed2583b",
      "17a631c59eca4558a083348e87d5af81",
      "e8735be100c04ee8954b47c300c1fb58",
      "68788c83cfc94ffc92b471bb65d24f36",
      "efb2d8e2bccb4213b6eac67741341efe",
      "14be82be076d44eb8642de8837e62294",
      "acb8051f99dd478dadbf754d00b34c30",
      "b53720ca6095451e9279cabbbf64201b",
      "e2d1ff38fddd4e82a9f4290acbe5dcdc",
      "fa80ac5acb3e4a26ac385f5506d431a0",
      "9120fdcc9f064436baa24c30e9d10be3",
      "cd1d085caa4c4fc2ab9858048eeee2c6",
      "8e002d6815754ab7958915b42a73c93e",
      "ad68ef71375d4a9e92ad0d76210fab30",
      "4045cf73e69b4a3bb3b63b1e010c5607",
      "c1b1de802f37412fbba27b2b206db6a0"
     ]
    },
    "id": "00463d80",
    "outputId": "0b0f7104-2696-410a-884a-9434e33acfd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 05:38:37,435] A new study created in memory with name: no-name-2d02b57a-985a-4d72-8e08-febaed8b458e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized global_best_qwk: 0.0\n",
      "Initialized global_best_model_state: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaff056b30be4bb4b4b60a0d2bebef0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ae317e621743aa9b5cff652166e3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14be82be076d44eb8642de8837e62294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_053910-z8bh6q1y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z8bh6q1y' target=\"_blank\">bertweet-base-sentiment-analysis_trial_0</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z8bh6q1y' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z8bh6q1y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 354.42 ms\n",
      "   • Total Epochs: 12\n",
      "   • Train Batches: 391\n",
      "   • Validation Batches: 69\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 64\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:13<00:00,  2.94it/s, Loss=1.0800, Acc=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.28it/s, Loss=0.7915, Acc=0.7\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 139.8s\n",
      "Training   - Loss: 1.080017 | Accuracy: 0.583202\n",
      "Validation - Loss: 0.791470 | Accuracy: 0.746615\n",
      "Overall    - F1: 0.754519 | Precision: 0.754489 | Recall: 0.756398\n",
      "Metrics    - MAE: 0.322470 | Adjacent Acc: 0.937113 | QWK: 0.854102\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.784047   0.746296     0.825820   0.825820  \n",
      "Negative             0.677095   0.692571     0.662295   0.662295  \n",
      "Neutral              0.809152   0.802879     0.815523   0.815523  \n",
      "Positive             0.710273   0.697130     0.723922   0.723922  \n",
      "Extremely Positive   0.792027   0.833566     0.754430   0.754430  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8541 (saved model)\n",
      "🌟 New best QWK: 0.8541 (saved model)\n",
      "\n",
      "EPOCH 2/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.6978, Acc=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.46it/s, Loss=0.7377, Acc=0.7\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.9s\n",
      "Training   - Loss: 0.697803 | Accuracy: 0.783912\n",
      "Validation - Loss: 0.737694 | Accuracy: 0.781042\n",
      "Overall    - F1: 0.779813 | Precision: 0.775220 | Recall: 0.801182\n",
      "Metrics    - MAE: 0.271058 | Adjacent Acc: 0.954326 | QWK: 0.889512\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.758506   0.637378     0.936475   0.936475  \n",
      "Negative             0.674293   0.750670     0.612022   0.612022  \n",
      "Neutral              0.848019   0.894015     0.806524   0.806524  \n",
      "Positive             0.776518   0.802510     0.752157   0.752157  \n",
      "Extremely Positive   0.841731   0.791527     0.898734   0.898734  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8895 (saved model)\n",
      "🌟 New best QWK: 0.8895 (saved model)\n",
      "\n",
      "EPOCH 3/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.5794, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.42it/s, Loss=0.6966, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.2s\n",
      "Training   - Loss: 0.579384 | Accuracy: 0.850158\n",
      "Validation - Loss: 0.696564 | Accuracy: 0.809272\n",
      "Overall    - F1: 0.812476 | Precision: 0.807995 | Recall: 0.825171\n",
      "Metrics    - MAE: 0.226073 | Adjacent Acc: 0.967179 | QWK: 0.912086\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.820416   0.761404     0.889344   0.889344  \n",
      "Negative             0.764302   0.801921     0.730055   0.730055  \n",
      "Neutral              0.855286   0.900498     0.814398   0.814398  \n",
      "Positive             0.782466   0.819039     0.749020   0.749020  \n",
      "Extremely Positive   0.839910   0.757114     0.943038   0.943038  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9121 (saved model)\n",
      "🌟 New best QWK: 0.9121 (saved model)\n",
      "\n",
      "EPOCH 4/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.4739, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.42it/s, Loss=0.6444, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.0s\n",
      "Training   - Loss: 0.473895 | Accuracy: 0.892350\n",
      "Validation - Loss: 0.644364 | Accuracy: 0.825109\n",
      "Overall    - F1: 0.824074 | Precision: 0.816792 | Recall: 0.837423\n",
      "Metrics    - MAE: 0.205187 | Adjacent Acc: 0.971999 | QWK: 0.920266\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.806159   0.722403     0.911885   0.911885  \n",
      "Negative             0.750723   0.797297     0.709290   0.709290  \n",
      "Neutral              0.865352   0.866817     0.863892   0.863892  \n",
      "Positive             0.825051   0.850833     0.800784   0.800784  \n",
      "Extremely Positive   0.873084   0.846611     0.901266   0.901266  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9203 (saved model)\n",
      "🌟 New best QWK: 0.9203 (saved model)\n",
      "\n",
      "EPOCH 5/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.4156, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.48it/s, Loss=0.6388, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.415649 | Accuracy: 0.921136\n",
      "Validation - Loss: 0.638768 | Accuracy: 0.839798\n",
      "Overall    - F1: 0.844121 | Precision: 0.841761 | Recall: 0.848471\n",
      "Metrics    - MAE: 0.193252 | Adjacent Acc: 0.969245 | QWK: 0.920805\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.858291   0.842209     0.875000   0.875000  \n",
      "Negative             0.802632   0.805281     0.800000   0.800000  \n",
      "Neutral              0.874489   0.908981     0.842520   0.842520  \n",
      "Positive             0.816147   0.832111     0.800784   0.800784  \n",
      "Extremely Positive   0.869048   0.820225     0.924051   0.924051  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9208 (saved model)\n",
      "🌟 New best QWK: 0.9208 (saved model)\n",
      "\n",
      "EPOCH 6/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.3845, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.51it/s, Loss=0.7119, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.384468 | Accuracy: 0.932965\n",
      "Validation - Loss: 0.711866 | Accuracy: 0.835667\n",
      "Overall    - F1: 0.837643 | Precision: 0.832128 | Recall: 0.844872\n",
      "Metrics    - MAE: 0.193482 | Adjacent Acc: 0.972917 | QWK: 0.922890\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.839388   0.786738     0.899590   0.899590  \n",
      "Negative             0.786579   0.791805     0.781421   0.781421  \n",
      "Neutral              0.858586   0.856663     0.860517   0.860517  \n",
      "Positive             0.828583   0.848684     0.809412   0.809412  \n",
      "Extremely Positive   0.875079   0.876747     0.873418   0.873418  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9229 (saved model)\n",
      "🌟 New best QWK: 0.9229 (saved model)\n",
      "\n",
      "EPOCH 7/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.3310, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.51it/s, Loss=0.7014, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.6s\n",
      "Training   - Loss: 0.331049 | Accuracy: 0.957808\n",
      "Validation - Loss: 0.701445 | Accuracy: 0.841634\n",
      "Overall    - F1: 0.845145 | Precision: 0.840710 | Recall: 0.851087\n",
      "Metrics    - MAE: 0.178793 | Adjacent Acc: 0.980721 | QWK: 0.932400\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.859100   0.822097     0.899590   0.899590  \n",
      "Negative             0.812325   0.833333     0.792350   0.792350  \n",
      "Neutral              0.843478   0.815983     0.872891   0.872891  \n",
      "Positive             0.827836   0.849711     0.807059   0.807059  \n",
      "Extremely Positive   0.882985   0.882427     0.883544   0.883544  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9324 (saved model)\n",
      "🌟 New best QWK: 0.9324 (saved model)\n",
      "\n",
      "EPOCH 8/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.3107, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.45it/s, Loss=0.7733, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.9s\n",
      "Training   - Loss: 0.310714 | Accuracy: 0.964905\n",
      "Validation - Loss: 0.773306 | Accuracy: 0.839569\n",
      "Overall    - F1: 0.841276 | Precision: 0.840717 | Recall: 0.844471\n",
      "Metrics    - MAE: 0.182924 | Adjacent Acc: 0.978885 | QWK: 0.929845\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.850976   0.853608     0.848361   0.848361  \n",
      "Negative             0.796296   0.846248     0.751913   0.751913  \n",
      "Neutral              0.849088   0.834783     0.863892   0.863892  \n",
      "Positive             0.832870   0.843248     0.822745   0.822745  \n",
      "Extremely Positive   0.877151   0.825698     0.935443   0.935443  \n",
      "========================================================================================================================\n",
      "QWK: 0.9298 (best: 0.9324 at epoch 7)\n",
      "📉 QWK: 0.9298 (best: 0.9324 at epoch 7)\n",
      "\n",
      "EPOCH 9/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2802, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.31it/s, Loss=0.7856, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.9s\n",
      "Training   - Loss: 0.280180 | Accuracy: 0.980284\n",
      "Validation - Loss: 0.785629 | Accuracy: 0.834978\n",
      "Overall    - F1: 0.839315 | Precision: 0.835864 | Recall: 0.849722\n",
      "Metrics    - MAE: 0.181317 | Adjacent Acc: 0.985081 | QWK: 0.934467\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.867063   0.840385     0.895492   0.895492  \n",
      "Negative             0.811409   0.867995     0.761749   0.761749  \n",
      "Neutral              0.833160   0.776482     0.898763   0.898763  \n",
      "Positive             0.814659   0.879891     0.758431   0.758431  \n",
      "Extremely Positive   0.870283   0.814570     0.934177   0.934177  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9345 (saved model)\n",
      "🌟 New best QWK: 0.9345 (saved model)\n",
      "\n",
      "EPOCH 10/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2524, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.32it/s, Loss=0.7864, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.1s\n",
      "Training   - Loss: 0.252436 | Accuracy: 0.990142\n",
      "Validation - Loss: 0.786435 | Accuracy: 0.843929\n",
      "Overall    - F1: 0.846448 | Precision: 0.842954 | Recall: 0.853926\n",
      "Metrics    - MAE: 0.172596 | Adjacent Acc: 0.984622 | QWK: 0.936593\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.860488   0.821229     0.903689   0.903689  \n",
      "Negative             0.805361   0.862672     0.755191   0.755191  \n",
      "Neutral              0.837111   0.787698     0.893138   0.893138  \n",
      "Positive             0.838866   0.866946     0.812549   0.812549  \n",
      "Extremely Positive   0.890411   0.876225     0.905063   0.905063  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9366 (saved model)\n",
      "🌟 New best QWK: 0.9366 (saved model)\n",
      "\n",
      "EPOCH 11/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2497, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.44it/s, Loss=0.8095, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.8s\n",
      "Training   - Loss: 0.249711 | Accuracy: 0.991719\n",
      "Validation - Loss: 0.809459 | Accuracy: 0.841864\n",
      "Overall    - F1: 0.844493 | Precision: 0.842067 | Recall: 0.851216\n",
      "Metrics    - MAE: 0.174202 | Adjacent Acc: 0.985311 | QWK: 0.935911\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.862240   0.834933     0.891393   0.891393  \n",
      "Negative             0.801638   0.862720     0.748634   0.748634  \n",
      "Neutral              0.833682   0.779081     0.896513   0.896513  \n",
      "Positive             0.838343   0.869419     0.809412   0.809412  \n",
      "Extremely Positive   0.886560   0.864183     0.910127   0.910127  \n",
      "========================================================================================================================\n",
      "QWK: 0.9359 (best: 0.9366 at epoch 10)\n",
      "📉 QWK: 0.9359 (best: 0.9366 at epoch 10)\n",
      "\n",
      "EPOCH 12/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2368, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.50it/s, Loss=0.8162, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 12 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.8s\n",
      "Training   - Loss: 0.236838 | Accuracy: 0.996057\n",
      "Validation - Loss: 0.816239 | Accuracy: 0.840716\n",
      "Overall    - F1: 0.843123 | Precision: 0.840146 | Recall: 0.850426\n",
      "Metrics    - MAE: 0.175809 | Adjacent Acc: 0.984852 | QWK: 0.935369\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.860534   0.831740     0.891393   0.891393  \n",
      "Negative             0.800468   0.861461     0.747541   0.747541  \n",
      "Neutral              0.836402   0.785573     0.894263   0.894263  \n",
      "Positive             0.836793   0.869712     0.806275   0.806275  \n",
      "Extremely Positive   0.881418   0.852246     0.912658   0.912658  \n",
      "========================================================================================================================\n",
      "QWK: 0.9354 (best: 0.9366 at epoch 10)\n",
      "📉 QWK: 0.9354 (best: 0.9366 at epoch 10)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9366 (Epoch 10)\n",
      "Total Epochs: 12\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 354.42 ms per sample\n",
      "Efficiency: 134.9M params, 354.4ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_0/final_epoch_12.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_0\n",
      "🏆 New best model saved! Score: 0.9366 (Trial 0)\n",
      "🏆 Best model files saved in: ./best_bert_model_so_far\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Epoch_Time</td><td>▁▆█▇▆▅▅▆▆▇▆▆</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>███▇▆▅▄▃▂▂▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▇█▇██▇███</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▄▅▆▆▆▇▇████</td></tr><tr><td>Validation F1</td><td>▁▃▅▆█▇██▇███</td></tr><tr><td>Validation Loss</td><td>▇▅▃▁▁▄▃▆▇▇██</td></tr><tr><td>Validation MAE</td><td>█▆▃▃▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆█▇██▇███</td></tr><tr><td>Validation QWK</td><td>▁▄▆▇▇▇█▇████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇█▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>12</td></tr><tr><td>Epoch_Time</td><td>140.76095</td></tr><tr><td>Inference Time (ms)</td><td>354.42345</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99606</td></tr><tr><td>Train Loss</td><td>0.23684</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.84072</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98485</td></tr><tr><td>Validation F1</td><td>0.84312</td></tr><tr><td>Validation Loss</td><td>0.81624</td></tr><tr><td>Validation MAE</td><td>0.17581</td></tr><tr><td>Validation Precision</td><td>0.84015</td></tr><tr><td>Validation QWK</td><td>0.93537</td></tr><tr><td>Validation Recall</td><td>0.85043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_0</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z8bh6q1y' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z8bh6q1y</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_053910-z8bh6q1y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 06:09:01,859] Trial 0 finished with value: 0.9365934028477956 and parameters: {'learning_rate': 7.889621272296148e-05, 'batch_size': 64, 'label_smoothing': 0.05006721052365936, 'epochs': 12, 'warmup_ratio': 0.08833286582169274, 'weight_decay': 0.07738924193415143, 'attention_dropout': 0.3205473170963326, 'hidden_dropout': 0.37665040790456367}. Best is trial 0 with value: 0.9365934028477956.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_060902-c9dsso6f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/c9dsso6f' target=\"_blank\">bertweet-base-sentiment-analysis_trial_1</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/c9dsso6f' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/c9dsso6f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 105.77 ms\n",
      "   • Total Epochs: 15\n",
      "   • Train Batches: 1563\n",
      "   • Validation Batches: 273\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 16\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.28it/s, Loss=1.1586, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.75it/s, Loss=1.0631, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 223.0s\n",
      "Training   - Loss: 1.158631 | Accuracy: 0.596032\n",
      "Validation - Loss: 1.063138 | Accuracy: 0.662153\n",
      "Overall    - F1: 0.670119 | Precision: 0.678104 | Recall: 0.713044\n",
      "Metrics    - MAE: 0.422538 | Adjacent Acc: 0.931604 | QWK: 0.834940\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.730392   0.607337     0.915984   0.915984  \n",
      "Negative             0.609626   0.667969     0.560656   0.560656  \n",
      "Neutral              0.787144   0.853947     0.730034   0.730034  \n",
      "Positive             0.525123   0.705960     0.418039   0.418039  \n",
      "Extremely Positive   0.698308   0.555306     0.940506   0.940506  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8349 (saved model)\n",
      "🌟 New best QWK: 0.8349 (saved model)\n",
      "\n",
      "EPOCH 2/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.8915, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.22it/s, Loss=0.8486, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.891516 | Accuracy: 0.754762\n",
      "Validation - Loss: 0.848571 | Accuracy: 0.796190\n",
      "Overall    - F1: 0.802317 | Precision: 0.800166 | Recall: 0.812197\n",
      "Metrics    - MAE: 0.262107 | Adjacent Acc: 0.946064 | QWK: 0.884653\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.812749   0.790698     0.836066   0.836066  \n",
      "Negative             0.733234   0.672131     0.806557   0.806557  \n",
      "Neutral              0.844847   0.850627     0.839145   0.839145  \n",
      "Positive             0.759982   0.862550     0.679216   0.679216  \n",
      "Extremely Positive   0.860775   0.824826     0.900000   0.900000  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8847 (saved model)\n",
      "🌟 New best QWK: 0.8847 (saved model)\n",
      "\n",
      "EPOCH 3/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.7744, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.56it/s, Loss=0.9177, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.774411 | Accuracy: 0.817857\n",
      "Validation - Loss: 0.917652 | Accuracy: 0.761992\n",
      "Overall    - F1: 0.757768 | Precision: 0.759792 | Recall: 0.788010\n",
      "Metrics    - MAE: 0.292862 | Adjacent Acc: 0.952031 | QWK: 0.885199\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.730829   0.591139     0.956967   0.956967  \n",
      "Negative             0.618464   0.755521     0.523497   0.523497  \n",
      "Neutral              0.851319   0.911425     0.798650   0.798650  \n",
      "Positive             0.759754   0.797414     0.725490   0.725490  \n",
      "Extremely Positive   0.828475   0.743461     0.935443   0.935443  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8852 (saved model)\n",
      "🌟 New best QWK: 0.8852 (saved model)\n",
      "\n",
      "EPOCH 4/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.6814, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.40it/s, Loss=0.8092, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.681414 | Accuracy: 0.873016\n",
      "Validation - Loss: 0.809210 | Accuracy: 0.819371\n",
      "Overall    - F1: 0.820776 | Precision: 0.816898 | Recall: 0.831371\n",
      "Metrics    - MAE: 0.218728 | Adjacent Acc: 0.964884 | QWK: 0.910614\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.820789   0.729299     0.938525   0.938525  \n",
      "Negative             0.749566   0.796069     0.708197   0.708197  \n",
      "Neutral              0.856312   0.886747     0.827897   0.827897  \n",
      "Positive             0.814441   0.806303     0.822745   0.822745  \n",
      "Extremely Positive   0.862770   0.866071     0.859494   0.859494  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9106 (saved model)\n",
      "🌟 New best QWK: 0.9106 (saved model)\n",
      "\n",
      "EPOCH 5/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.6498, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.83it/s, Loss=0.8490, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.649757 | Accuracy: 0.894444\n",
      "Validation - Loss: 0.849000 | Accuracy: 0.803305\n",
      "Overall    - F1: 0.804518 | Precision: 0.797353 | Recall: 0.825968\n",
      "Metrics    - MAE: 0.240762 | Adjacent Acc: 0.959376 | QWK: 0.904564\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.793814   0.683432     0.946721   0.946721  \n",
      "Negative             0.722501   0.738584     0.707104   0.707104  \n",
      "Neutral              0.865282   0.915829     0.820022   0.820022  \n",
      "Positive             0.790816   0.863510     0.729412   0.729412  \n",
      "Extremely Positive   0.850174   0.785408     0.926582   0.926582  \n",
      "========================================================================================================================\n",
      "QWK: 0.9046 (best: 0.9106 at epoch 4)\n",
      "📉 QWK: 0.9046 (best: 0.9106 at epoch 4)\n",
      "\n",
      "EPOCH 6/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.5941, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:07<00:00, 34.21it/s, Loss=0.8072, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.594135 | Accuracy: 0.921429\n",
      "Validation - Loss: 0.807178 | Accuracy: 0.831765\n",
      "Overall    - F1: 0.834809 | Precision: 0.829805 | Recall: 0.842236\n",
      "Metrics    - MAE: 0.202662 | Adjacent Acc: 0.968097 | QWK: 0.917538\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.847721   0.804788     0.895492   0.895492  \n",
      "Negative             0.770140   0.757128     0.783607   0.783607  \n",
      "Neutral              0.845120   0.879562     0.813273   0.813273  \n",
      "Positive             0.828676   0.856784     0.802353   0.802353  \n",
      "Extremely Positive   0.882389   0.850764     0.916456   0.916456  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9175 (saved model)\n",
      "🌟 New best QWK: 0.9175 (saved model)\n",
      "\n",
      "EPOCH 7/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5662, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.59it/s, Loss=0.8083, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.1s\n",
      "Training   - Loss: 0.566194 | Accuracy: 0.932937\n",
      "Validation - Loss: 0.808266 | Accuracy: 0.847831\n",
      "Overall    - F1: 0.850166 | Precision: 0.856853 | Recall: 0.844664\n",
      "Metrics    - MAE: 0.184760 | Adjacent Acc: 0.970852 | QWK: 0.919772\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.850377   0.895692     0.809426   0.809426  \n",
      "Negative             0.807756   0.819101     0.796721   0.796721  \n",
      "Neutral              0.866328   0.868778     0.863892   0.863892  \n",
      "Positive             0.836641   0.814870     0.859608   0.859608  \n",
      "Extremely Positive   0.889729   0.885822     0.893671   0.893671  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9198 (saved model)\n",
      "🌟 New best QWK: 0.9198 (saved model)\n",
      "\n",
      "EPOCH 8/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.32it/s, Loss=0.5397, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.31it/s, Loss=0.8288, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.8s\n",
      "Training   - Loss: 0.539679 | Accuracy: 0.953571\n",
      "Validation - Loss: 0.828822 | Accuracy: 0.840257\n",
      "Overall    - F1: 0.842802 | Precision: 0.838849 | Recall: 0.850644\n",
      "Metrics    - MAE: 0.182006 | Adjacent Acc: 0.979573 | QWK: 0.930227\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.853119   0.837945     0.868852   0.868852  \n",
      "Negative             0.801596   0.837902     0.768306   0.768306  \n",
      "Neutral              0.853035   0.809909     0.901012   0.901012  \n",
      "Positive             0.823871   0.873462     0.779608   0.779608  \n",
      "Extremely Positive   0.882388   0.835028     0.935443   0.935443  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9302 (saved model)\n",
      "🌟 New best QWK: 0.9302 (saved model)\n",
      "\n",
      "EPOCH 9/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.32it/s, Loss=0.5192, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.52it/s, Loss=0.8374, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.7s\n",
      "Training   - Loss: 0.519177 | Accuracy: 0.959127\n",
      "Validation - Loss: 0.837367 | Accuracy: 0.846683\n",
      "Overall    - F1: 0.850502 | Precision: 0.850125 | Recall: 0.853186\n",
      "Metrics    - MAE: 0.178104 | Adjacent Acc: 0.978426 | QWK: 0.928387\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.873033   0.894624     0.852459   0.852459  \n",
      "Negative             0.814485   0.830682     0.798907   0.798907  \n",
      "Neutral              0.853552   0.829968     0.878515   0.878515  \n",
      "Positive             0.833537   0.866328     0.803137   0.803137  \n",
      "Extremely Positive   0.877904   0.829021     0.932911   0.932911  \n",
      "========================================================================================================================\n",
      "QWK: 0.9284 (best: 0.9302 at epoch 8)\n",
      "📉 QWK: 0.9284 (best: 0.9302 at epoch 8)\n",
      "\n",
      "EPOCH 10/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.4822, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.89it/s, Loss=0.8641, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.8s\n",
      "Training   - Loss: 0.482241 | Accuracy: 0.973016\n",
      "Validation - Loss: 0.864073 | Accuracy: 0.844388\n",
      "Overall    - F1: 0.848382 | Precision: 0.845443 | Recall: 0.854152\n",
      "Metrics    - MAE: 0.174202 | Adjacent Acc: 0.982557 | QWK: 0.934170\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.870681   0.840000     0.903689   0.903689  \n",
      "Negative             0.803371   0.826590     0.781421   0.781421  \n",
      "Neutral              0.833770   0.780943     0.894263   0.894263  \n",
      "Positive             0.839788   0.874363     0.807843   0.807843  \n",
      "Extremely Positive   0.894299   0.905318     0.883544   0.883544  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9342 (saved model)\n",
      "🌟 New best QWK: 0.9342 (saved model)\n",
      "\n",
      "EPOCH 11/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.32it/s, Loss=0.4727, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.33it/s, Loss=0.9028, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.8s\n",
      "Training   - Loss: 0.472708 | Accuracy: 0.982143\n",
      "Validation - Loss: 0.902807 | Accuracy: 0.834290\n",
      "Overall    - F1: 0.833939 | Precision: 0.827983 | Recall: 0.848577\n",
      "Metrics    - MAE: 0.185678 | Adjacent Acc: 0.982098 | QWK: 0.931488\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.837687   0.768836     0.920082   0.920082  \n",
      "Negative             0.763789   0.845950     0.696175   0.696175  \n",
      "Neutral              0.840703   0.798583     0.887514   0.887514  \n",
      "Positive             0.838496   0.885689     0.796078   0.796078  \n",
      "Extremely Positive   0.889021   0.840858     0.943038   0.943038  \n",
      "========================================================================================================================\n",
      "QWK: 0.9315 (best: 0.9342 at epoch 10)\n",
      "📉 QWK: 0.9315 (best: 0.9342 at epoch 10)\n",
      "\n",
      "EPOCH 12/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.4642, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.20it/s, Loss=0.8789, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 12 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.9s\n",
      "Training   - Loss: 0.464174 | Accuracy: 0.985317\n",
      "Validation - Loss: 0.878925 | Accuracy: 0.850126\n",
      "Overall    - F1: 0.852928 | Precision: 0.853118 | Recall: 0.857322\n",
      "Metrics    - MAE: 0.167317 | Adjacent Acc: 0.985081 | QWK: 0.936128\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.871001   0.877339     0.864754   0.864754  \n",
      "Negative             0.812030   0.862408     0.767213   0.767213  \n",
      "Neutral              0.842214   0.779693     0.915636   0.915636  \n",
      "Positive             0.845775   0.886500     0.808627   0.808627  \n",
      "Extremely Positive   0.893617   0.859649     0.930380   0.930380  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9361 (saved model)\n",
      "🌟 New best QWK: 0.9361 (saved model)\n",
      "\n",
      "EPOCH 13/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.32it/s, Loss=0.4486, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.65it/s, Loss=0.8929, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 13 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.448601 | Accuracy: 0.991270\n",
      "Validation - Loss: 0.892908 | Accuracy: 0.848290\n",
      "Overall    - F1: 0.850031 | Precision: 0.849797 | Recall: 0.855105\n",
      "Metrics    - MAE: 0.170530 | Adjacent Acc: 0.983934 | QWK: 0.933975\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.864975   0.857143     0.872951   0.872951  \n",
      "Negative             0.799057   0.867008     0.740984   0.740984  \n",
      "Neutral              0.841723   0.781310     0.912261   0.912261  \n",
      "Positive             0.850081   0.879296     0.822745   0.822745  \n",
      "Extremely Positive   0.894319   0.864227     0.926582   0.926582  \n",
      "========================================================================================================================\n",
      "QWK: 0.9340 (best: 0.9361 at epoch 12)\n",
      "📉 QWK: 0.9340 (best: 0.9361 at epoch 12)\n",
      "\n",
      "EPOCH 14/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.4357, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.05it/s, Loss=0.9015, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 14 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.4s\n",
      "Training   - Loss: 0.435717 | Accuracy: 0.996032\n",
      "Validation - Loss: 0.901549 | Accuracy: 0.845536\n",
      "Overall    - F1: 0.847920 | Precision: 0.845202 | Recall: 0.855896\n",
      "Metrics    - MAE: 0.172137 | Adjacent Acc: 0.984163 | QWK: 0.935255\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.863636   0.833969     0.895492   0.895492  \n",
      "Negative             0.798591   0.862944     0.743169   0.743169  \n",
      "Neutral              0.840083   0.780135     0.910011   0.910011  \n",
      "Positive             0.841458   0.880789     0.805490   0.805490  \n",
      "Extremely Positive   0.895833   0.868171     0.925316   0.925316  \n",
      "========================================================================================================================\n",
      "QWK: 0.9353 (best: 0.9361 at epoch 12)\n",
      "📉 QWK: 0.9353 (best: 0.9361 at epoch 12)\n",
      "\n",
      "EPOCH 15/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.4409, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.39it/s, Loss=0.8962, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 15 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.9s\n",
      "Training   - Loss: 0.440938 | Accuracy: 0.994444\n",
      "Validation - Loss: 0.896250 | Accuracy: 0.847143\n",
      "Overall    - F1: 0.849222 | Precision: 0.846925 | Recall: 0.856160\n",
      "Metrics    - MAE: 0.170530 | Adjacent Acc: 0.984163 | QWK: 0.935628\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.863682   0.839458     0.889344   0.889344  \n",
      "Negative             0.798827   0.862025     0.744262   0.744262  \n",
      "Neutral              0.841941   0.785019     0.907762   0.907762  \n",
      "Positive             0.845277   0.878916     0.814118   0.814118  \n",
      "Extremely Positive   0.896383   0.869203     0.925316   0.925316  \n",
      "========================================================================================================================\n",
      "QWK: 0.9356 (best: 0.9361 at epoch 12)\n",
      "📉 QWK: 0.9356 (best: 0.9361 at epoch 12)\n",
      "\n",
      "⏹️  EARLY STOPPING triggered at epoch 15\n",
      "    No improvement in QWK for 2 epochs\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9361 (Epoch 12)\n",
      "Total Epochs: 15\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 105.77 ms per sample\n",
      "Efficiency: 134.9M params, 105.8ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_1/final_epoch_15.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_1\n",
      "📊 Trial 1 score: 0.9361 (Best: 0.9366)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Epoch_Time</td><td>█▄▂▂▃▃▃▁▁▁▂▂▂▅▂</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>▅██▇▇▆▆▅▄▃▂▂▁▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▅▇▆▇████▇████</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▃▄▅▅▆▆▇▇██████</td></tr><tr><td>Validation F1</td><td>▁▆▄▇▆▇████▇████</td></tr><tr><td>Validation Loss</td><td>█▂▄▁▂▁▁▂▂▃▄▃▃▄▃</td></tr><tr><td>Validation MAE</td><td>█▄▄▂▃▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▆▄▆▆▇█▇██▇████</td></tr><tr><td>Validation QWK</td><td>▁▄▄▆▆▇▇█▇██████</td></tr><tr><td>Validation Recall</td><td>▁▆▅▇▆▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>15</td></tr><tr><td>Epoch_Time</td><td>221.93337</td></tr><tr><td>Inference Time (ms)</td><td>105.77195</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99444</td></tr><tr><td>Train Loss</td><td>0.44094</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.84714</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98416</td></tr><tr><td>Validation F1</td><td>0.84922</td></tr><tr><td>Validation Loss</td><td>0.89625</td></tr><tr><td>Validation MAE</td><td>0.17053</td></tr><tr><td>Validation Precision</td><td>0.84692</td></tr><tr><td>Validation QWK</td><td>0.93563</td></tr><tr><td>Validation Recall</td><td>0.85616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_1</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/c9dsso6f' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/c9dsso6f</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_060902-c9dsso6f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 07:06:20,342] Trial 1 finished with value: 0.9361276398133396 and parameters: {'learning_rate': 4.570195370569955e-05, 'batch_size': 16, 'label_smoothing': 0.11196125036101309, 'epochs': 15, 'warmup_ratio': 0.11199151048649855, 'weight_decay': 0.10019252204650037, 'attention_dropout': 0.3425873629760852, 'hidden_dropout': 0.36120517172971595}. Best is trial 0 with value: 0.9365934028477956.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_070621-os7s7ihs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/os7s7ihs' target=\"_blank\">bertweet-base-sentiment-analysis_trial_2</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/os7s7ihs' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/os7s7ihs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 106.35 ms\n",
      "   • Total Epochs: 12\n",
      "   • Train Batches: 1563\n",
      "   • Validation Batches: 273\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 16\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.29it/s, Loss=1.1386, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.58it/s, Loss=0.9639, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.7s\n",
      "Training   - Loss: 1.138562 | Accuracy: 0.623810\n",
      "Validation - Loss: 0.963892 | Accuracy: 0.762451\n",
      "Overall    - F1: 0.765729 | Precision: 0.761940 | Recall: 0.774810\n",
      "Metrics    - MAE: 0.301813 | Adjacent Acc: 0.943310 | QWK: 0.865491\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.778182   0.699346     0.877049   0.877049  \n",
      "Negative             0.667422   0.692941     0.643716   0.643716  \n",
      "Neutral              0.822616   0.810929     0.834646   0.834646  \n",
      "Positive             0.751377   0.753749     0.749020   0.749020  \n",
      "Extremely Positive   0.809049   0.852735     0.769620   0.769620  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8655 (saved model)\n",
      "🌟 New best QWK: 0.8655 (saved model)\n",
      "\n",
      "EPOCH 2/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.8694, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.74it/s, Loss=0.9284, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.9s\n",
      "Training   - Loss: 0.869402 | Accuracy: 0.803968\n",
      "Validation - Loss: 0.928365 | Accuracy: 0.784714\n",
      "Overall    - F1: 0.786550 | Precision: 0.781296 | Recall: 0.808655\n",
      "Metrics    - MAE: 0.264173 | Adjacent Acc: 0.955474 | QWK: 0.894719\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.785030   0.682300     0.924180   0.924180  \n",
      "Negative             0.702638   0.778220     0.640437   0.640437  \n",
      "Neutral              0.873469   0.906780     0.842520   0.842520  \n",
      "Positive             0.751154   0.807762     0.701961   0.701961  \n",
      "Extremely Positive   0.820456   0.731417     0.934177   0.934177  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8947 (saved model)\n",
      "🌟 New best QWK: 0.8947 (saved model)\n",
      "\n",
      "EPOCH 3/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.7925, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 31.70it/s, Loss=0.8805, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.8s\n",
      "Training   - Loss: 0.792511 | Accuracy: 0.858730\n",
      "Validation - Loss: 0.880527 | Accuracy: 0.816617\n",
      "Overall    - F1: 0.822056 | Precision: 0.829946 | Recall: 0.821255\n",
      "Metrics    - MAE: 0.224466 | Adjacent Acc: 0.962359 | QWK: 0.905765\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.832609   0.886574     0.784836   0.784836  \n",
      "Negative             0.796565   0.782700     0.810929   0.810929  \n",
      "Neutral              0.863500   0.927649     0.807649   0.807649  \n",
      "Positive             0.778534   0.795417     0.762353   0.762353  \n",
      "Extremely Positive   0.839074   0.757390     0.940506   0.940506  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9058 (saved model)\n",
      "🌟 New best QWK: 0.9058 (saved model)\n",
      "\n",
      "EPOCH 4/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.7428, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.00it/s, Loss=0.9040, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.4s\n",
      "Training   - Loss: 0.742778 | Accuracy: 0.886905\n",
      "Validation - Loss: 0.903991 | Accuracy: 0.813174\n",
      "Overall    - F1: 0.819002 | Precision: 0.818160 | Recall: 0.826026\n",
      "Metrics    - MAE: 0.240303 | Adjacent Acc: 0.949277 | QWK: 0.894516\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.825722   0.757265     0.907787   0.907787  \n",
      "Negative             0.736949   0.687146     0.794536   0.794536  \n",
      "Neutral              0.875516   0.920596     0.834646   0.834646  \n",
      "Positive             0.797231   0.828959     0.767843   0.767843  \n",
      "Extremely Positive   0.859591   0.896836     0.825316   0.825316  \n",
      "========================================================================================================================\n",
      "QWK: 0.8945 (best: 0.9058 at epoch 3)\n",
      "📉 QWK: 0.8945 (best: 0.9058 at epoch 3)\n",
      "\n",
      "EPOCH 5/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.6982, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.77it/s, Loss=0.8632, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.698171 | Accuracy: 0.914683\n",
      "Validation - Loss: 0.863173 | Accuracy: 0.835896\n",
      "Overall    - F1: 0.837003 | Precision: 0.850422 | Recall: 0.828817\n",
      "Metrics    - MAE: 0.189580 | Adjacent Acc: 0.975442 | QWK: 0.922626\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.835040   0.938619     0.752049   0.752049  \n",
      "Negative             0.790083   0.796667     0.783607   0.783607  \n",
      "Neutral              0.843783   0.799597     0.893138   0.893138  \n",
      "Positive             0.835600   0.828197     0.843137   0.843137  \n",
      "Extremely Positive   0.880511   0.889032     0.872152   0.872152  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9226 (saved model)\n",
      "🌟 New best QWK: 0.9226 (saved model)\n",
      "\n",
      "EPOCH 6/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.30it/s, Loss=0.6747, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:07<00:00, 34.13it/s, Loss=0.8487, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.674712 | Accuracy: 0.930159\n",
      "Validation - Loss: 0.848748 | Accuracy: 0.854028\n",
      "Overall    - F1: 0.856158 | Precision: 0.853687 | Recall: 0.860148\n",
      "Metrics    - MAE: 0.169153 | Adjacent Acc: 0.978885 | QWK: 0.932843\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.870079   0.837121     0.905738   0.905738  \n",
      "Negative             0.808023   0.849398     0.770492   0.770492  \n",
      "Neutral              0.862315   0.841542     0.884139   0.884139  \n",
      "Positive             0.851765   0.851765     0.851765   0.851765  \n",
      "Extremely Positive   0.888608   0.888608     0.888608   0.888608  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9328 (saved model)\n",
      "🌟 New best QWK: 0.9328 (saved model)\n",
      "\n",
      "EPOCH 7/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.6318, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.42it/s, Loss=0.8808, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.631816 | Accuracy: 0.952381\n",
      "Validation - Loss: 0.880806 | Accuracy: 0.849897\n",
      "Overall    - F1: 0.850109 | Precision: 0.853347 | Recall: 0.848449\n",
      "Metrics    - MAE: 0.178104 | Adjacent Acc: 0.974294 | QWK: 0.926017\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.846885   0.873638     0.821721   0.821721  \n",
      "Negative             0.795872   0.837153     0.758470   0.758470  \n",
      "Neutral              0.867257   0.853101     0.881890   0.881890  \n",
      "Positive             0.849188   0.837529     0.861176   0.861176  \n",
      "Extremely Positive   0.891344   0.865316     0.918987   0.918987  \n",
      "========================================================================================================================\n",
      "QWK: 0.9260 (best: 0.9328 at epoch 6)\n",
      "📉 QWK: 0.9260 (best: 0.9328 at epoch 6)\n",
      "\n",
      "EPOCH 8/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.6037, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.30it/s, Loss=0.9206, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.603681 | Accuracy: 0.967460\n",
      "Validation - Loss: 0.920629 | Accuracy: 0.840028\n",
      "Overall    - F1: 0.844341 | Precision: 0.840248 | Recall: 0.850517\n",
      "Metrics    - MAE: 0.179481 | Adjacent Acc: 0.981868 | QWK: 0.932373\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.866667   0.830827     0.905738   0.905738  \n",
      "Negative             0.813026   0.836028     0.791257   0.791257  \n",
      "Neutral              0.835917   0.796334     0.879640   0.879640  \n",
      "Positive             0.826245   0.854271     0.800000   0.800000  \n",
      "Extremely Positive   0.879847   0.883780     0.875949   0.875949  \n",
      "========================================================================================================================\n",
      "QWK: 0.9324 (best: 0.9328 at epoch 6)\n",
      "📉 QWK: 0.9324 (best: 0.9328 at epoch 6)\n",
      "\n",
      "EPOCH 9/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5736, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.70it/s, Loss=0.9221, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.573605 | Accuracy: 0.980556\n",
      "Validation - Loss: 0.922065 | Accuracy: 0.843929\n",
      "Overall    - F1: 0.845098 | Precision: 0.840601 | Recall: 0.854826\n",
      "Metrics    - MAE: 0.173973 | Adjacent Acc: 0.983704 | QWK: 0.935819\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.856585   0.817505     0.899590   0.899590  \n",
      "Negative             0.796948   0.860583     0.742077   0.742077  \n",
      "Neutral              0.845867   0.804260     0.892013   0.892013  \n",
      "Positive             0.843314   0.883921     0.806275   0.806275  \n",
      "Extremely Positive   0.882775   0.836735     0.934177   0.934177  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9358 (saved model)\n",
      "🌟 New best QWK: 0.9358 (saved model)\n",
      "\n",
      "EPOCH 10/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5607, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 31.80it/s, Loss=0.9455, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.3s\n",
      "Training   - Loss: 0.560733 | Accuracy: 0.986111\n",
      "Validation - Loss: 0.945462 | Accuracy: 0.841405\n",
      "Overall    - F1: 0.845215 | Precision: 0.841638 | Recall: 0.854071\n",
      "Metrics    - MAE: 0.175120 | Adjacent Acc: 0.984852 | QWK: 0.936035\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.869911   0.843931     0.897541   0.897541  \n",
      "Negative             0.812065   0.865266     0.765027   0.765027  \n",
      "Neutral              0.837087   0.783333     0.898763   0.898763  \n",
      "Positive             0.827586   0.879859     0.781176   0.781176  \n",
      "Extremely Positive   0.879424   0.835804     0.927848   0.927848  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9360 (saved model)\n",
      "🌟 New best QWK: 0.9360 (saved model)\n",
      "\n",
      "EPOCH 11/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5488, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.85it/s, Loss=0.9464, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.548783 | Accuracy: 0.990873\n",
      "Validation - Loss: 0.946370 | Accuracy: 0.843929\n",
      "Overall    - F1: 0.847817 | Precision: 0.845149 | Recall: 0.854920\n",
      "Metrics    - MAE: 0.171907 | Adjacent Acc: 0.985541 | QWK: 0.937087\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.873747   0.854902     0.893443   0.893443  \n",
      "Negative             0.815287   0.866995     0.769399   0.769399  \n",
      "Neutral              0.834555   0.780607     0.896513   0.896513  \n",
      "Positive             0.833608   0.877710     0.793725   0.793725  \n",
      "Extremely Positive   0.881890   0.845528     0.921519   0.921519  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9371 (saved model)\n",
      "🌟 New best QWK: 0.9371 (saved model)\n",
      "\n",
      "EPOCH 12/12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5519, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.03it/s, Loss=0.9498, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 12 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.1s\n",
      "Training   - Loss: 0.551921 | Accuracy: 0.990476\n",
      "Validation - Loss: 0.949788 | Accuracy: 0.844159\n",
      "Overall    - F1: 0.847273 | Precision: 0.844680 | Recall: 0.854564\n",
      "Metrics    - MAE: 0.171448 | Adjacent Acc: 0.985770 | QWK: 0.937434\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.869739   0.850980     0.889344   0.889344  \n",
      "Negative             0.810465   0.865839     0.761749   0.761749  \n",
      "Neutral              0.837526   0.784102     0.898763   0.898763  \n",
      "Positive             0.837382   0.881282     0.797647   0.797647  \n",
      "Extremely Positive   0.881254   0.841197     0.925316   0.925316  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9374 (saved model)\n",
      "🌟 New best QWK: 0.9374 (saved model)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9374 (Epoch 12)\n",
      "Total Epochs: 12\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 106.35 ms per sample\n",
      "Efficiency: 134.9M params, 106.4ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_2/final_epoch_12.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_2\n",
      "🏆 New best model saved! Score: 0.9374 (Trial 2)\n",
      "🏆 Best model files saved in: ./best_bert_model_so_far\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Epoch_Time</td><td>▇▁█▅▃▃▂▃▃▄▃▂</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>██▇▇▆▅▄▃▂▂▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▅▇██▇▇▇▇▇</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▃▄▂▆▇▆▇████</td></tr><tr><td>Validation F1</td><td>▁▃▅▅▇██▇▇▇▇▇</td></tr><tr><td>Validation Loss</td><td>█▆▃▄▂▁▃▅▅▇▇▇</td></tr><tr><td>Validation MAE</td><td>█▆▄▅▂▁▁▂▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▆▅███▇▇▇▇▇</td></tr><tr><td>Validation QWK</td><td>▁▄▅▄▇█▇█████</td></tr><tr><td>Validation Recall</td><td>▁▄▅▅▅█▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>12</td></tr><tr><td>Epoch_Time</td><td>222.08167</td></tr><tr><td>Inference Time (ms)</td><td>106.35221</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99048</td></tr><tr><td>Train Loss</td><td>0.55192</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.84416</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98577</td></tr><tr><td>Validation F1</td><td>0.84727</td></tr><tr><td>Validation Loss</td><td>0.94979</td></tr><tr><td>Validation MAE</td><td>0.17145</td></tr><tr><td>Validation Precision</td><td>0.84468</td></tr><tr><td>Validation QWK</td><td>0.93743</td></tr><tr><td>Validation Recall</td><td>0.85456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_2</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/os7s7ihs' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/os7s7ihs</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_070621-os7s7ihs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 07:52:14,358] Trial 2 finished with value: 0.9374337888939281 and parameters: {'learning_rate': 4.7412352298523686e-05, 'batch_size': 16, 'label_smoothing': 0.14864590596800178, 'epochs': 12, 'warmup_ratio': 0.053072966467540166, 'weight_decay': 0.14067329738635054, 'attention_dropout': 0.31630050099253554, 'hidden_dropout': 0.30284169042309084}. Best is trial 2 with value: 0.9374337888939281.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_075215-tal7m47b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/tal7m47b' target=\"_blank\">bertweet-base-sentiment-analysis_trial_3</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/tal7m47b' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/tal7m47b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 192.24 ms\n",
      "   • Total Epochs: 14\n",
      "   • Train Batches: 782\n",
      "   • Validation Batches: 137\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 32\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:41<00:00,  4.85it/s, Loss=1.1726, Acc=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.14it/s, Loss=0.8549, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 168.4s\n",
      "Training   - Loss: 1.172644 | Accuracy: 0.557177\n",
      "Validation - Loss: 0.854929 | Accuracy: 0.714023\n",
      "Overall    - F1: 0.725190 | Precision: 0.725751 | Recall: 0.728238\n",
      "Metrics    - MAE: 0.360340 | Adjacent Acc: 0.932293 | QWK: 0.838611\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.769685   0.740530     0.801230   0.801230  \n",
      "Negative             0.657732   0.622439     0.697268   0.697268  \n",
      "Neutral              0.764513   0.744931     0.785152   0.785152  \n",
      "Positive             0.665313   0.689975     0.642353   0.642353  \n",
      "Extremely Positive   0.768707   0.830882     0.715190   0.715190  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8386 (saved model)\n",
      "🌟 New best QWK: 0.8386 (saved model)\n",
      "\n",
      "EPOCH 2/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.7771, Acc=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.29it/s, Loss=0.7252, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.4s\n",
      "Training   - Loss: 0.777129 | Accuracy: 0.756703\n",
      "Validation - Loss: 0.725171 | Accuracy: 0.784485\n",
      "Overall    - F1: 0.789853 | Precision: 0.805244 | Recall: 0.780053\n",
      "Metrics    - MAE: 0.281845 | Adjacent Acc: 0.939178 | QWK: 0.867264\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.793333   0.866505     0.731557   0.731557  \n",
      "Negative             0.718679   0.750297     0.689617   0.689617  \n",
      "Neutral              0.841044   0.889586     0.797525   0.797525  \n",
      "Positive             0.754938   0.707334     0.809412   0.809412  \n",
      "Extremely Positive   0.841270   0.812500     0.872152   0.872152  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8673 (saved model)\n",
      "🌟 New best QWK: 0.8673 (saved model)\n",
      "\n",
      "EPOCH 3/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.87it/s, Loss=0.6208, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.31it/s, Loss=0.6889, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.7s\n",
      "Training   - Loss: 0.620757 | Accuracy: 0.832808\n",
      "Validation - Loss: 0.688914 | Accuracy: 0.805830\n",
      "Overall    - F1: 0.804281 | Precision: 0.812464 | Recall: 0.813224\n",
      "Metrics    - MAE: 0.233647 | Adjacent Acc: 0.964196 | QWK: 0.904822\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.784446   0.667626     0.950820   0.950820  \n",
      "Negative             0.720657   0.778200     0.671038   0.671038  \n",
      "Neutral              0.860729   0.918367     0.809899   0.809899  \n",
      "Positive             0.817847   0.771747     0.869804   0.869804  \n",
      "Extremely Positive   0.837725   0.926380     0.764557   0.764557  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9048 (saved model)\n",
      "🌟 New best QWK: 0.9048 (saved model)\n",
      "\n",
      "EPOCH 4/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.5251, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.75it/s, Loss=0.6822, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.525098 | Accuracy: 0.878943\n",
      "Validation - Loss: 0.682199 | Accuracy: 0.822125\n",
      "Overall    - F1: 0.821963 | Precision: 0.816788 | Recall: 0.833566\n",
      "Metrics    - MAE: 0.213679 | Adjacent Acc: 0.966491 | QWK: 0.913401\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.813996   0.739130     0.905738   0.905738  \n",
      "Negative             0.744770   0.821900     0.680874   0.680874  \n",
      "Neutral              0.862702   0.852747     0.872891   0.872891  \n",
      "Positive             0.814727   0.822542     0.807059   0.807059  \n",
      "Extremely Positive   0.873620   0.847619     0.901266   0.901266  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9134 (saved model)\n",
      "🌟 New best QWK: 0.9134 (saved model)\n",
      "\n",
      "EPOCH 5/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.4818, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.84it/s, Loss=0.6630, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.2s\n",
      "Training   - Loss: 0.481807 | Accuracy: 0.897871\n",
      "Validation - Loss: 0.663027 | Accuracy: 0.842093\n",
      "Overall    - F1: 0.844437 | Precision: 0.842998 | Recall: 0.849446\n",
      "Metrics    - MAE: 0.192334 | Adjacent Acc: 0.966950 | QWK: 0.919910\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.846948   0.781629     0.924180   0.924180  \n",
      "Negative             0.782276   0.783133     0.781421   0.781421  \n",
      "Neutral              0.882051   0.893764     0.870641   0.870641  \n",
      "Positive             0.836576   0.830116     0.843137   0.843137  \n",
      "Extremely Positive   0.874332   0.926346     0.827848   0.827848  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9199 (saved model)\n",
      "🌟 New best QWK: 0.9199 (saved model)\n",
      "\n",
      "EPOCH 6/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.4223, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.91it/s, Loss=0.7027, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.422319 | Accuracy: 0.921924\n",
      "Validation - Loss: 0.702655 | Accuracy: 0.833372\n",
      "Overall    - F1: 0.833760 | Precision: 0.825382 | Recall: 0.848744\n",
      "Metrics    - MAE: 0.190957 | Adjacent Acc: 0.976819 | QWK: 0.928602\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.832721   0.755000     0.928279   0.928279  \n",
      "Negative             0.772334   0.817073     0.732240   0.732240  \n",
      "Neutral              0.865311   0.846237     0.885264   0.885264  \n",
      "Positive             0.827872   0.878521     0.782745   0.782745  \n",
      "Extremely Positive   0.870560   0.830080     0.915190   0.915190  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9286 (saved model)\n",
      "🌟 New best QWK: 0.9286 (saved model)\n",
      "\n",
      "EPOCH 7/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.3767, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.55it/s, Loss=0.7810, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.4s\n",
      "Training   - Loss: 0.376704 | Accuracy: 0.943218\n",
      "Validation - Loss: 0.780991 | Accuracy: 0.813174\n",
      "Overall    - F1: 0.816134 | Precision: 0.809189 | Recall: 0.833987\n",
      "Metrics    - MAE: 0.215974 | Adjacent Acc: 0.971999 | QWK: 0.920119\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.826493   0.758562     0.907787   0.907787  \n",
      "Negative             0.769841   0.799764     0.742077   0.742077  \n",
      "Neutral              0.863301   0.870709     0.856018   0.856018  \n",
      "Positive             0.781748   0.866412     0.712157   0.712157  \n",
      "Extremely Positive   0.839286   0.750499     0.951899   0.951899  \n",
      "========================================================================================================================\n",
      "QWK: 0.9201 (best: 0.9286 at epoch 6)\n",
      "📉 QWK: 0.9201 (best: 0.9286 at epoch 6)\n",
      "\n",
      "EPOCH 8/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.3599, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.54it/s, Loss=0.7453, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.359929 | Accuracy: 0.955442\n",
      "Validation - Loss: 0.745297 | Accuracy: 0.834978\n",
      "Overall    - F1: 0.839549 | Precision: 0.837962 | Recall: 0.845962\n",
      "Metrics    - MAE: 0.191875 | Adjacent Acc: 0.974524 | QWK: 0.925963\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.858308   0.853955     0.862705   0.862705  \n",
      "Negative             0.809551   0.843602     0.778142   0.778142  \n",
      "Neutral              0.871591   0.880597     0.862767   0.862767  \n",
      "Positive             0.802938   0.836735     0.771765   0.771765  \n",
      "Extremely Positive   0.855360   0.774923     0.954430   0.954430  \n",
      "========================================================================================================================\n",
      "QWK: 0.9260 (best: 0.9286 at epoch 6)\n",
      "📉 QWK: 0.9260 (best: 0.9286 at epoch 6)\n",
      "\n",
      "EPOCH 9/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.89it/s, Loss=0.3258, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 20.05it/s, Loss=0.7724, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 166.9s\n",
      "Training   - Loss: 0.325795 | Accuracy: 0.971609\n",
      "Validation - Loss: 0.772386 | Accuracy: 0.838880\n",
      "Overall    - F1: 0.842320 | Precision: 0.843037 | Recall: 0.843808\n",
      "Metrics    - MAE: 0.184072 | Adjacent Acc: 0.978426 | QWK: 0.928875\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.865828   0.886266     0.846311   0.846311  \n",
      "Negative             0.796128   0.831153     0.763934   0.763934  \n",
      "Neutral              0.845941   0.830803     0.861642   0.861642  \n",
      "Positive             0.830414   0.843169     0.818039   0.818039  \n",
      "Extremely Positive   0.873290   0.823793     0.929114   0.929114  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9289 (saved model)\n",
      "🌟 New best QWK: 0.9289 (saved model)\n",
      "\n",
      "EPOCH 10/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:39<00:00,  4.89it/s, Loss=0.3177, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 20.02it/s, Loss=0.7650, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 166.8s\n",
      "Training   - Loss: 0.317681 | Accuracy: 0.972792\n",
      "Validation - Loss: 0.764975 | Accuracy: 0.848979\n",
      "Overall    - F1: 0.851686 | Precision: 0.847410 | Recall: 0.857437\n",
      "Metrics    - MAE: 0.171678 | Adjacent Acc: 0.980262 | QWK: 0.934503\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.865079   0.838462     0.893443   0.893443  \n",
      "Negative             0.804919   0.823799     0.786885   0.786885  \n",
      "Neutral              0.854054   0.822060     0.888639   0.888639  \n",
      "Positive             0.843129   0.872483     0.815686   0.815686  \n",
      "Extremely Positive   0.891250   0.880247     0.902532   0.902532  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9345 (saved model)\n",
      "🌟 New best QWK: 0.9345 (saved model)\n",
      "\n",
      "EPOCH 11/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.2962, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.61it/s, Loss=0.8047, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.2s\n",
      "Training   - Loss: 0.296174 | Accuracy: 0.981073\n",
      "Validation - Loss: 0.804747 | Accuracy: 0.843929\n",
      "Overall    - F1: 0.847261 | Precision: 0.846097 | Recall: 0.851190\n",
      "Metrics    - MAE: 0.174202 | Adjacent Acc: 0.982786 | QWK: 0.934832\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.868313   0.871901     0.864754   0.864754  \n",
      "Negative             0.803653   0.841099     0.769399   0.769399  \n",
      "Neutral              0.837308   0.791583     0.888639   0.888639  \n",
      "Positive             0.837739   0.869932     0.807843   0.807843  \n",
      "Extremely Positive   0.889294   0.855972     0.925316   0.925316  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9348 (saved model)\n",
      "🌟 New best QWK: 0.9348 (saved model)\n",
      "\n",
      "EPOCH 12/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.2699, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.58it/s, Loss=0.8078, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 12 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.269885 | Accuracy: 0.991719\n",
      "Validation - Loss: 0.807792 | Accuracy: 0.845765\n",
      "Overall    - F1: 0.849189 | Precision: 0.846579 | Recall: 0.854901\n",
      "Metrics    - MAE: 0.171678 | Adjacent Acc: 0.983704 | QWK: 0.936059\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.870968   0.857143     0.885246   0.885246  \n",
      "Negative             0.807780   0.847539     0.771585   0.771585  \n",
      "Neutral              0.839389   0.789109     0.896513   0.896513  \n",
      "Positive             0.838921   0.876174     0.804706   0.804706  \n",
      "Extremely Positive   0.888889   0.862932     0.916456   0.916456  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9361 (saved model)\n",
      "🌟 New best QWK: 0.9361 (saved model)\n",
      "\n",
      "EPOCH 13/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:39<00:00,  4.89it/s, Loss=0.2641, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.56it/s, Loss=0.8137, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 13 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 166.9s\n",
      "Training   - Loss: 0.264086 | Accuracy: 0.994874\n",
      "Validation - Loss: 0.813695 | Accuracy: 0.847602\n",
      "Overall    - F1: 0.850341 | Precision: 0.846691 | Recall: 0.856646\n",
      "Metrics    - MAE: 0.170989 | Adjacent Acc: 0.982557 | QWK: 0.935891\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.866867   0.847358     0.887295   0.887295  \n",
      "Negative             0.805936   0.843489     0.771585   0.771585  \n",
      "Neutral              0.846154   0.805697     0.890889   0.890889  \n",
      "Positive             0.841419   0.876061     0.809412   0.809412  \n",
      "Extremely Positive   0.891331   0.860849     0.924051   0.924051  \n",
      "========================================================================================================================\n",
      "QWK: 0.9359 (best: 0.9361 at epoch 12)\n",
      "📉 QWK: 0.9359 (best: 0.9361 at epoch 12)\n",
      "\n",
      "EPOCH 14/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:39<00:00,  4.89it/s, Loss=0.2742, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.50it/s, Loss=0.8108, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 14 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 166.9s\n",
      "Training   - Loss: 0.274217 | Accuracy: 0.991325\n",
      "Validation - Loss: 0.810761 | Accuracy: 0.847602\n",
      "Overall    - F1: 0.850528 | Precision: 0.847736 | Recall: 0.856079\n",
      "Metrics    - MAE: 0.170301 | Adjacent Acc: 0.983245 | QWK: 0.936328\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.868952   0.855159     0.883197   0.883197  \n",
      "Negative             0.807560   0.848375     0.770492   0.770492  \n",
      "Neutral              0.842105   0.798387     0.890889   0.890889  \n",
      "Positive             0.842148   0.874894     0.811765   0.811765  \n",
      "Extremely Positive   0.891875   0.861865     0.924051   0.924051  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9363 (saved model)\n",
      "🌟 New best QWK: 0.9363 (saved model)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9363 (Epoch 14)\n",
      "Total Epochs: 14\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 192.24 ms per sample\n",
      "Efficiency: 134.9M params, 192.2ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_3/final_epoch_14.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_3\n",
      "📊 Trial 3 score: 0.9363 (Best: 0.9374)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Epoch_Time</td><td>█▄▅▃▃▃▄▃▁▁▃▃▁▂</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>▅███▇▆▅▅▄▃▂▁▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇█▇▆▇▇█████</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▂▅▆▆▇▆▇▇█████</td></tr><tr><td>Validation F1</td><td>▁▅▅▆█▇▆▇▇█████</td></tr><tr><td>Validation Loss</td><td>█▃▂▂▁▂▅▄▅▅▆▆▆▆</td></tr><tr><td>Validation MAE</td><td>█▅▃▃▂▂▃▂▂▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▆▆▆█▇▆▇██████</td></tr><tr><td>Validation QWK</td><td>▁▃▆▆▇▇▇▇▇█████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇██▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>Epoch_Time</td><td>166.93316</td></tr><tr><td>Inference Time (ms)</td><td>192.24169</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99132</td></tr><tr><td>Train Loss</td><td>0.27422</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.8476</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98325</td></tr><tr><td>Validation F1</td><td>0.85053</td></tr><tr><td>Validation Loss</td><td>0.81076</td></tr><tr><td>Validation MAE</td><td>0.1703</td></tr><tr><td>Validation Precision</td><td>0.84774</td></tr><tr><td>Validation QWK</td><td>0.93633</td></tr><tr><td>Validation Recall</td><td>0.85608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_3</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/tal7m47b' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/tal7m47b</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_075215-tal7m47b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 08:31:58,619] Trial 3 finished with value: 0.9363284149992751 and parameters: {'learning_rate': 4.370722861893705e-05, 'batch_size': 32, 'label_smoothing': 0.05650532067967007, 'epochs': 14, 'warmup_ratio': 0.14505869364791701, 'weight_decay': 0.12934805586326448, 'attention_dropout': 0.30555226844342287, 'hidden_dropout': 0.3755019911761089}. Best is trial 2 with value: 0.9374337888939281.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_083159-z7houu3c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z7houu3c' target=\"_blank\">bertweet-base-sentiment-analysis_trial_4</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z7houu3c' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z7houu3c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 101.92 ms\n",
      "   • Total Epochs: 10\n",
      "   • Train Batches: 1563\n",
      "   • Validation Batches: 273\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 16\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:34<00:00,  7.29it/s, Loss=1.1783, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 32.23it/s, Loss=0.9674, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.8s\n",
      "Training   - Loss: 1.178308 | Accuracy: 0.590873\n",
      "Validation - Loss: 0.967420 | Accuracy: 0.748451\n",
      "Overall    - F1: 0.754341 | Precision: 0.751474 | Recall: 0.767736\n",
      "Metrics    - MAE: 0.328667 | Adjacent Acc: 0.929998 | QWK: 0.855008\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.767521   0.658358     0.920082   0.920082  \n",
      "Negative             0.644049   0.655719     0.632787   0.632787  \n",
      "Neutral              0.818291   0.879690     0.764904   0.764904  \n",
      "Positive             0.728132   0.731591     0.724706   0.724706  \n",
      "Extremely Positive   0.813713   0.832011     0.796203   0.796203  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8550 (saved model)\n",
      "🌟 New best QWK: 0.8550 (saved model)\n",
      "\n",
      "EPOCH 2/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.9163, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.55it/s, Loss=0.9048, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.1s\n",
      "Training   - Loss: 0.916252 | Accuracy: 0.777381\n",
      "Validation - Loss: 0.904805 | Accuracy: 0.792059\n",
      "Overall    - F1: 0.795268 | Precision: 0.787477 | Recall: 0.809422\n",
      "Metrics    - MAE: 0.254074 | Adjacent Acc: 0.956622 | QWK: 0.896657\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.796082   0.703937     0.915984   0.915984  \n",
      "Negative             0.714912   0.717272     0.712568   0.712568  \n",
      "Neutral              0.848000   0.861789     0.834646   0.834646  \n",
      "Positive             0.775175   0.814335     0.739608   0.739608  \n",
      "Extremely Positive   0.842172   0.840050     0.844304   0.844304  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8967 (saved model)\n",
      "🌟 New best QWK: 0.8967 (saved model)\n",
      "\n",
      "EPOCH 3/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.8090, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.54it/s, Loss=0.8774, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.1s\n",
      "Training   - Loss: 0.808961 | Accuracy: 0.844048\n",
      "Validation - Loss: 0.877402 | Accuracy: 0.819601\n",
      "Overall    - F1: 0.822492 | Precision: 0.835104 | Recall: 0.815582\n",
      "Metrics    - MAE: 0.223319 | Adjacent Acc: 0.959835 | QWK: 0.900352\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.826884   0.821862     0.831967   0.831967  \n",
      "Negative             0.764097   0.806804     0.725683   0.725683  \n",
      "Neutral              0.864350   0.861453     0.867267   0.867267  \n",
      "Positive             0.807094   0.749328     0.874510   0.874510  \n",
      "Extremely Positive   0.850035   0.936073     0.778481   0.778481  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9004 (saved model)\n",
      "🌟 New best QWK: 0.9004 (saved model)\n",
      "\n",
      "EPOCH 4/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.7432, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.22it/s, Loss=0.8633, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.2s\n",
      "Training   - Loss: 0.743178 | Accuracy: 0.884127\n",
      "Validation - Loss: 0.863254 | Accuracy: 0.830388\n",
      "Overall    - F1: 0.830964 | Precision: 0.826848 | Recall: 0.837711\n",
      "Metrics    - MAE: 0.201744 | Adjacent Acc: 0.971311 | QWK: 0.917462\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.821643   0.803922     0.840164   0.840164  \n",
      "Negative             0.787948   0.821090     0.757377   0.757377  \n",
      "Neutral              0.870666   0.852371     0.889764   0.889764  \n",
      "Positive             0.813518   0.845893     0.783529   0.783529  \n",
      "Extremely Positive   0.861045   0.810962     0.917722   0.917722  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9175 (saved model)\n",
      "🌟 New best QWK: 0.9175 (saved model)\n",
      "\n",
      "EPOCH 5/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.30it/s, Loss=0.6916, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.62it/s, Loss=0.8811, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.1s\n",
      "Training   - Loss: 0.691583 | Accuracy: 0.909524\n",
      "Validation - Loss: 0.881083 | Accuracy: 0.831076\n",
      "Overall    - F1: 0.834894 | Precision: 0.836581 | Recall: 0.836816\n",
      "Metrics    - MAE: 0.199220 | Adjacent Acc: 0.972229 | QWK: 0.919884\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.843552   0.871179     0.817623   0.817623  \n",
      "Negative             0.807155   0.826087     0.789071   0.789071  \n",
      "Neutral              0.861063   0.875581     0.847019   0.847019  \n",
      "Positive             0.801444   0.820197     0.783529   0.783529  \n",
      "Extremely Positive   0.861255   0.789863     0.946835   0.946835  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9199 (saved model)\n",
      "🌟 New best QWK: 0.9199 (saved model)\n",
      "\n",
      "EPOCH 6/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.6402, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 34.10it/s, Loss=0.9077, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.8s\n",
      "Training   - Loss: 0.640169 | Accuracy: 0.936508\n",
      "Validation - Loss: 0.907656 | Accuracy: 0.826257\n",
      "Overall    - F1: 0.829507 | Precision: 0.824873 | Recall: 0.840788\n",
      "Metrics    - MAE: 0.198990 | Adjacent Acc: 0.976819 | QWK: 0.924899\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.848665   0.820268     0.879098   0.879098  \n",
      "Negative             0.788087   0.827918     0.751913   0.751913  \n",
      "Neutral              0.853982   0.840044     0.868391   0.868391  \n",
      "Positive             0.804029   0.864621     0.751373   0.751373  \n",
      "Extremely Positive   0.852775   0.771516     0.953165   0.953165  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9249 (saved model)\n",
      "🌟 New best QWK: 0.9249 (saved model)\n",
      "\n",
      "EPOCH 7/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5968, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 34.11it/s, Loss=0.9336, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 221.9s\n",
      "Training   - Loss: 0.596794 | Accuracy: 0.959921\n",
      "Validation - Loss: 0.933639 | Accuracy: 0.829699\n",
      "Overall    - F1: 0.832369 | Precision: 0.825939 | Recall: 0.845238\n",
      "Metrics    - MAE: 0.188891 | Adjacent Acc: 0.982786 | QWK: 0.931120\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.843083   0.770798     0.930328   0.930328  \n",
      "Negative             0.786001   0.827295     0.748634   0.748634  \n",
      "Neutral              0.828346   0.776575     0.887514   0.887514  \n",
      "Positive             0.821280   0.873563     0.774902   0.774902  \n",
      "Extremely Positive   0.883133   0.881463     0.884810   0.884810  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9311 (saved model)\n",
      "🌟 New best QWK: 0.9311 (saved model)\n",
      "\n",
      "EPOCH 8/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5900, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.72it/s, Loss=0.9119, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.590041 | Accuracy: 0.965476\n",
      "Validation - Loss: 0.911929 | Accuracy: 0.840487\n",
      "Overall    - F1: 0.842635 | Precision: 0.837105 | Recall: 0.851576\n",
      "Metrics    - MAE: 0.178793 | Adjacent Acc: 0.982098 | QWK: 0.933413\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.851747   0.789842     0.924180   0.924180  \n",
      "Negative             0.794536   0.828979     0.762842   0.762842  \n",
      "Neutral              0.839827   0.809176     0.872891   0.872891  \n",
      "Positive             0.838034   0.861640     0.815686   0.815686  \n",
      "Extremely Positive   0.889031   0.895887     0.882278   0.882278  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9334 (saved model)\n",
      "🌟 New best QWK: 0.9334 (saved model)\n",
      "\n",
      "EPOCH 9/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5386, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.85it/s, Loss=0.9183, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.538640 | Accuracy: 0.988492\n",
      "Validation - Loss: 0.918270 | Accuracy: 0.840487\n",
      "Overall    - F1: 0.843798 | Precision: 0.839815 | Recall: 0.851624\n",
      "Metrics    - MAE: 0.176498 | Adjacent Acc: 0.984622 | QWK: 0.935045\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.868110   0.835227     0.903689   0.903689  \n",
      "Negative             0.800464   0.852905     0.754098   0.754098  \n",
      "Neutral              0.836421   0.790000     0.888639   0.888639  \n",
      "Positive             0.833945   0.869048     0.801569   0.801569  \n",
      "Extremely Positive   0.880049   0.851896     0.910127   0.910127  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9350 (saved model)\n",
      "🌟 New best QWK: 0.9350 (saved model)\n",
      "\n",
      "EPOCH 10/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/1563 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 1563/1563 [03:33<00:00,  7.31it/s, Loss=0.5460, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/273 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 273/273 [00:08<00:00, 33.27it/s, Loss=0.9271, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 222.0s\n",
      "Training   - Loss: 0.546027 | Accuracy: 0.987302\n",
      "Validation - Loss: 0.927108 | Accuracy: 0.842552\n",
      "Overall    - F1: 0.846158 | Precision: 0.843275 | Recall: 0.852811\n",
      "Metrics    - MAE: 0.173055 | Adjacent Acc: 0.985770 | QWK: 0.936752\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.872873   0.853229     0.893443   0.893443  \n",
      "Negative             0.802768   0.849817     0.760656   0.760656  \n",
      "Neutral              0.836306   0.783677     0.896513   0.896513  \n",
      "Positive             0.836885   0.876395     0.800784   0.800784  \n",
      "Extremely Positive   0.881957   0.853254     0.912658   0.912658  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9368 (saved model)\n",
      "🌟 New best QWK: 0.9368 (saved model)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9368 (Epoch 10)\n",
      "Total Epochs: 10\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 101.92 ms per sample\n",
      "Efficiency: 134.9M params, 101.9ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_4/final_epoch_10.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_4\n",
      "📊 Trial 4 score: 0.9368 (Best: 0.9374)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Epoch_Time</td><td>█▃▃▃▃▁▁▂▂▂</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>▇█▇▆▅▄▃▂▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▇▇▇███</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▄▅▆▆▇████</td></tr><tr><td>Validation F1</td><td>▁▄▆▇▇▇▇███</td></tr><tr><td>Validation Loss</td><td>█▄▂▁▂▄▆▄▅▅</td></tr><tr><td>Validation MAE</td><td>█▅▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▇▇▇▇▇███</td></tr><tr><td>Validation QWK</td><td>▁▅▅▆▇▇████</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Epoch_Time</td><td>221.98794</td></tr><tr><td>Inference Time (ms)</td><td>101.9181</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.9873</td></tr><tr><td>Train Loss</td><td>0.54603</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.84255</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98577</td></tr><tr><td>Validation F1</td><td>0.84616</td></tr><tr><td>Validation Loss</td><td>0.92711</td></tr><tr><td>Validation MAE</td><td>0.17305</td></tr><tr><td>Validation Precision</td><td>0.84327</td></tr><tr><td>Validation QWK</td><td>0.93675</td></tr><tr><td>Validation Recall</td><td>0.85281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_4</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z7houu3c' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/z7houu3c</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_083159-z7houu3c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 09:09:26,444] Trial 4 finished with value: 0.9367519028033742 and parameters: {'learning_rate': 5.06464307077503e-05, 'batch_size': 16, 'label_smoothing': 0.1429467563112426, 'epochs': 10, 'warmup_ratio': 0.11532875879528516, 'weight_decay': 0.13075132035276754, 'attention_dropout': 0.3243327937987488, 'hidden_dropout': 0.31432088948837145}. Best is trial 2 with value: 0.9374337888939281.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_090927-jvtgln6m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/jvtgln6m' target=\"_blank\">bertweet-base-sentiment-analysis_trial_5</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/jvtgln6m' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/jvtgln6m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 388.30 ms\n",
      "   • Total Epochs: 11\n",
      "   • Train Batches: 391\n",
      "   • Validation Batches: 69\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 64\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.90it/s, Loss=1.0478, Acc=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.07it/s, Loss=0.8632, Acc=0.7\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.9s\n",
      "Training   - Loss: 1.047771 | Accuracy: 0.606467\n",
      "Validation - Loss: 0.863212 | Accuracy: 0.722745\n",
      "Overall    - F1: 0.724344 | Precision: 0.769846 | Recall: 0.716593\n",
      "Metrics    - MAE: 0.354372 | Adjacent Acc: 0.929080 | QWK: 0.828504\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.779528   0.750000     0.811475   0.811475  \n",
      "Negative             0.622654   0.763492     0.525683   0.525683  \n",
      "Neutral              0.815057   0.791314     0.840270   0.840270  \n",
      "Positive             0.711256   0.608939     0.854902   0.854902  \n",
      "Extremely Positive   0.693227   0.935484     0.550633   0.550633  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8285 (saved model)\n",
      "🌟 New best QWK: 0.8285 (saved model)\n",
      "\n",
      "EPOCH 2/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.7664, Acc=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.27it/s, Loss=0.8179, Acc=0.7\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.0s\n",
      "Training   - Loss: 0.766432 | Accuracy: 0.762224\n",
      "Validation - Loss: 0.817935 | Accuracy: 0.750975\n",
      "Overall    - F1: 0.750781 | Precision: 0.743970 | Recall: 0.780460\n",
      "Metrics    - MAE: 0.313978 | Adjacent Acc: 0.941014 | QWK: 0.872900\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.723539   0.588689     0.938525   0.938525  \n",
      "Negative             0.621089   0.660912     0.585792   0.585792  \n",
      "Neutral              0.833621   0.853774     0.814398   0.814398  \n",
      "Positive             0.733800   0.830525     0.657255   0.657255  \n",
      "Extremely Positive   0.841858   0.785950     0.906329   0.906329  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8729 (saved model)\n",
      "🌟 New best QWK: 0.8729 (saved model)\n",
      "\n",
      "EPOCH 3/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.5892, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.36it/s, Loss=0.7005, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.0s\n",
      "Training   - Loss: 0.589166 | Accuracy: 0.848580\n",
      "Validation - Loss: 0.700483 | Accuracy: 0.810190\n",
      "Overall    - F1: 0.812105 | Precision: 0.818714 | Recall: 0.810996\n",
      "Metrics    - MAE: 0.239614 | Adjacent Acc: 0.955015 | QWK: 0.891756\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.811565   0.790291     0.834016   0.834016  \n",
      "Negative             0.738124   0.833563     0.662295   0.662295  \n",
      "Neutral              0.856351   0.844639     0.868391   0.868391  \n",
      "Positive             0.793662   0.748436     0.844706   0.844706  \n",
      "Extremely Positive   0.860825   0.876640     0.845570   0.845570  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8918 (saved model)\n",
      "🌟 New best QWK: 0.8918 (saved model)\n",
      "\n",
      "EPOCH 4/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.5457, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.33it/s, Loss=0.6872, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.9s\n",
      "Training   - Loss: 0.545671 | Accuracy: 0.874606\n",
      "Validation - Loss: 0.687241 | Accuracy: 0.829470\n",
      "Overall    - F1: 0.832609 | Precision: 0.831003 | Recall: 0.836114\n",
      "Metrics    - MAE: 0.210695 | Adjacent Acc: 0.962359 | QWK: 0.910574\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.833671   0.825301     0.842213   0.842213  \n",
      "Negative             0.775362   0.736480     0.818579   0.818579  \n",
      "Neutral              0.865362   0.885748     0.845894   0.845894  \n",
      "Positive             0.817363   0.855184     0.782745   0.782745  \n",
      "Extremely Positive   0.871287   0.852300     0.891139   0.891139  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9106 (saved model)\n",
      "🌟 New best QWK: 0.9106 (saved model)\n",
      "\n",
      "EPOCH 5/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.4786, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.36it/s, Loss=0.7756, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.478602 | Accuracy: 0.892350\n",
      "Validation - Loss: 0.775602 | Accuracy: 0.800780\n",
      "Overall    - F1: 0.803924 | Precision: 0.796517 | Recall: 0.822008\n",
      "Metrics    - MAE: 0.241221 | Adjacent Acc: 0.962130 | QWK: 0.903897\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.809783   0.725649     0.915984   0.915984  \n",
      "Negative             0.738313   0.726216     0.750820   0.750820  \n",
      "Neutral              0.838253   0.881988     0.798650   0.798650  \n",
      "Positive             0.780928   0.863248     0.712941   0.712941  \n",
      "Extremely Positive   0.852345   0.785486     0.931646   0.931646  \n",
      "========================================================================================================================\n",
      "QWK: 0.9039 (best: 0.9106 at epoch 4)\n",
      "📉 QWK: 0.9039 (best: 0.9106 at epoch 4)\n",
      "\n",
      "EPOCH 6/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.4135, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.48it/s, Loss=0.7629, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.413497 | Accuracy: 0.930994\n",
      "Validation - Loss: 0.762920 | Accuracy: 0.800551\n",
      "Overall    - F1: 0.801671 | Precision: 0.794573 | Recall: 0.823985\n",
      "Metrics    - MAE: 0.232270 | Adjacent Acc: 0.970852 | QWK: 0.912700\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.803206   0.710236     0.924180   0.924180  \n",
      "Negative             0.745190   0.798750     0.698361   0.698361  \n",
      "Neutral              0.847973   0.848929     0.847019   0.847019  \n",
      "Positive             0.777633   0.869186     0.703529   0.703529  \n",
      "Extremely Positive   0.834356   0.745763     0.946835   0.946835  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9127 (saved model)\n",
      "🌟 New best QWK: 0.9127 (saved model)\n",
      "\n",
      "EPOCH 7/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.3600, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.37it/s, Loss=0.7356, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 141.0s\n",
      "Training   - Loss: 0.359955 | Accuracy: 0.951104\n",
      "Validation - Loss: 0.735606 | Accuracy: 0.836585\n",
      "Overall    - F1: 0.838869 | Precision: 0.836738 | Recall: 0.841941\n",
      "Metrics    - MAE: 0.187055 | Adjacent Acc: 0.977966 | QWK: 0.927123\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.845996   0.847737     0.844262   0.844262  \n",
      "Negative             0.794264   0.801782     0.786885   0.786885  \n",
      "Neutral              0.845777   0.820296     0.872891   0.872891  \n",
      "Positive             0.829150   0.856904     0.803137   0.803137  \n",
      "Extremely Positive   0.879162   0.856971     0.902532   0.902532  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9271 (saved model)\n",
      "🌟 New best QWK: 0.9271 (saved model)\n",
      "\n",
      "EPOCH 8/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.3255, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.46it/s, Loss=0.7107, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.325532 | Accuracy: 0.965300\n",
      "Validation - Loss: 0.710710 | Accuracy: 0.846683\n",
      "Overall    - F1: 0.848973 | Precision: 0.848399 | Recall: 0.849940\n",
      "Metrics    - MAE: 0.177416 | Adjacent Acc: 0.977048 | QWK: 0.929676\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.855087   0.857732     0.852459   0.852459  \n",
      "Negative             0.799781   0.800657     0.798907   0.798907  \n",
      "Neutral              0.851993   0.828025     0.877390   0.877390  \n",
      "Positive             0.844037   0.858766     0.829804   0.829804  \n",
      "Extremely Positive   0.893968   0.896815     0.891139   0.891139  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9297 (saved model)\n",
      "🌟 New best QWK: 0.9297 (saved model)\n",
      "\n",
      "EPOCH 9/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2806, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.48it/s, Loss=0.7890, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.8s\n",
      "Training   - Loss: 0.280617 | Accuracy: 0.985804\n",
      "Validation - Loss: 0.788966 | Accuracy: 0.832683\n",
      "Overall    - F1: 0.834753 | Precision: 0.834923 | Recall: 0.838626\n",
      "Metrics    - MAE: 0.184531 | Adjacent Acc: 0.984163 | QWK: 0.931187\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.842105   0.832000     0.852459   0.852459  \n",
      "Negative             0.783862   0.829268     0.743169   0.743169  \n",
      "Neutral              0.821721   0.754468     0.902137   0.902137  \n",
      "Positive             0.833942   0.864478     0.805490   0.805490  \n",
      "Extremely Positive   0.892132   0.894402     0.889873   0.889873  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9312 (saved model)\n",
      "🌟 New best QWK: 0.9312 (saved model)\n",
      "\n",
      "EPOCH 10/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.92it/s, Loss=0.2702, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.43it/s, Loss=0.8254, Acc=0.8\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.7s\n",
      "Training   - Loss: 0.270169 | Accuracy: 0.990142\n",
      "Validation - Loss: 0.825421 | Accuracy: 0.833831\n",
      "Overall    - F1: 0.835748 | Precision: 0.836203 | Recall: 0.840298\n",
      "Metrics    - MAE: 0.184760 | Adjacent Acc: 0.983245 | QWK: 0.930441\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.848233   0.860759     0.836066   0.836066  \n",
      "Negative             0.786790   0.837238     0.742077   0.742077  \n",
      "Neutral              0.828409   0.768269     0.898763   0.898763  \n",
      "Positive             0.831756   0.874567     0.792941   0.792941  \n",
      "Extremely Positive   0.883553   0.840183     0.931646   0.931646  \n",
      "========================================================================================================================\n",
      "QWK: 0.9304 (best: 0.9312 at epoch 9)\n",
      "📉 QWK: 0.9304 (best: 0.9312 at epoch 9)\n",
      "\n",
      "EPOCH 11/11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/391 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 391/391 [02:14<00:00,  2.91it/s, Loss=0.2604, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/69 [00:00<?, ?it/s]                              /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 69/69 [00:06<00:00, 10.35it/s, Loss=0.8196, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 140.9s\n",
      "Training   - Loss: 0.260368 | Accuracy: 0.993691\n",
      "Validation - Loss: 0.819645 | Accuracy: 0.835208\n",
      "Overall    - F1: 0.837652 | Precision: 0.837253 | Recall: 0.841681\n",
      "Metrics    - MAE: 0.183383 | Adjacent Acc: 0.983245 | QWK: 0.930705\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.850669   0.855072     0.846311   0.846311  \n",
      "Negative             0.791523   0.831528     0.755191   0.755191  \n",
      "Neutral              0.824324   0.766184     0.892013   0.892013  \n",
      "Positive             0.833402   0.871575     0.798431   0.798431  \n",
      "Extremely Positive   0.888344   0.861905     0.916456   0.916456  \n",
      "========================================================================================================================\n",
      "QWK: 0.9307 (best: 0.9312 at epoch 9)\n",
      "📉 QWK: 0.9307 (best: 0.9312 at epoch 9)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9312 (Epoch 9)\n",
      "Total Epochs: 11\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 388.30 ms per sample\n",
      "Efficiency: 134.9M params, 388.3ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_5/final_epoch_11.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_5\n",
      "📊 Trial 5 score: 0.9312 (Best: 0.9374)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>Epoch_Time</td><td>█▃▃▂▁▁▃▁▂▁▂</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>██▇▆▅▄▃▂▂▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▂▂▂▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▇▅▅▇█▇▇▇</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▃▄▅▅▆▇▇███</td></tr><tr><td>Validation F1</td><td>▁▂▆▇▅▅▇█▇▇▇</td></tr><tr><td>Validation Loss</td><td>█▆▂▁▅▄▃▂▅▆▆</td></tr><tr><td>Validation MAE</td><td>█▆▃▂▄▃▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▃▁▆▇▅▄▇█▇▇▇</td></tr><tr><td>Validation QWK</td><td>▁▄▅▇▆▇█████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇██▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>11</td></tr><tr><td>Epoch_Time</td><td>140.91291</td></tr><tr><td>Inference Time (ms)</td><td>388.2978</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99369</td></tr><tr><td>Train Loss</td><td>0.26037</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.83521</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98325</td></tr><tr><td>Validation F1</td><td>0.83765</td></tr><tr><td>Validation Loss</td><td>0.81965</td></tr><tr><td>Validation MAE</td><td>0.18338</td></tr><tr><td>Validation Precision</td><td>0.83725</td></tr><tr><td>Validation QWK</td><td>0.9307</td></tr><tr><td>Validation Recall</td><td>0.84168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_5</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/jvtgln6m' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/jvtgln6m</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_090927-jvtgln6m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 09:35:39,704] Trial 5 finished with value: 0.9311869947559468 and parameters: {'learning_rate': 0.0001751264204223623, 'batch_size': 64, 'label_smoothing': 0.05485110344469462, 'epochs': 11, 'warmup_ratio': 0.06894540809759296, 'weight_decay': 0.14145536677989268, 'attention_dropout': 0.30762801090282166, 'hidden_dropout': 0.3856199820994313}. Best is trial 2 with value: 0.9374337888939281.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_093540-n8f9hqmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/n8f9hqmr' target=\"_blank\">bertweet-base-sentiment-analysis_trial_6</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/n8f9hqmr' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/n8f9hqmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 186.13 ms\n",
      "   • Total Epochs: 10\n",
      "   • Train Batches: 782\n",
      "   • Validation Batches: 137\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 32\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.86it/s, Loss=1.1504, Acc=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.69it/s, Loss=0.9663, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.9s\n",
      "Training   - Loss: 1.150415 | Accuracy: 0.608833\n",
      "Validation - Loss: 0.966291 | Accuracy: 0.724122\n",
      "Overall    - F1: 0.733657 | Precision: 0.739450 | Recall: 0.744519\n",
      "Metrics    - MAE: 0.351159 | Adjacent Acc: 0.932522 | QWK: 0.846180\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.768254   0.794311     0.743852   0.743852  \n",
      "Negative             0.692453   0.609129     0.802186   0.802186  \n",
      "Neutral              0.792303   0.797267     0.787402   0.787402  \n",
      "Positive             0.635436   0.777526     0.537255   0.537255  \n",
      "Extremely Positive   0.779838   0.719017     0.851899   0.851899  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8462 (saved model)\n",
      "🌟 New best QWK: 0.8462 (saved model)\n",
      "\n",
      "EPOCH 2/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.89it/s, Loss=0.9057, Acc=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.91it/s, Loss=1.0087, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.0s\n",
      "Training   - Loss: 0.905717 | Accuracy: 0.772871\n",
      "Validation - Loss: 1.008705 | Accuracy: 0.739959\n",
      "Overall    - F1: 0.737829 | Precision: 0.739138 | Recall: 0.762859\n",
      "Metrics    - MAE: 0.319945 | Adjacent Acc: 0.946064 | QWK: 0.873288\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.718310   0.581013     0.940574   0.940574  \n",
      "Negative             0.598596   0.719325     0.512568   0.512568  \n",
      "Neutral              0.839521   0.897567     0.788526   0.788526  \n",
      "Positive             0.733676   0.740415     0.727059   0.727059  \n",
      "Extremely Positive   0.799043   0.757370     0.845570   0.845570  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.8733 (saved model)\n",
      "🌟 New best QWK: 0.8733 (saved model)\n",
      "\n",
      "EPOCH 3/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:39<00:00,  4.89it/s, Loss=0.8292, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.61it/s, Loss=1.0617, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 166.8s\n",
      "Training   - Loss: 0.829219 | Accuracy: 0.819401\n",
      "Validation - Loss: 1.061748 | Accuracy: 0.707826\n",
      "Overall    - F1: 0.709133 | Precision: 0.727864 | Recall: 0.752108\n",
      "Metrics    - MAE: 0.351618 | Adjacent Acc: 0.948129 | QWK: 0.871293\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.725118   0.589974     0.940574   0.940574  \n",
      "Negative             0.600692   0.818868     0.474317   0.474317  \n",
      "Neutral              0.869464   0.902056     0.839145   0.839145  \n",
      "Positive             0.614397   0.739514     0.525490   0.525490  \n",
      "Extremely Positive   0.735992   0.588906     0.981013   0.981013  \n",
      "========================================================================================================================\n",
      "QWK: 0.8713 (best: 0.8733 at epoch 2)\n",
      "📉 QWK: 0.8713 (best: 0.8733 at epoch 2)\n",
      "\n",
      "EPOCH 4/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.87it/s, Loss=0.7340, Acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.58it/s, Loss=0.8860, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.5s\n",
      "Training   - Loss: 0.733965 | Accuracy: 0.876183\n",
      "Validation - Loss: 0.885998 | Accuracy: 0.806289\n",
      "Overall    - F1: 0.802459 | Precision: 0.796466 | Recall: 0.825474\n",
      "Metrics    - MAE: 0.234336 | Adjacent Acc: 0.963277 | QWK: 0.908003\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.756713   0.627530     0.952869   0.952869  \n",
      "Negative             0.681577   0.738520     0.632787   0.632787  \n",
      "Neutral              0.874855   0.902031     0.849269   0.849269  \n",
      "Positive             0.821725   0.871592     0.777255   0.777255  \n",
      "Extremely Positive   0.877427   0.842657     0.915190   0.915190  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9080 (saved model)\n",
      "🌟 New best QWK: 0.9080 (saved model)\n",
      "\n",
      "EPOCH 5/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.6708, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.65it/s, Loss=0.8970, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.4s\n",
      "Training   - Loss: 0.670843 | Accuracy: 0.908123\n",
      "Validation - Loss: 0.897047 | Accuracy: 0.805830\n",
      "Overall    - F1: 0.812958 | Precision: 0.810568 | Recall: 0.828163\n",
      "Metrics    - MAE: 0.224237 | Adjacent Acc: 0.972917 | QWK: 0.915452\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.849751   0.825919     0.875000   0.875000  \n",
      "Negative             0.799105   0.818807     0.780328   0.780328  \n",
      "Neutral              0.857942   0.853170     0.862767   0.862767  \n",
      "Positive             0.743612   0.848241     0.661961   0.661961  \n",
      "Extremely Positive   0.814378   0.706704     0.960759   0.960759  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9155 (saved model)\n",
      "🌟 New best QWK: 0.9155 (saved model)\n",
      "\n",
      "EPOCH 6/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.6317, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.84it/s, Loss=0.8461, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.631669 | Accuracy: 0.929022\n",
      "Validation - Loss: 0.846092 | Accuracy: 0.841175\n",
      "Overall    - F1: 0.842460 | Precision: 0.839414 | Recall: 0.846451\n",
      "Metrics    - MAE: 0.182695 | Adjacent Acc: 0.977966 | QWK: 0.928264\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.842424   0.830677     0.854508   0.854508  \n",
      "Negative             0.791991   0.806342     0.778142   0.778142  \n",
      "Neutral              0.850000   0.822292     0.879640   0.879640  \n",
      "Positive             0.838579   0.863674     0.814902   0.814902  \n",
      "Extremely Positive   0.889303   0.874083     0.905063   0.905063  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9283 (saved model)\n",
      "🌟 New best QWK: 0.9283 (saved model)\n",
      "\n",
      "EPOCH 7/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.88it/s, Loss=0.5709, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:06<00:00, 19.78it/s, Loss=0.8695, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.3s\n",
      "Training   - Loss: 0.570899 | Accuracy: 0.960568\n",
      "Validation - Loss: 0.869453 | Accuracy: 0.836585\n",
      "Overall    - F1: 0.839346 | Precision: 0.836928 | Recall: 0.846866\n",
      "Metrics    - MAE: 0.185219 | Adjacent Acc: 0.980032 | QWK: 0.929439\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.856557   0.856557     0.856557   0.856557  \n",
      "Negative             0.797267   0.832342     0.765027   0.765027  \n",
      "Neutral              0.843399   0.803462     0.887514   0.887514  \n",
      "Positive             0.824070   0.881932     0.773333   0.773333  \n",
      "Extremely Positive   0.875437   0.810345     0.951899   0.951899  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9294 (saved model)\n",
      "🌟 New best QWK: 0.9294 (saved model)\n",
      "\n",
      "EPOCH 8/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.87it/s, Loss=0.5596, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.12it/s, Loss=0.8869, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.9s\n",
      "Training   - Loss: 0.559551 | Accuracy: 0.971609\n",
      "Validation - Loss: 0.886912 | Accuracy: 0.841634\n",
      "Overall    - F1: 0.844044 | Precision: 0.840657 | Recall: 0.849215\n",
      "Metrics    - MAE: 0.178793 | Adjacent Acc: 0.981409 | QWK: 0.931893\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.857430   0.840551     0.875000   0.875000  \n",
      "Negative             0.797951   0.832542     0.766120   0.766120  \n",
      "Neutral              0.838043   0.810726     0.867267   0.867267  \n",
      "Positive             0.837228   0.860812     0.814902   0.814902  \n",
      "Extremely Positive   0.889567   0.858657     0.922785   0.922785  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9319 (saved model)\n",
      "🌟 New best QWK: 0.9319 (saved model)\n",
      "\n",
      "EPOCH 9/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.86it/s, Loss=0.5323, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.29it/s, Loss=0.9077, Acc=0\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 168.1s\n",
      "Training   - Loss: 0.532274 | Accuracy: 0.983833\n",
      "Validation - Loss: 0.907674 | Accuracy: 0.836585\n",
      "Overall    - F1: 0.839674 | Precision: 0.836185 | Recall: 0.846360\n",
      "Metrics    - MAE: 0.182006 | Adjacent Acc: 0.983475 | QWK: 0.931953\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.858576   0.840864     0.877049   0.877049  \n",
      "Negative             0.799310   0.843447     0.759563   0.759563  \n",
      "Neutral              0.829844   0.793634     0.869516   0.869516  \n",
      "Positive             0.827755   0.862979     0.795294   0.795294  \n",
      "Extremely Positive   0.882883   0.840000     0.930380   0.930380  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9320 (saved model)\n",
      "🌟 New best QWK: 0.9320 (saved model)\n",
      "\n",
      "EPOCH 10/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.86it/s, Loss=0.5176, Acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.23it/s, Loss=0.9205, Acc=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 168.1s\n",
      "Training   - Loss: 0.517553 | Accuracy: 0.990536\n",
      "Validation - Loss: 0.920538 | Accuracy: 0.836814\n",
      "Overall    - F1: 0.839375 | Precision: 0.836202 | Recall: 0.845774\n",
      "Metrics    - MAE: 0.180399 | Adjacent Acc: 0.984852 | QWK: 0.933077\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.855711   0.837255     0.875000   0.875000  \n",
      "Negative             0.797695   0.843902     0.756284   0.756284  \n",
      "Neutral              0.827917   0.786437     0.874016   0.874016  \n",
      "Positive             0.832450   0.866723     0.800784   0.800784  \n",
      "Extremely Positive   0.883101   0.846690     0.922785   0.922785  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.9331 (saved model)\n",
      "🌟 New best QWK: 0.9331 (saved model)\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.9331 (Epoch 10)\n",
      "Total Epochs: 10\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 186.13 ms per sample\n",
      "Efficiency: 134.9M params, 186.1ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_6/final_epoch_10.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_6\n",
      "📊 Trial 6 score: 0.9331 (Best: 0.9374)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Epoch_Time</td><td>▇▂▁▄▄▄▃▇██</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_Rate</td><td>▆█▇▇▅▄▃▂▁▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▂▃▁▆▆█████</td></tr><tr><td>Validation Adjacent Accuracy</td><td>▁▃▃▅▆▇▇███</td></tr><tr><td>Validation F1</td><td>▂▂▁▆▆█████</td></tr><tr><td>Validation Loss</td><td>▅▆█▂▃▁▂▂▃▃</td></tr><tr><td>Validation MAE</td><td>█▇█▃▃▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▂▂▁▅▆█████</td></tr><tr><td>Validation QWK</td><td>▁▃▃▆▇█████</td></tr><tr><td>Validation Recall</td><td>▁▂▂▆▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Epoch_Time</td><td>168.10208</td></tr><tr><td>Inference Time (ms)</td><td>186.12778</td></tr><tr><td>Learning_Rate</td><td>0</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.99054</td></tr><tr><td>Train Loss</td><td>0.51755</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.83681</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98485</td></tr><tr><td>Validation F1</td><td>0.83937</td></tr><tr><td>Validation Loss</td><td>0.92054</td></tr><tr><td>Validation MAE</td><td>0.1804</td></tr><tr><td>Validation Precision</td><td>0.8362</td></tr><tr><td>Validation QWK</td><td>0.93308</td></tr><tr><td>Validation Recall</td><td>0.84577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_6</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/n8f9hqmr' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/n8f9hqmr</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_093540-n8f9hqmr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 10:03:58,027] Trial 6 finished with value: 0.9330769267275812 and parameters: {'learning_rate': 9.807792845007705e-05, 'batch_size': 32, 'label_smoothing': 0.13624623232495747, 'epochs': 10, 'warmup_ratio': 0.13181059073945012, 'weight_decay': 0.13776483349555363, 'attention_dropout': 0.32024878814457686, 'hidden_dropout': 0.3682328149056981}. Best is trial 2 with value: 0.9374337888939281.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250802_100359-opntdjr8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/opntdjr8' target=\"_blank\">bertweet-base-sentiment-analysis_trial_7</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/opntdjr8' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/opntdjr8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training Configuration:\n",
      "   • Device: cuda\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Avg Inference Time: 186.61 ms\n",
      "   • Total Epochs: 14\n",
      "   • Train Batches: 782\n",
      "   • Validation Batches: 137\n",
      "   • Learning Rate: 0.00e+00\n",
      "   • Batch Size: 32\n",
      "============================================================\n",
      "\n",
      "EPOCH 1/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:41<00:00,  4.85it/s, Loss=1.2300, Acc=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.30it/s, Loss=1.6908, Acc=0\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 168.5s\n",
      "Training   - Loss: 1.230009 | Accuracy: 0.516167\n",
      "Validation - Loss: 1.690767 | Accuracy: 0.204039\n",
      "Overall    - F1: 0.067785 | Precision: 0.040808 | Recall: 0.200000\n",
      "Metrics    - MAE: 1.089282 | Adjacent Acc: 0.706679 | QWK: 0.000000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.000000   0.000000     0.000000   0.000000  \n",
      "Negative             0.000000   0.000000     0.000000   0.000000  \n",
      "Neutral              0.338925   0.204039     1.000000   1.000000  \n",
      "Positive             0.000000   0.000000     0.000000   0.000000  \n",
      "Extremely Positive   0.000000   0.000000     0.000000   0.000000  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.0000 (saved model)\n",
      "🌟 New best QWK: 0.0000 (saved model)\n",
      "\n",
      "EPOCH 2/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.87it/s, Loss=1.6168, Acc=0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 19.07it/s, Loss=1.6149, Acc=0\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipython-input-3553570516.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.9s\n",
      "Training   - Loss: 1.616829 | Accuracy: 0.206230\n",
      "Validation - Loss: 1.614862 | Accuracy: 0.210007\n",
      "Overall    - F1: 0.069423 | Precision: 0.042001 | Recall: 0.200000\n",
      "Metrics    - MAE: 1.445261 | Adjacent Acc: 0.526050 | QWK: 0.000000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.000000   0.000000     0.000000   0.000000  \n",
      "Negative             0.347117   0.210007     1.000000   1.000000  \n",
      "Neutral              0.000000   0.000000     0.000000   0.000000  \n",
      "Positive             0.000000   0.000000     0.000000   0.000000  \n",
      "Extremely Positive   0.000000   0.000000     0.000000   0.000000  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.0000 (saved model)\n",
      "🌟 New best QWK: 0.0000 (saved model)\n",
      "\n",
      "EPOCH 3/14\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                              | 0/782 [00:00<?, ?it/s]                               /tmp/ipython-input-3553570516.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training: 100%|██████████████████████████████| 782/782 [02:40<00:00,  4.87it/s, Loss=1.6100, Acc=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Validation Phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                              | 0/137 [00:00<?, ?it/s]                             /tmp/ipython-input-3553570516.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████| 137/137 [00:07<00:00, 18.92it/s, Loss=1.6061, Acc=0\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 DETAILED SUMMARY\n",
      "========================================================================================================================\n",
      "Epoch Time: 167.8s\n",
      "Training   - Loss: 1.610007 | Accuracy: 0.199132\n",
      "Validation - Loss: 1.606133 | Accuracy: 0.181317\n",
      "Overall    - F1: 0.061395 | Precision: 0.036263 | Recall: 0.200000\n",
      "Metrics    - MAE: 1.778747 | Adjacent Acc: 0.473950 | QWK: 0.000000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "PER-CLASS BREAKDOWN:\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Class                F1         Precision    Recall     Accuracy  \n",
      "─────────────────────────────────────────────────────────────────\n",
      "Extremely Negative   0.000000   0.000000     0.000000   0.000000  \n",
      "Negative             0.000000   0.000000     0.000000   0.000000  \n",
      "Neutral              0.000000   0.000000     0.000000   0.000000  \n",
      "Positive             0.000000   0.000000     0.000000   0.000000  \n",
      "Extremely Positive   0.306975   0.181317     1.000000   1.000000  \n",
      "========================================================================================================================\n",
      "New best QWK: 0.0000 (saved model)\n",
      "🌟 New best QWK: 0.0000 (saved model)\n",
      "\n",
      "⏹️  EARLY STOPPING triggered at epoch 3\n",
      "    No improvement in QWK for 2 epochs\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best QWK: 0.0000 (Epoch 0)\n",
      "Total Epochs: 3\n",
      "Model Size: 514.62 MB\n",
      "Parameters: 134,903,813 total, 134,903,813 trainable\n",
      "Inference Time: 186.61 ms per sample\n",
      "Efficiency: 134.9M params, 186.6ms\n",
      "============================================================\n",
      "✅ Trial checkpoint saved: ./checkpoints_bert/trial_7/final_epoch_14.ckpt\n",
      "✅ Model files saved in: ./checkpoints_bert/trial_7\n",
      "📊 Trial 7 score: 0.0000 (Best: 0.9374)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Epoch_Time</td><td>█▂▁</td></tr><tr><td>Inference Time (ms)</td><td>▁▁▁</td></tr><tr><td>Learning_Rate</td><td>█▆▁</td></tr><tr><td>Model Size (MB)</td><td>▁▁▁</td></tr><tr><td>Parameters per MB</td><td>▁▁▁</td></tr><tr><td>Total Parameters</td><td>▁▁▁</td></tr><tr><td>Train Accuracy</td><td>█▁▁</td></tr><tr><td>Train Loss</td><td>▁██</td></tr><tr><td>Trainable Parameters</td><td>▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▇█▁</td></tr><tr><td>Validation Adjacent Accuracy</td><td>█▃▁</td></tr><tr><td>Validation F1</td><td>▇█▁</td></tr><tr><td>Validation Loss</td><td>█▂▁</td></tr><tr><td>Validation MAE</td><td>▁▅█</td></tr><tr><td>Validation Precision</td><td>▇█▁</td></tr><tr><td>Validation QWK</td><td>▁▁▁</td></tr><tr><td>Validation Recall</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Epoch_Time</td><td>167.79392</td></tr><tr><td>Inference Time (ms)</td><td>186.60998</td></tr><tr><td>Learning_Rate</td><td>0.00025</td></tr><tr><td>Model Size (MB)</td><td>514.61919</td></tr><tr><td>Parameters per MB</td><td>262142.98954</td></tr><tr><td>Total Parameters</td><td>134903813</td></tr><tr><td>Train Accuracy</td><td>0.19913</td></tr><tr><td>Train Loss</td><td>1.61001</td></tr><tr><td>Trainable Parameters</td><td>134903813</td></tr><tr><td>Validation Accuracy</td><td>0.18132</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.47395</td></tr><tr><td>Validation F1</td><td>0.06139</td></tr><tr><td>Validation Loss</td><td>1.60613</td></tr><tr><td>Validation MAE</td><td>1.77875</td></tr><tr><td>Validation Precision</td><td>0.03626</td></tr><tr><td>Validation QWK</td><td>0</td></tr><tr><td>Validation Recall</td><td>0.2</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-base-sentiment-analysis_trial_7</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/opntdjr8' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert/runs/opntdjr8</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/sentiment-full-bert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250802_100359-opntdjr8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 10:13:03,133] Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.00026574850668784197, 'batch_size': 32, 'label_smoothing': 0.06787121957757655, 'epochs': 14, 'warmup_ratio': 0.06075050223656639, 'weight_decay': 0.09584107484292885, 'attention_dropout': 0.3194849590481659, 'hidden_dropout': 0.37464253933405495}. Best is trial 2 with value: 0.9374337888939281.\n"
     ]
    }
   ],
   "source": [
    "global_best_qwk = 0.0\n",
    "global_best_model_state = None\n",
    "\n",
    "print(f\"Initialized global_best_qwk: {global_best_qwk}\")\n",
    "print(f\"Initialized global_best_model_state: {global_best_model_state}\")\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720d326",
   "metadata": {
    "id": "e720d326"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e6d36f",
   "metadata": {
    "id": "95e6d36f"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device=None):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            device = next(model.parameters()).device  # Get model's device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    results = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'macro_f1': f1_score(y_true, y_pred, average='macro'),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro'),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro'),\n",
    "        'weighted_f1': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'adjacent_accuracy': np.sum(np.abs(y_pred - y_true) <= 1) / len(y_true),\n",
    "        'qwk': cohen_kappa_score(y_true, y_pred, weights='quadratic'),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
    "        'classification_report': classification_report(y_true, y_pred,\n",
    "                                                     target_names=list(ordinal_id2label.values()),\n",
    "                                                     labels=list(ordinal_id2label.keys()))\n",
    "    }\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Macro F1: {results['macro_f1']:.4f}\")\n",
    "    print(f\"precision: {results['precision']:.4f}\")\n",
    "    print(f\"recall: {results['recall']:.4f}\")\n",
    "    print(f\"weighted_f1: {results['weighted_f1']:.4f}\")\n",
    "    print(f\"MAE: {results['mae']:.4f}\")\n",
    "    print(f\"Adjacent Accuracy: {results['adjacent_accuracy']:.4f}\")\n",
    "    print(f\"qwk: {results['qwk']:.4f}\")\n",
    "    print(f\"\\nClassification Report:\\n{results['classification_report']}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dbd13ee",
   "metadata": {
    "id": "7dbd13ee"
   },
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # existing confusion matrix\n",
    "    sns.heatmap(results['confusion_matrix'], annot=True, fmt='d',\n",
    "                xticklabels=list(ordinal_id2label.values()),  # use ordinal_id2label\n",
    "                yticklabels=list(ordinal_id2label.values()), ax=ax1)  # use ordinal_id2label\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "\n",
    "    # existing metrics bar chart\n",
    "    metrics = ['Accuracy', 'Macro F1', 'Precision', 'Recall', 'Adjacent Accuracy', 'QWK', 'MAE']\n",
    "    values = [results['accuracy'], results['macro_f1'], results['precision'], results['recall'],\n",
    "              results['adjacent_accuracy'], results['qwk'], results['mae']]\n",
    "    ax2.bar(metrics, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    ax2.set_title('Key Metrics')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4ce0aa2",
   "metadata": {
    "id": "f4ce0aa2"
   },
   "outputs": [],
   "source": [
    "from torch.serialization import safe_globals\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "def quick_eval_manual(model_path, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if model_path == 'best_model_optuna.pt':\n",
    "        model_path = './best_bert_model_so_far/model_bert.pt'\n",
    "\n",
    "    # Use the safe_globals context manager\n",
    "    with safe_globals({RobertaForSequenceClassification}):\n",
    "        model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "    model.to(device)\n",
    "    results = evaluate_model(model, test_loader, device)\n",
    "    plot_results(results)\n",
    "    return results\n",
    "\n",
    "def quick_eval_auto(model_path, study, formatted_test, tokenizer, id2label):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    optimal_batch_size = study.best_params['batch_size']\n",
    "    max_length = study.best_params.get('max_length', 128)  # Get from study if available\n",
    "    test_dataset = TweetDataset(formatted_test, tokenizer, max_length=max_length)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=optimal_batch_size, shuffle=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=5, id2label=ordinal_id2label, label2id=ordinal_label2id)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    results = evaluate_model(model, test_loader,  device)\n",
    "    plot_results(results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fe776-c77f-4604-b06b-fb0f3e12f494",
   "metadata": {},
   "source": [
    "### Final Testing with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc934864",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 934
    },
    "id": "cc934864",
    "outputId": "31e49a6d-fa29-4422-be86-8a1d6d2a1155"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8423\n",
      "Macro F1: 0.8453\n",
      "precision: 0.8393\n",
      "recall: 0.8573\n",
      "weighted_f1: 0.8414\n",
      "MAE: 0.1790\n",
      "Adjacent Accuracy: 0.9810\n",
      "qwk: 0.9330\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.80      0.91      0.85       410\n",
      "          Negative       0.88      0.77      0.82       813\n",
      "           Neutral       0.79      0.91      0.85       659\n",
      "          Positive       0.87      0.79      0.83       954\n",
      "Extremely Positive       0.85      0.91      0.88       588\n",
      "\n",
      "          accuracy                           0.84      3424\n",
      "         macro avg       0.84      0.86      0.85      3424\n",
      "      weighted avg       0.85      0.84      0.84      3424\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHpCAYAAABTH4/7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA4aNJREFUeJzs3Xl8TGf7x/HPRPaQWJPY9yL2pSX2EkIttZba1VJKW5QSWiJaQWuv0qKWlqe6obXv1FJr1Vo7sWSxJiIkkZnfH36mnSY0IjKj830/r/N6Ze5znftc5zzpZFxz3/cxmEwmEyIiIiIiIiIiIhnIwdoJiIiIiIiIiIiI/VFRSkREREREREREMpyKUiIiIiIiIiIikuFUlBIRERERERERkQynopSIiIiIiIiIiGQ4FaVERERERERERCTDqSglIiIiIiIiIiIZTkUpERERERERERHJcCpKiYiIiIiIiIhIhlNRSkTszqlTp2jYsCFeXl4YDAaWLVuWrv2fP38eg8HA/Pnz07Xf51ndunWpW7eutdMQERERwWAwEBwcbO00RAQVpUTESs6cOcObb75JkSJFcHV1xdPTkxo1ajB16lTu3r37TM/dtWtXDh8+zMcff8zXX39NlSpVnun5MlK3bt0wGAx4enqmeB9PnTqFwWDAYDDw6aefPnH/V65cITg4mIMHD6ZDtiIiIpKe5s+fj8FgYN++fRbt0dHRvPTSS7i6urJmzZoMy+fhZ46ePXumuH/EiBHmmGvXrj1x/zt37iQ4OJhbt249ZaYiYi2O1k5AROzPypUradu2LS4uLnTp0oUyZcqQkJDA9u3bGTJkCEePHuXLL798Jue+e/cuu3btYsSIEfTv3/+ZnKNgwYLcvXsXJyenZ9L/v3F0dCQuLo5ffvmF1157zWLfokWLcHV15d69e2nq+8qVK4wePZpChQpRoUKFVB+3bt26NJ1PREREnk5MTAwNGzbk0KFDLF26lEaNGmXo+V1dXfnxxx/5/PPPcXZ2ttj3v//976k+l+zcuZPRo0fTrVs3smbNmurj7t69i6Oj/iksYgs0UkpEMtS5c+do3749BQsW5NixY0ydOpVevXrRr18//ve//3Hs2DFKly79zM5/9epVgCf64PKkDAYDrq6uZMqU6Zmd43FcXFyoX78+//vf/5LtW7x4MU2aNMmwXOLi4gBwdnZO9kFUREREnq3bt28TGBjIwYMH+fHHH2ncuHGG59CoUSNiYmJYvXq1RfvOnTs5d+5chn0uMRqN5uKXq6urilIiNkJFKRHJUBMmTCA2Npa5c+eSO3fuZPuLFSvGu+++a359//59xowZQ9GiRXFxcaFQoUIMHz6c+Ph4i+MKFSpE06ZN2b59u3l4epEiRVi4cKE5Jjg4mIIFCwIwZMgQDAYDhQoVAh5Me3v4898FBwdjMBgs2tavX0/NmjXJmjUrmTNnpkSJEgwfPty8/1FrSm3atIlatWrh4eFB1qxZefXVVzl+/HiK5zt9+rT5Wz8vLy+6d+9uLvCkRocOHVi9erXFcPa9e/dy6tQpOnTokCz+xo0bDB48mLJly5I5c2Y8PT1p3Lgxf/zxhzlmy5YtvPjiiwB0797dPNz+4XXWrVuXMmXKsH//fmrXro27u7v5vvxzTamuXbvi6uqa7PoDAwPJli0bV65cSfW1ioiISHKxsbE0atSIAwcO8OOPPyYr/ly+fJk33ngDHx8fXFxcKF26NF999ZXF8R4eHhafyx66dOkSmTJlIjQ09F/zyJs3L7Vr12bx4sUW7YsWLaJs2bKUKVMmxeN2795No0aN8PLywt3dnTp16rBjxw7z/uDgYIYMGQJA4cKFzZ9Lzp8/Dzz4krB///4sWrSI0qVL4+LiYp66mNKaUpcvX6ZHjx7kyZMHFxcXChcuTN++fUlISAAgMTGR0aNHU7x4cVxdXcmRIwc1a9Zk/fr1/3oPROTRVB4WkQz1yy+/UKRIEapXr56q+J49e7JgwQLatGnDe++9x+7duwkNDeX48eMsXbrUIvb06dO0adOGHj160LVrV7766iu6detG5cqVKV26NK1atSJr1qwMHDiQ119/nVdeeYXMmTM/Uf5Hjx6ladOmlCtXjpCQEFxcXDh9+rTFh6SUbNiwgcaNG1OkSBGCg4O5e/cu06dPp0aNGhw4cCBZQey1116jcOHChIaGcuDAAebMmYO3tzfjx49PVZ6tWrWiT58+/PTTT7zxxhvAg1FSJUuWpFKlSsniz549y7Jly2jbti2FCxcmMjKSL774gjp16nDs2DHy5MlDqVKlCAkJYeTIkfTu3ZtatWoBWPx/ef36dRo3bkz79u3p1KkTPj4+KeY3depUNm3aRNeuXdm1axeZMmXiiy++YN26dXz99dfkyZMnVdcpIiIiyd25c4fGjRuzd+9efvjhB5o2bWqxPzIykmrVqpkLN7ly5WL16tX06NGDmJgYBgwYQObMmWnZsiVLlixh0qRJFiPA//e//2EymejYsWOq8unQoQPvvvsusbGxZM6cmfv37/P9998zaNCgFKfubdq0icaNG1O5cmVGjRqFg4MD8+bNo169evz666+89NJLtGrVipMnT/K///2PyZMnkzNnTgBy5cpl0c93331H//79yZkzZ4pfQMKD5Qleeuklbt26Re/evSlZsiSXL1/mhx9+IC4uDmdnZ4KDgwkNDaVnz5689NJLxMTEsG/fPg4cOECDBg1SdR9EJAUmEZEMEh0dbQJMr776aqriDx48aAJMPXv2tGgfPHiwCTBt2rTJ3FawYEETYNq2bZu5LSoqyuTi4mJ67733zG3nzp0zAaZPPvnEos+uXbuaChYsmCyHUaNGmf7+Vjl58mQTYLp69eoj8354jnnz5pnbKlSoYPL29jZdv37d3PbHH3+YHBwcTF26dEl2vjfeeMOiz5YtW5py5MjxyHP+/To8PDxMJpPJ1KZNG1P9+vVNJpPJlJSUZPL19TWNHj06xXtw7949U1JSUrLrcHFxMYWEhJjb9u7dm+zaHqpTp44JMM2aNSvFfXXq1LFoW7t2rQkwffTRR6azZ8+aMmfObGrRosW/XqOIiIikbN68eSbAVLBgQZOTk5Np2bJlKcb16NHDlDt3btO1a9cs2tu3b2/y8vIyxcXFmUymv/5Wr1692iKuXLlyyf6upwQw9evXz3Tjxg2Ts7Oz6euvvzaZTCbTypUrTQaDwXT+/HnzZ5+Hn62MRqOpePHipsDAQJPRaDT3FRcXZypcuLCpQYMG5rZPPvnEBJjOnTuX4rkdHBxMR48eTXHfqFGjzK+7dOlicnBwMO3duzdZ7MMcypcvb2rSpMm/XrOIPBlN3xORDBMTEwNAlixZUhW/atUqAAYNGmTR/t577wEPFkz/Oz8/P/PoHXjwTVmJEiU4e/ZsmnP+p4drUS1fvhyj0ZiqY8LDwzl48CDdunUje/bs5vZy5crRoEED83X+XZ8+fSxe16pVi+vXr5vvYWp06NCBLVu2EBERwaZNm4iIiEhx6h48WIfKweHBn4SkpCSuX79unpp44MCBVJ/TxcWF7t27pyq2YcOGvPnmm4SEhNCqVStcXV354osvUn0uERERSVlkZCSurq7kz58/2T6TycSPP/5Is2bNMJlMXLt2zbwFBgYSHR1t/tsfEBBAnjx5WLRokfn4I0eOcOjQITp16pTqfLJly0ajRo3M610uXryY6tWrm5dV+LuDBw+alxu4fv26Obc7d+5Qv359tm3blurPYHXq1MHPz++xMUajkWXLltGsWbMUn8j8cBmHrFmzcvToUU6dOpWqc4tI6qgoJSIZxtPTE3iw6GZqXLhwAQcHB4oVK2bR7uvrS9asWblw4YJFe4ECBZL1kS1bNm7evJnGjJNr164dNWrUoGfPnvj4+NC+fXu+++67x344ephniRIlku0rVaqU+YPW3/3zWrJlywbwRNfyyiuvkCVLFpYsWcKiRYt48cUXk93Lh4xGI5MnT6Z48eK4uLiQM2dOcuXKxaFDh4iOjk71OfPmzftEC5p/+umnZM+enYMHDzJt2jS8vb1TfayIiIik7IsvvsDZ2ZlGjRpx4sQJi31Xr17l1q1bfPnll+TKlctie/jFUlRUFAAODg507NiRZcuWmde2fPgk37Zt2z5RTh06dGD9+vWEhYWxbNmyR35R9rDo07Vr12T5zZkzh/j4+FR/NilcuPC/xly9epWYmJhHrm31UEhICLdu3eKFF16gbNmyDBkyhEOHDqUqDxF5NK0pJSIZxtPTkzx58nDkyJEnOu6fC40/yqOedmcymdJ8jqSkJIvXbm5ubNu2jc2bN7Ny5UrWrFnDkiVLqFevHuvWrUu3J+49zbU85OLiQqtWrViwYAFnz55NtqDn340dO5YPP/yQN954gzFjxpA9e3YcHBwYMGBAqr+NhAf350n8/vvv5g++hw8f5vXXX3+i40VERCQ5Pz8/Vq1aRf369WnQoAE7duwwj5p6+He9U6dOdO3aNcXjy5UrZ/65S5cufPLJJyxbtozXX3+dxYsX07RpU7y8vJ4op+bNm+Pi4kLXrl2Jj4/ntddeSzHuYX6ffPIJFSpUSDEmtWuCPunnksepXbs2Z86cYfny5axbt445c+YwefJkZs2aRc+ePdPtPCL2RkUpEclQTZs25csvv2TXrl34+/s/NrZgwYIYjUZOnTpFqVKlzO2RkZHcunUrxSHfaZUtWzaLJ9U99M/RWPDgW8P69etTv359Jk2axNixYxkxYgSbN28mICAgxesAkn1TCfDnn3+SM2dOPDw8nv4iUtChQwe++uorHBwcaN++/SPjfvjhB15++WXmzp1r0X7r1i3zwqGQ+gJhaty5c4fu3bvj5+dH9erVmTBhAi1btjQ/4U9ERETS7qWXXmLZsmU0adKEBg0a8Ouvv5pHHGXJkoWkpKQUP7f8U5kyZahYsSKLFi0iX758hIWFMX369CfOx83NjRYtWvDNN9/QuHFji88Xf1e0aFHgwZeZ/5ZfenwuyZUrF56enqn60jR79ux0796d7t27ExsbS+3atQkODlZRSuQpaPqeiGSo999/Hw8PD3r27ElkZGSy/WfOnGHq1KnAg+lnAFOmTLGImTRpEkCyRxs/jaJFixIdHW0xDDs8PDzZE/5u3LiR7NiH3+LFx8en2Hfu3LmpUKECCxYssCh8HTlyhHXr1pmv81l4+eWXGTNmDJ999hm+vr6PjMuUKVOyUVjff/89ly9ftmh7WDxLqYD3pIYOHUpYWBgLFixg0qRJFCpUyPztqYiIiDy9+vXr87///Y/Tp0/TqFEjYmJiyJQpE61bt+bHH39MsRBz9erVZG2dO3dm3bp1TJkyhRw5ctC4ceM05TN48GBGjRrFhx9++MiYypUrU7RoUT799FNiY2Mfm196fC5xcHCgRYsW/PLLL+zbty/Z/oefj65fv27RnjlzZooVK6bPLSJPSSOlRCRDFS1alMWLF9OuXTtKlSpFly5dKFOmDAkJCezcuZPvv/+ebt26AVC+fHm6du3Kl19+ya1bt6hTpw579uxhwYIFtGjRgpdffjnd8mrfvj1Dhw6lZcuWvPPOO8TFxTFz5kxeeOEFi4W+Q0JC2LZtG02aNKFgwYJERUXx+eefky9fPmrWrPnI/j/55BMaN26Mv78/PXr04O7du0yfPh0vL6/HTqt7Wg4ODnzwwQf/Gte0aVNCQkLo3r071atX5/DhwyxatIgiRYpYxBUtWpSsWbMya9YssmTJgoeHB1WrVk3Vmg1/t2nTJj7//HNGjRpFpUqVAJg3bx5169blww8/ZMKECU/Un4iIiKSsZcuWzJ49mzfeeIPmzZuzZs0axo0bx+bNm6latSq9evXCz8+PGzducODAATZs2JDsS7gOHTrw/vvvs3TpUvr27YuTk1Oacilfvjzly5d/bIyDgwNz5syhcePGlC5dmu7du5M3b14uX77M5s2b8fT05JdffgEeFLAARowYQfv27XFycqJZs2ZPPAJ97NixrFu3jjp16tC7d29KlSpFeHg433//Pdu3bydr1qz4+flRt25dKleuTPbs2dm3bx8//PAD/fv3T9O9EJEHVJQSkQzXvHlzDh06xCeffMLy5cuZOXMmLi4ulCtXjokTJ9KrVy9z7Jw5cyhSpAjz589n6dKl+Pr6EhQUxKhRo9I1pxw5crB06VIGDRrE+++/T+HChQkNDeXUqVMWRanmzZtz/vx5vvrqK65du0bOnDmpU6cOo0ePfuzaCgEBAaxZs4ZRo0YxcuRInJycqFOnDuPHj3/igs6zMHz4cO7cucPixYtZsmQJlSpVYuXKlQwbNswizsnJiQULFhAUFESfPn24f/8+8+bNe6JruH37Nm+88QYVK1ZkxIgR5vZatWrx7rvvMnHiRFq1akW1atXS7fpERETsWffu3blx4waDBw+mbdu2LF26lD179hASEsJPP/3E559/To4cOShdujTjx49PdryPjw8NGzZk1apVdO7c+ZnnW7duXXbt2mUe7R0bG4uvry9Vq1blzTffNMe9+OKLjBkzhlmzZrFmzRqMRiPnzp174qJU3rx52b17Nx9++CGLFi0iJiaGvHnz0rhxY9zd3QF45513+Pnnn1m3bh3x8fEULFiQjz76iCFDhqTrtYvYG4PpSVbNFREREREREbvTsmVLDh8+zOnTp62dioj8h2hNKREREREREXmk8PBwVq5cmSGjpETEvmj6noiIiIiIiCRz7tw5duzYwZw5c3BycrKYOicikh40UkpERERERESS2bp1K507d+bcuXMsWLDgsU/yFRFJCxWlRERERCRNtm3bRrNmzciTJw8Gg4Fly5b96zFbtmyhUqVKuLi4UKxYMebPn//M8xSRtOnWrRsmk4kLFy7Qpk0ba6cjIv9BKkqJiIiISJrcuXOH8uXLM2PGjFTFnzt3jiZNmvDyyy9z8OBBBgwYQM+ePVm7du0zzlRERERskZ6+JyIiIiJPzWAwsHTpUlq0aPHImKFDh7Jy5UqOHDlibmvfvj23bt1izZo1KR4THx9PfHy8+bXRaOTGjRvkyJEDg8GQbvmLiIhI+jGZTNy+fZs8efLg4PDo8VBa6Fwy3O48raydwnOr8e3D1k7huRUTH2ftFEQkle4nXH6m/SdeO5vmY51yFknHTOzPrl27CAgIsGgLDAxkwIABjzwmNDSU0aNHP+PMRERE5Fm4ePEi+fLle+R+FaVEREREJENERETg4+Nj0ebj40NMTAx3797Fzc0t2TFBQUEMGjTI/Do6OpoCBQpw8eJFPD09n3nOIiIi8uRiYmLInz8/WbJkeWycilIiIiJiX4xJ1s5AnoCLiwsuLi7J2j09PVWUEhERsXH/NtVeRSkRERGxLyajtTOwW76+vkRGRlq0RUZG4unpmeIoKREREflvU1FKRERE7ItRRSlr8ff3Z9WqVRZt69evx9/f30oZiYiIiDU9egl0ERERkf8gk8mY5k0sxcbGcvDgQQ4ePAjAuXPnOHjwIGFhYcCD9aC6dOliju/Tpw9nz57l/fff588//+Tzzz/nu+++Y+DAgdZIX0RERKxMI6VERETEvmikVLrZt28fL7/8svn1wwXJu3btyvz58wkPDzcXqAAKFy7MypUrGThwIFOnTiVfvnzMmTOHwMDADM9dRCTV+ve3dgbp77PPrJ2BCKCilIiIiNgbjXhKN3Xr1sVkMj1y//z581M85vfff3+GWYmIiMjzQtP3REREREREREQkw2mklIiIiNgXY5K1MxARERERVJQSERERe6PpeyIiIiI2QUUpERERsS9a6FxERETEJqgoJSIiInbFpJFSIiIiIjZBRSkRERGxLxopJSIiImITVJQSERER+6KRUiIiIiI2wcHaCYiIiIiIiIiIiP3RSCkRERGxL8Yka2cgIiIiIqgoJSIiIvZG0/dEREREbIKm74mIiIh9MRrTvj2BQoUKYTAYkm39+vUD4N69e/Tr148cOXKQOXNmWrduTWRkpEUfYWFhNGnSBHd3d7y9vRkyZAj3799Pt1shIiIiYk0aKSUiIiL2JYNGSu3du5ekpL+mCh45coQGDRrQtm1bAAYOHMjKlSv5/vvv8fLyon///rRq1YodO3YAkJSURJMmTfD19WXnzp2Eh4fTpUsXnJycGDt2bIZcg4iIiMizpKKUiIiI2JcnHPGUVrly5bJ4PW7cOIoWLUqdOnWIjo5m7ty5LF68mHr16gEwb948SpUqxW+//Ua1atVYt24dx44dY8OGDfj4+FChQgXGjBnD0KFDCQ4OxtnZOUOuQ0REBODVAzusnUK6W16phrVTsHuaviciIiJ2xWRKSvMWHx9PTEyMxRYfH/+v50xISOCbb77hjTfewGAwsH//fhITEwkICDDHlCxZkgIFCrBr1y4Adu3aRdmyZfHx8THHBAYGEhMTw9GjR9P/xoiIiIhkMBWlRERERFIpNDQULy8viy00NPRfj1u2bBm3bt2iW7duAERERODs7EzWrFkt4nx8fIiIiDDH/L0g9XD/w30iIiIizztN3xMRERH78hRrSgUFBTFo0CCLNhcXl389bu7cuTRu3Jg8efKk+dwiIiIi/zUaKZWCLVu2YDAYuHXrlrVTeeYKFSrElClTrJ2GiIhIxnmKp++5uLjg6elpsf1bUerChQts2LCBnj17mtt8fX1JSEhI9lkjMjISX19fc8w/n8b38PXDGBEREZHn2RMVpbp165bio40bNWqU6j7q1q3LgAEDnjTP587DezVu3DiL9mXLlmEwGDI8n/nz5yebIgAPngzUu3fvDM8nI3l3CaTshklUOfENVU58g9/PoXi9XBEA53y5qHrlpxS37E39k/XlmC0zFffNpuqVn8jk6Z7Rl2J13Xt04Nddv3Dh8u9cuPw7azd+R0CD2inGfvfjHG7cPsUrTQNS3G/vatWsyrKl8wk7v5/7CZdp3jzQ2ik9N3Tvnk7fPl05ffI3YmPOsHP7L7xYpYK1U8p4JmPatzSYN28e3t7eNGnSxNxWuXJlnJyc2Lhxo7ntxIkThIWF4e//4O+Pv78/hw8fJioqyhyzfv16PD098fPzS+PFi4iIiNiOJ56+16hRI+bNm2fRlpph60/CZDKRlJSEo+PzPbvQ1dWV8ePH8+abb5ItWzZrp5Oifz4Z6L8oIfw6YWO/4d65cAwGyNn2ZV6YN4wjDQdz9/RlDpR/wyLeu1MDcvdtwa1Nvyfrq/DEfsQdP49znhwZlb5NuXIlgtGjPuXsmfMYDAbad2jJN9/OpG6NV/nzz9PmuL79umEymayYqe3z8HDn0KFjzJv/LT9+P9fa6TxXdO/Srm3b5nz6ySje6jeMPXt/5523e7Jq5SL8ytTm6tXr1k4v4xiTMu5URiPz5s2ja9euFp9rvLy86NGjB4MGDSJ79ux4enry9ttv4+/vT7Vq1QBo2LAhfn5+dO7cmQkTJhAREcEHH3xAv3790v2zl4iIiIg1PPH0PRcXF3x9fS22hwWXLVu24OzszK+//mqOnzBhAt7e3kRGRtKtWze2bt3K1KlTzaOszp8/b54ut3r1aipXroyLiwvbt2/HaDQSGhpK4cKFcXNzo3z58vzwww/mvh8et3btWipWrIibmxv16tUjKiqK1atXU6pUKTw9PenQoQNxcXHm4/6t37+7c+cOnp6eyfYvW7YMDw8Pbt++/ch7FRAQgK+v778ugLp9+3Zq1aqFm5sb+fPn55133uHOnTvm/eHh4TRp0gQ3NzcKFy7M4sWLk027mzRpEmXLlsXDw4P8+fPz1ltvERsba75P3bt3Jzo62nzfg4ODAcvpex06dKBdu3YWuSUmJpIzZ04WLlz4xPfOVtxav4/oTQeIPxfOvbPhXBq/GOOde2Su/AIYjSRevWWxZWtcleu/7MAYd8+iH+8ugTh6ehA+a7mVrsT61q7exIZ1Wzl75gJnTp/n45DJ3ImNo8pLFcwxZcqWot/bPXj7rSDrJfocWLN2MyNHTWD58jXWTuW5o3uXdgPf7cWcuYtZsPA7jh8/xVv9hhEXd5fu3dpbO7WMlYEjpTZs2EBYWBhvvPFGsn2TJ0+madOmtG7dmtq1a+Pr68tPP/1k3p8pUyZWrFhBpkyZ8Pf3p1OnTnTp0oWQkJCnunwRERERW5Gua0o9nJrXuXNnoqOj+f333/nwww+ZM2cOPj4+TJ06FX9/f3r16kV4eDjh4eHkz5/ffPywYcMYN24cx48fp1y5coSGhrJw4UJmzZrF0aNHGThwIJ06dWLr1q0W5w0ODuazzz5j586dXLx4kddee40pU6awePFiVq5cybp165g+fbo5PrX9Anh4eNC+fftko8PmzZtHmzZtyJIlyyPvR6ZMmRg7dizTp0/n0qVLKcacOXOGRo0a0bp1aw4dOsSSJUvYvn07/fv3N8d06dKFK1eusGXLFn788Ue+/PJLi6H8AA4ODkybNo2jR4+yYMECNm3axPvvvw9A9erVmTJlCp6enub7Pnjw4GS5dOzYkV9++cVczAJYu3YtcXFxtGzZ8onvnU1ycCD7qzVwcHcldt+JZLvdyxbBo0wRrv5vo0W7W/F85B34GmfenYbJqBFA8OB3rlXrJrh7uLN390EA3Nxcmf3VJIa8F0xU1DXrJigiFpycnKhUqRwbN/31xZHJZGLjpu1Uq1bZipn9tzVs2BCTycQLL7yQbJ+rqyszZszgxo0b3Llzh59++inZWlEFCxZk1apVxMXFcfXqVT799NPnfiS5iIiIyENP/KlmxYoVZM6c2aJt+PDhDB8+HICPPvqI9evX07t3b44cOULXrl1p3rw58GCourOzM+7u7iku0BkSEkKDBg0AiI+PZ+zYsWzYsMG8tkKRIkXYvn07X3zxBXXq1DEf99FHH1GjRg0AevToQVBQEGfOnKFIkSIAtGnThs2bNzN06NAn6vehnj17Ur16dcLDw8mdOzdRUVGsWrWKDRs2/Ov9atmyJRUqVGDUqFHMnZt8mkloaCgdO3Y0r7NVvHhxpk2bRp06dZg5cybnz59nw4YN7N27lypVqgAwZ84cihcvbtHP39fpKlSoEB999BF9+vTh888/x9nZGS8vLwwGw2MXRg0MDMTDw4OlS5fSuXNnABYvXkzz5s3JkiVLmu5dfHw88fHxFm0JpiScDZn+9d6lJ7eSBSj9SygOLs4k3bnHyR7juXsqeaHQ+/UA7p68aFGwMjg7UvTzQYSNWUDC5Wu4FPBJdpw9KeX3Ams3foerqwt3YuPo3OEtTpx4MHXv43Ej2LP7AKtXbvyXXkQko+XMmR1HR0eiIi0LxlFRVylZoqiVsrISY9qfviciIiIi6eeJi1Ivv/wyM2fOtGjLnj27+WdnZ2cWLVpEuXLlKFiwIJMnT0513w+LLgCnT58mLi7OXKR6KCEhgYoVK1q0lStXzvyzj48P7u7u5oLUw7Y9e/Y8cb8PvfTSS5QuXZoFCxYwbNgwvvnmGwoWLEjt2ikv8PxP48ePp169eimOTvrjjz84dOgQixYtMreZTCaMRiPnzp3j5MmTODo6UqlSJfP+YsWKJVujasOGDYSGhvLnn38SExPD/fv3uXfvHnFxcbi7p25BbkdHR1577TUWLVpE586duXPnDsuXL+fbb78F0nbvQkNDGT16tEVbj8wl6ZWlVKpySi/3zlzhcIP3yJTFnRxN/Sk69W2Ot/rQojBlcHUmR8taXJ7yvcWx+YM6ce/0Ja7/tC1Dc7ZVp0+do06N5nh6ZqF5i0Z8/sUEmjXqSOGiBahVuxp1a75q7RRFRB4vjQuWi4iIiEj6euKilIeHB8WKFXtszM6dOwG4ceMGN27cwMPDI9V9P/RwCtnKlSvJmzevRdw/F/d0cnIy/2wwGCxeP2wz/v+3ok/S79/17NmTGTNmMGzYMObNm0f37t1T/RS92rVrExgYSFBQEN26dbPYFxsby5tvvsk777yT7LgCBQpw8uTJf+3//PnzNG3alL59+/Lxxx+TPXt2tm/fTo8ePUhISEh1UQoeTOGrU6cOUVFRrF+/Hjc3N/PTFdNy74KCghg0aJBF2x8lOqc6n/RiSrxP/PkIAOIOn8WjQjF8ejbl/NBZ5pgcTfxxcHPm2vdbLI71rFkW95IFeKnJ/xer/v//9spHFnB52g9c/nRJRlyCzUhMTOTc2TAA/jh4lIqVyvLmW125d/cehYsU4Nyl/RbxC775jF0799H8lU7WSFdE/t+1aze4f/8+3j45Ldq9vXMREXnVSllZiUZKiYiIiNiEdF+U4MyZMwwcOJDZs2ezZMkSunbtyoYNG3BweLB8lbOzM0lJ//7UGz8/P1xcXAgLC0txWlhapbXfTp068f777zNt2jSOHTtG165dn+i848aNo0KFCpQoUcKivVKlShw7duyRhb4SJUpw//59fv/9dypXfrDmx+nTp7l586Y5Zv/+/RiNRiZOnGi+z999951FP6m979WrVyd//vwsWbKE1atX07ZtW3ORLy33zsXFJVnBKqOn7qXI4ICDs+Wvf67X63Nr3T7u34ixaD/VcwIOrn9dg0eFYhSd3J9jLUdw73xkhqRryxwcHHB2cWbcx1P5eoHl792OPasYMWwsa1ZvslJ2IvJQYmIiBw4cot7LNfn557XAgy9t6r1ck89nzvuXo/9jVJQSERERsQlPXJSKj48nIiLCshNHR3LmzElSUhKdOnUiMDCQ7t2706hRI8qWLcvEiRMZMmQI8GC9o927d3P+/HkyZ85sMfXv77JkycLgwYMZOHAgRqORmjVrEh0dzY4dO/D09HziotDT9pstWzZatWrFkCFDaNiwIfny5Xui85YtW5aOHTsybdo0i/ahQ4dSrVo1+vfvT8+ePfHw8ODYsWOsX7+ezz77jJIlSxIQEEDv3r2ZOXMmTk5OvPfee7i5uZlHahUrVozExESmT59Os2bN2LFjB7NmzbI4T6FChYiNjWXjxo2UL18ed3f3R46g6tChA7NmzeLkyZNs3rz5qe+dteUP6sitTb8Tf/kqmTK7kbNlLTyrl+bPDmPMMS6FfMlSzY8TnT5Odnz8BcvCk2P2B4vb3z11iaSYuGTx/2UfBr/HhvXbuHTxCpkze9DmtWbUrFWVNi3eICrqWoqLm1+6dIWwCykv9G/PPDzcKVassPl14UIFKF++NDdu3OTixStWzMz26d6l3eSps5k3dzL7Dxxi797feeftXnh4uDF/gX2N+DSZ/v1LGhERERF59p64KLVmzRpy585t0VaiRAn+/PNPPv74Yy5cuMCKFSsAyJ07N19++SWvv/46DRs2pHz58gwePJiuXbvi5+fH3bt3OXfu3CPPNWbMGHLlykVoaChnz54la9asVKpUybyoelqltd8ePXqwePHiFB/rnBohISEsWWL5wb9cuXJs3bqVESNGUKtWLUwmE0WLFqVdu3bmmIULF9KjRw/z46JDQ0M5evQorq6uAJQvX55JkyYxfvx4goKCqF27NqGhoXTp0sXcR/Xq1enTpw/t2rXj+vXrjBo1iuDg4BTz7NixIx9//DEFCxY0LyD/0LP6/+RZcszpRdFp7+DknY2k23HEHT/Pnx3GELPtD3NMrvb1SQi/TvTWg9ZL9DmQK1cOZn4xAR9fb2JibnP0yJ+0afEGWzbvsHZqz50qlcuzccMP5tcTPw0GYMHC7+jRc6CVsno+6N6l3fff/0yunNkJHjkYX99c/PHHUZo07WR/T8vUSCkRERERm2AwmUx6vn0qff311wwcOJArV67g7OxstTwuXbpE/vz52bBhA/Xr17daHmm1O08ra6fw3Gp8+7C1U3huxcTb16g2kefZ/YTLz7T/u1u+SvOxbnXT9sWUpJ+YmBi8vLyIjo7G09PT2umIiD3o39/aGaS/zz574kNePfDf+yJ6eaUa/x4kaZLav9fpvqbUf1FcXBzh4eGMGzeON998M8MLUps2bSI2NpayZcsSHh7O+++/T6FChVL99D8RERH5Gz19T0RERMQmOFg7gefBhAkTKFmyJL6+vgQFBWX4+RMTExk+fDilS5emZcuW5MqViy1btiR7yqCIiIikgtGY9k1ERERE0o1GSqVCcHDwI9dfygiBgYEEBgZa7fwiIiL/KRopJSIiImITVJQSERER+6IRTyIiIiI2QUUpERERsS8aKSUiIiJiE1SUEhEREfuikVIiIiIiNkELnYuIiIiIiIiISIbTSCkRERGxLxopJSKSajN/X2ntFNJV34pNrJ2CiPyNilIiIiJiX7SmlIiIiIhNUFFKRERE7ItGSomIiIjYBBWlRERExL5opJSIiIiITVBRSkREROyLRkqJPNarB3ZYO4V0t7xSDWunICIiKVBRSkREROyLRkrJo/Tvb+0M0t9nn1k7AxERkUdSUUpEREREROQfGq45ZO0U0t26RuWsnYKIiAUVpURERMS+aPqeiIiIiE1QUUpERETsi4pSIiIiIjZBRSkRERGxLyaTtTMQEREREVSUEhEREXujkVIiIiIiNkFFKREREbEvKkqJiIiI2AQVpURERMS+mFSUEhEREbEFDtZOQERERERERERE7I+KUiIiImJfjMa0b5LMjBkzKFSoEK6urlStWpU9e/Y8Nn7KlCmUKFECNzc38ufPz8CBA7l3714GZSsiIiK2REUpERERsS8mU9q3J3T58mU6depEjhw5cHNzo2zZsuzbt+9vqZgYOXIkuXPnxs3NjYCAAE6dOmXRx40bN+jYsSOenp5kzZqVHj16EBsb+9S3IT0sWbKEQYMGMWrUKA4cOED58uUJDAwkKioqxfjFixczbNgwRo0axfHjx5k7dy5Llixh+PDhGZy5iIiI2AIVpURERMS+ZNBIqZs3b1KjRg2cnJxYvXo1x44dY+LEiWTLls0cM2HCBKZNm8asWbPYvXs3Hh4eBAYGWowc6tixI0ePHmX9+vWsWLGCbdu20bt373S7HU9j0qRJ9OrVi+7du+Pn58esWbNwd3fnq6++SjF+586d1KhRgw4dOlCoUCEaNmzI66+//tjRVfHx8cTExFhsIiIi8t+ghc4lw/VIumLtFJ5bl+d0snYKz62Kb6+wdgrPpSt3rls7hedWXGK8tVOQR8mgaXjjx48nf/78zJs3z9xWuHBh888mk4kpU6bwwQcf8OqrrwKwcOFCfHx8WLZsGe3bt+f48eOsWbOGvXv3UqVKFQCmT5/OK6+8wqeffkqePHky5FpSkpCQwP79+wkKCjK3OTg4EBAQwK5du1I8pnr16nzzzTfs2bOHl156ibNnz7Jq1So6d+78yPOEhoYyevTodM9fRERErE8jpURERMS+mIxp3lIatRMfn3IB8ueff6ZKlSq0bdsWb29vKlasyOzZs837z507R0REBAEBAeY2Ly8vqlatai7q7Nq1i6xZs5oLUgABAQE4ODiwe/fuZ3SDUufatWskJSXh4+Nj0e7j40NERESKx3To0IGQkBBq1qyJk5MTRYsWpW7duo+dvhcUFER0dLR5u3jxYrpeh4iIiFiPilIiIiIiqRQaGoqXl5fFFhoammLs2bNnmTlzJsWLF2ft2rX07duXd955hwULFgCYCzePK+pERETg7e1tsd/R0ZHs2bM/svBjy7Zs2cLYsWP5/PPPOXDgAD/99BMrV65kzJgxjzzGxcUFT09Pi01ERET+GzR9T0REROyKyfjkC5Y/FBQUxKBBgyzaXFxcUow1Go1UqVKFsWPHAlCxYkWOHDnCrFmz6Nq1a5pzsBU5c+YkU6ZMREZGWrRHRkbi6+ub4jEffvghnTt3pmfPngCULVuWO3fu0Lt3b0aMGIGDg74vFRERsSf6yy8iIiL25SkWOk9p1M6jilK5c+fGz8/Poq1UqVKEhYUBmAs3jyvq+Pr6JnuS3f3797lx48YjCz8ZxdnZmcqVK7Nx40Zzm9FoZOPGjfj7+6d4TFxcXLLCU6ZMmYAHa2yJiIiIfVFRSkREROzLU6wp9SRq1KjBiRMnLNpOnjxJwYIFgQeLnvv6+loUdWJiYti9e7e5qOPv78+tW7fYv3+/OWbTpk0YjUaqVq2a1juQbgYNGsTs2bNZsGABx48fp2/fvty5c4fu3bsD0KVLF4uF0Js1a8bMmTP59ttvOXfuHOvXr+fDDz+kWbNm5uKUiIiI2A9N3xMRERH78hTT957EwIEDqV69OmPHjuW1115jz549fPnll3z55ZcAGAwGBgwYwEcffUTx4sUpXLgwH374IXny5KFFixbAg5FVjRo1olevXsyaNYvExET69+9P+/btrfrkvYfatWvH1atXGTlyJBEREVSoUIE1a9aY18kKCwuzGBn1wQcfYDAY+OCDD7h8+TK5cuWiWbNmfPzxx9a6BBEREbEiFaVERETEvhifbMRTWr344ossXbqUoKAgQkJCKFy4MFOmTKFjx47mmPfff9+8ptKtW7eoWbMma9aswdXV1RyzaNEi+vfvT/369XFwcKB169ZMmzYtQ64hNfr370///v1T3LdlyxaL146OjowaNYpRo0ZlQGYiIiJi61SUEhEREfuSQUUpgKZNm9K0adNH7jcYDISEhBASEvLImOzZs7N48eJnkZ6IiIiIVWlNKRERERERERERyXAaKSUiIiL2RU95ExEREbEJKkqJiIiIfcnA6XsiIiIi8mgqSomIiIh9yaCn74mIiIjI46koJSIiIvbFpJFSIiIiIrZARSkRERGxLxopJSIiImITVJQSERERu2LSmlIiIiIiNsHB2gmIiIiIiIiIiIj90UgpERERsS+aviciIiJiE1SUEhEREfuihc5FREREbIKKUiIiImJfNFJKRERExCaoKCUiIiL2RQudi4iIiNgEFaVERETEvmiklIiIiIhNUFFKRERE7IvWlBIRERGxCQ7WTkBEREREREREROyPilJ2rFChQkyZMsXaaYiIiGQsoyntm4iIiIikGxWlnpFu3bphMBgYN26cRfuyZcswGAwZmsv8+fPJmjVrsva9e/fSu3fvDM3FFjg4ONB/aG/W7P2Jfee3sHr3D7w5sLtFjJu7G8PHvseG339m3/ktLN/2P17r0tJKGVtPZEwcw3/YSZ3QH6gasoQ2n63k6OXrACQmGZmy7nfafLaSamOW0OCTpXzw406iYuLMx1++GUvwst94ZdJyqoYsoenkn/l80yES7ydZ65KsYuO+5fwZtTfZ9uG49wHI6Z2D8TNG8+uRNRw4t40fN3xNw6YvWzlr2zBocF+2bFvG5YhDnDm/h8XfzqJY8cKPjP9x6VfE3DlLk6YNMjDL50etmlVZtnQ+Yef3cz/hMs2bB1o7JaswGY1p3kREREQk/WhNqWfI1dWV8ePH8+abb5ItWzZrp5NMrly5rJ2CVfR4uzPturZixDshnD5xjtLlS/LR1A+IvX2HRXO+A+D9kHepWrMyQf2CuXwxnOp1X+KDcUOIirzGlrW/WvkKMkbM3QS6zVnPi4V9+KxzXbJ7uHLh+m083ZwBuJd4n+NXbtKrbhlK+GYj5m4CE1btZ8DibSzu0wiA89diMJrgg+YvUSB7Fk5H3SJk+R7uJdxnUKNK1ry8DNUmsCuZMmUyvy5esijzfpjB2p83ADD+s2CyeGbhrc6DuHkjmqatApk8O5Q2Dbpw/MhJa6VtE2rWfIkvv/yaA/sP4eiYiVHBQ1j280JeqtyQuLi7FrH9+r+BSQNZHsvDw51Dh44xb/63/Pj9XGunYz0a8SQiIiJiEzRS6hkKCAjA19eX0NDQR8Zs376dWrVq4ebmRv78+XnnnXe4c+eOeX94eDhNmjTBzc2NwoULs3jx4mTT7iZNmkTZsmXx8PAgf/78vPXWW8TGxgKwZcsWunfvTnR0NAaDAYPBQHBwMGA5fa9Dhw60a9fOIrfExERy5szJwoULATAajYSGhlK4cGHc3NwoX748P/zwQzrcqYxV4cWybF67jW0bdnLlYjjrV2xm55Y9lK3oZxGzfMkq9u48wJWL4fzw9XJOHD1tEfNfN+/XY/h6uhPSshpl8+Ukb7bMVC+Wm/zZswCQxdWZL7rVI7BMQQrl9KRc/pwMa1qFY1duEH7rwe9wjeJ5CGlZjerFcpMve2bqlsxHlxol2Xj8ojUvLcPdvH6La1HXzVvdBjW5cO4ie3YeAKDCi+X4Zu4SDv9+jEsXLjNr8lfcjr5N6fKlrJy59bVq0Z3F3/zIn8dPceTwn/R5cwgFCuSlQsUyFnFly5Wi/zs9eKvv+1bK9PmwZu1mRo6awPLla6ydinVp+p6IiIiITVBR6hnKlCkTY8eOZfr06Vy6dCnZ/jNnztCoUSNat27NoUOHWLJkCdu3b6d///7mmC5dunDlyhW2bNnCjz/+yJdffklUVJRFPw4ODkybNo2jR4+yYMECNm3axPvvP/iHWfXq1ZkyZQqenp6Eh4cTHh7O4MGDk+XSsWNHfvnlF3MxC2Dt2rXExcXRsuWDaWuhoaEsXLiQWbNmcfToUQYOHEinTp3YunVrutyvjHJw72Gq1nyRgkXyA1DCrxiVqpbn1027LGJeDqyFt++D0WQv1qhEoaL52bllt1VytoatJy7hlzc7g5f8ysvjf6Td56v5cd/pxx4Tey8Rg+FBwepxMV5uLumd7nPDycmR5m0a89Pin81tB/ce4pVXG+CV1RODwcArLRrg7OLCnp37rZipbfLyfFAUvXkz2tzm5ubK3K+m8N7AUURFXrNWavI8MRnTvomIiIhIutH0vWesZcuWVKhQgVGjRjF3ruVUidDQUDp27MiAAQMAKF68ONOmTaNOnTrMnDmT8+fPs2HDBvbu3UuVKlUAmDNnDsWLF7fo5+Hx8GD000cffUSfPn34/PPPcXZ2xsvLC4PBgK+v7yPzDAwMxMPDg6VLl9K5c2cAFi9eTPPmzcmSJQvx8fGMHTuWDRs24O/vD0CRIkXYvn07X3zxBXXq1Emx3/j4eOLj4y3ajCYjDgbr1UPnTFuIRxYPftmxhKQkI5kyOTAtdBYrf1xrjhk7fCLBnw5j0x+/kJh4H5PRSPB7oez/7aDV8s5ol27G8v3eU3TyL0nP2qU5cvkGE1btxymTA80rFkkWH5+YxNR1v9OobEEyuzql2GfY9dt8u/skAwMrPuv0bVb9xnXJ4pWZpd+uMLcN6BnE5Nlj2X1yI4mJ97l39x5vdx9C2LnkxWx7ZjAYGDfhQ3bt3MfxY39Nawwd/wG7dx9g1coNVsxORERERESelIpSGWD8+PHUq1cv2QilP/74g0OHDrFo0SJzm8lkwmg0cu7cOU6ePImjoyOVKv219k6xYsWSrU+1YcMGQkND+fPPP4mJieH+/fvcu3ePuLg43N3dU5Wjo6Mjr732GosWLaJz587cuXOH5cuX8+233wJw+vRp4uLiaNDAcvHghIQEKlZ8dIEhNDSU0aNHW7Tlcs+Ld+Z8qcrrWWj0an2atgpkaN+RnD5xjpKlizN0zECiIq7x83erAOjYoy3lKpehX+fBhF+KoHK1CowYN5ioyGv8tm2v1XLPSEYT+OXJzjsNKgBQMnd2zkTe4oe9p5IVpRKTjLz/3XZMwIimL6XYX2RMHP2+3kyD0gVoXaXYM87edrXp2JxfN+6yGNHz7rA+ZPHMQrfWb3Hzxi0CGtdh8uxQOjXvxcnjZ6yYrW2ZODmEUn4vEBjwmrmt8Sv1qVOnOjWrN7ViZvLc0TQ8EREREZugolQGqF27NoGBgQQFBdGtWzdze2xsLG+++SbvvPNOsmMKFCjAyZP/vsDx+fPnadq0KX379uXjjz8me/bsbN++nR49epCQkJDqohQ8mMJXp04doqKiWL9+PW5ubjRq1MicK8DKlSvJmzevxXEuLo+eihUUFMSgQYMs2qoVC0h1Ts/CeyPfZs70haxe9mBUxanjZ8idPzc93+nCz9+twsXVhXeH9+Xd7kPZtmEnACePnaZkmRfo1reD3RSlcmV2pWguL4u2wrm82HDMcj2ohwWp8Ft3+LJ7/RRHSUXFxNFr3kbK58/Jh81TLlrZgzz5fPGv/RJvd/9r3aP8hfLSqWc7mtZqx+kTZwE4cfQUlatVpMMbbQkeMu5R3dmVTycG06jxyzRu2J4rVyLM7XXqVqdwkQJcvHLQIv6bxZ+zc8demjTukMGZyvPApKKUiIiIiE1QUSqDjBs3jgoVKlCiRAlzW6VKlTh27BjFiqU8aqREiRLcv3+f33//ncqVKwMPRizdvHnTHLN//36MRiMTJ07EweHBlLjvvvvOoh9nZ2eSkpL+Ncfq1auTP39+lixZwurVq2nbti1OTg8KDH5+fri4uBAWFvbIqXopcXFxSVa0subUPQBXN9dk/yAxJiWZ75+jYyacnJ0w/iMm6W8x9qB8gVycvxZj0Xbhegy5s3qYXz8sSIVdv83s7vXJ6p68QBn5/wUpvzzZGd2yGg4Ohmeeu61q9Xozrl+7ydb1O8xtbm6uwIMHCfydMSnJ6v+t2IpPJwbTtHlDmjTqwIULllMaJ02cyYL5Syzadu9dQ9DQj1i9amNGpinPExWlRERERGyCilIZpGzZsnTs2JFp06aZ24YOHUq1atXo378/PXv2xMPDg2PHjrF+/Xo+++wzSpYsSUBAAL1792bmzJk4OTnx3nvv4ebmhsHw4B/2xYoVIzExkenTp9OsWTN27NjBrFmzLM5dqFAhYmNj2bhxI+XLl8fd3f2RI6g6dOjArFmzOHnyJJs3bza3Z8mShcGDBzNw4ECMRiM1a9YkOjqaHTt24OnpSdeuXZ/BXXs2tqzbTq8B3Qi/HMHpE+coVeYFurz5Okv/92CNnzuxcezdcYD3RvUn/l48Vy6FU8W/Es3bNuaTUdP+pff/jk7VS9Jt9jrmbD1KwzIFOHL5Oj/uO20e6ZSYZGTIkl85fuUm0zrVwWg0ce32XQC83JxxcsxEZEwcPb/aQJ6sHgwMrMjNO3+tL5Yzi5tVrstaDAYDLds3Y9mSlRZF4rOnznP+bBijPw1iQvBUbt2MJqBxXarXqUqfjgOtmLFtmDQ5hDavNef1dr25HRuLt09OAGKib3PvXjxRkddSXNz84sUryQpYAh4e7hQrVtj8unChApQvX5obN25y8eIVK2aWwYxasFxERETEFqgolYFCQkJYsuSvb/TLlSvH1q1bGTFiBLVq1cJkMlG0aFHatWtnjlm4cCE9evSgdu3a+Pr6EhoaytGjR3F1fTC6onz58kyaNInx48cTFBRE7dq1CQ0NpUuXLuY+qlevTp8+fWjXrh3Xr19n1KhRBAcHp5hjx44d+fjjjylYsCA1atSw2DdmzBhy5cpFaGgoZ8+eJWvWrFSqVInhw4en41169sYOn8jbw3rzwbghZM+ZjauR1/j+62XMnPjXQvSD3/yAASPeYtznwXhl9eTKpQimhX7BkgU/WTHzjFUmbw4mvV6baesP8uXWw+TNmpkhjSvTpPyDf9BGxcSx5c/LALT7fLXFsbO71+fFwj78diaCizdiuXgjlsBPl1nEHAyxr2lV1eu8RN78uS2eugdw/34Sb74+gPc+7M/Mbybh7u5O2PmLDHs7mG0bd1opW9vRs3cnAFav/daivc+bQ1j8zY/WSOm5VqVyeTZu+MH8euKnwQAsWPgdPXraURFUI6VEREREbILBZDLpk9lz5NKlS+TPn58NGzZQv359a6eTJmV8qlk7hefW3mmNrZ3Cc6vi2yv+PUiSuXLnurVTeG7FJcb/e5Ck6H7C5Wfa/+0+jdJ8bJZZa9IxE0mLmJgYvLy8iI6OxtPTM307798/ffuzBZ999sSHvHpgx78HPWeWV6rx70H/0HDNoWeQiXWta1TuiY+Z+fvKZ5CJ9fSt2OTJD9J7A6D3Bnkyqf17rZFSNm7Tpk3ExsZStmxZwsPDef/99ylUqBC1a9e2dmoiIiIiIiIiImmmopSNS0xMZPjw4Zw9e5YsWbJQvXp1Fi1aZF6AXERERJ6MBomLiIiI2AY92snGBQYGcuTIEeLi4oiMjGTp0qUULFjQ2mmJiIg8v4ymtG9PIDg4GIPBYLGVLFnSvP/evXv069ePHDlykDlzZlq3bk1kZKRFH2FhYTRp0gR3d3e8vb0ZMmQI9+/fT5fbICIiImJtGiklIiIi9iUDFzovXbo0GzZsML92dPzro9fAgQNZuXIl33//PV5eXvTv359WrVqxY8eDNTuSkpJo0qQJvr6+7Ny5k/DwcLp06YKTkxNjx47NsGsQEREReVZUlBIRERG7YsrAopSjoyO+vr7J2qOjo5k7dy6LFy+mXr16AMybN49SpUrx22+/Ua1aNdatW8exY8fYsGEDPj4+VKhQgTFjxjB06FCCg4NxdnbOsOsQEREReRY0fU9ERETsy1NM34uPjycmJsZii49/9JMWT506RZ48eShSpAgdO3YkLCwMgP3795OYmEhAQIA5tmTJkhQoUIBdu3YBsGvXLsqWLYuPj485JjAwkJiYGI4ePfqMbo6IiIhIxlFRSkREROyLMe1baGgoXl5eFltoaGiKp6latSrz589nzZo1zJw5k3PnzlGrVi1u375NREQEzs7OZM2a1eIYHx8fIiIiAIiIiLAoSD3c/3CfiIiIyPNO0/dEREREUikoKIhBgwZZtLm4uKQY27hxY/PP5cqVo2rVqhQsWJDvvvsONze3Z5qniIiIyPNAI6VERETErpiMpjRvLi4ueHp6WmyPKkr9U9asWXnhhRc4ffo0vr6+JCQkcOvWLYuYyMhI8xpUvr6+yZ7G9/B1SutUiYiIiDxvVJQSERER+/IUa0o9jdjYWM6cOUPu3LmpXLkyTk5ObNy40bz/xIkThIWF4e/vD4C/vz+HDx8mKirKHLN+/Xo8PT3x8/N7qlxEREREbIGm74mIiIh9MWbMaQYPHkyzZs0oWLAgV65cYdSoUWTKlInXX38dLy8vevTowaBBg8iePTuenp68/fbb+Pv7U61aNQAaNmyIn58fnTt3ZsKECURERPDBBx/Qr1+/VI/OEhEREbFlKkqJiIiIXTE95Yin1Lp06RKvv/46169fJ1euXNSsWZPffvuNXLlyATB58mQcHBxo3bo18fHxBAYG8vnnn5uPz5QpEytWrKBv3774+/vj4eFB165dCQkJyZD8RURERJ41FaVERETEvmTQSKlvv/32sftdXV2ZMWMGM2bMeGRMwYIFWbVqVXqnJiIiImITVJQSERERu5JRI6VERERE5PG00LmIiIiIiIiIiGQ4jZQSERER+5JB0/dERERE5PFUlBIRERG7YlJRSkRERMQmqCglIiIi9kVFKRERERGboKKUiIiI2BWNlBIRERGxDSpKiYiIiH1RUUpERETEJujpeyIiIiIiIiIikuFUlBIRERG7YjKmfZPkZsyYQaFChXB1daVq1ars2bPnsfG3bt2iX79+5M6dGxcXF1544QVWrVqVQdmKiIiILdH0PREREbErKi6lnyVLljBo0CBmzZpF1apVmTJlCoGBgZw4cQJvb+9k8QkJCTRo0ABvb29++OEH8ubNy4ULF8iaNWvGJy8iIiJWp6KUiIiI2BUVpdLPpEmT6NWrF927dwdg1qxZrFy5kq+++ophw4Yli//qq6+4ceMGO3fuxMnJCYBChQplZMoiIiJiQzR9T0REROyLyZD2TcwSEhLYv38/AQEB5jYHBwcCAgLYtWtXisf8/PPP+Pv7069fP3x8fChTpgxjx44lKSnpkeeJj48nJibGYhMREZH/Bo2Ukgz3582L1k7huZWz+zxrp/DcujatlbVTeC7lHfiLtVMQSXcaKZU+rl27RlJSEj4+PhbtPj4+/Pnnnykec/bsWTZt2kTHjh1ZtWoVp0+f5q233iIxMZFRo0aleExoaCijR49O9/xFRETE+jRSSkREROyKyWhI8yZPx2g04u3tzZdffknlypVp164dI0aMYNasWY88JigoiOjoaPN28aK+3BIREfmv0EgpEREREXliOXPmJFOmTERGRlq0R0ZG4uvrm+IxuXPnxsnJiUyZMpnbSpUqRUREBAkJCTg7Oyc7xsXFBRcXl/RNXkRERGyCRkqJiIiIXTEZ077JX5ydnalcuTIbN240txmNRjZu3Ii/v3+Kx9SoUYPTp09jNP51M0+ePEnu3LlTLEiJiIjIf5uKUiIiImJXTCZDmjexNGjQIGbPns2CBQs4fvw4ffv25c6dO+an8XXp0oWgoCBzfN++fblx4wbvvvsuJ0+eZOXKlYwdO5Z+/fpZ6xJERETEijR9T0REROyKRjyln3bt2nH16lVGjhxJREQEFSpUYM2aNebFz8PCwnBw+Os70Pz587N27VoGDhxIuXLlyJs3L++++y5Dhw611iWIiIiIFakoJSIiInZFC5anr/79+9O/f/8U923ZsiVZm7+/P7/99tszzkpERESeBypKiYiIiF0xmaydgYiIiIiAilIiIiJiZzRSSkRERMQ2aKFzERERERERERHJcBopJSIiInZFI6VEREREbIOKUiIiImJXtKaUiIiIiG1QUUpERETsikZKiYiIiNgGFaVERETErphMKkqJiIiI2AIVpURERMSumIzWzkBEREREQEUpERERsTNGjZQSERERsQkO1k5ARERERERERETsj4pSIiIiYldMJkOat6cxbtw4DAYDAwYMMLfdu3ePfv36kSNHDjJnzkzr1q2JjIy0OC4sLIwmTZrg7u6Ot7c3Q4YM4f79+0+Vi4iIiIgtUFFKRERE7IrJaEjzllZ79+7liy++oFy5chbtAwcO5JdffuH7779n69atXLlyhVatWpn3JyUl0aRJExISEti5cycLFixg/vz5jBw5Ms25iIiIiNgKFaVERETErphMad/i4+OJiYmx2OLj4x97vtjYWDp27Mjs2bPJli2buT06Opq5c+cyadIk6tWrR+XKlZk3bx47d+7kt99+A2DdunUcO3aMb775hgoVKtC4cWPGjBnDjBkzSEhIeKb3SURERORZU1FKRERE7MrTjJQKDQ3Fy8vLYgsNDX3s+fr160eTJk0ICAiwaN+/fz+JiYkW7SVLlqRAgQLs2rULgF27dlG2bFl8fHzMMYGBgcTExHD06NF0vCsiIiIiGU9P3xMRERG78jRP3wsKCmLQoEEWbS4uLo+M//bbbzlw4AB79+5Nti8iIgJnZ2eyZs1q0e7j40NERIQ55u8FqYf7H+4TEREReZ6pKCUiIiKSSi4uLo8tQv3dxYsXeffdd1m/fj2urq7PODMRERGR54+m74mIiIhdyain7+3fv5+oqCgqVaqEo6Mjjo6ObN26lWnTpuHo6IiPjw8JCQncunXL4rjIyEh8fX0B8PX1TfY0voevH8aIiIiIPK9UlJKnsmXLFgwGQ7IP1CIiIrbqaRY6fxL169fn8OHDHDx40LxVqVKFjh07mn92cnJi48aN5mNOnDhBWFgY/v7+APj7+3P48GGioqLMMevXr8fT0xM/P790uR8iIiIi1qKilI3o1q0bBoOBcePGWbQvW7YMgyHta1/80/nz5zEYDBw8eDDd+nzeDX2/P7t2ruTm9RNcufQHP/4wlxdeKGrttGzS4MFvse3X5UREHuH8+X18u+RLihcvYhHj4uLCpMkhhF38nciooyxaPBNv75xWyth6Im/fY/iK36kzfR1VJ6+mzbxtHI24Zd5vMpn4fPsJAj7fQNXJq3lzyW9cuHnHoo/ouwkErfidGlPXUnPaWoLX/EFcwv0MvhLr6t6jA7/u+oULl3/nwuXfWbvxOwIa1Dbv/3nVN9y4fcpimzglxIoZ2y691/3FaDKkeXsSWbJkoUyZMhabh4cHOXLkoEyZMnh5edGjRw8GDRrE5s2b2b9/P927d8ff359q1aoB0LBhQ/z8/OjcuTN//PEHa9eu5YMPPqBfv36pnkYoIiIiYqtUlLIhrq6ujB8/nps3b1o7Fbt6zHTtWtWYOXMBNWo1o9Err+Pk6MTqlYtxd3ezdmo2p2atqnz5xde8XLclzZp1xsnJkZ9/WWhxr8ZP+JBXXqlP505vERjYjty5fVj8v1lWzDrjxdxLpNvinThmcuCzNi/xU/c6DKpbCk8XJ3PM/D1nWXzgPCMalOHrjjVwc3bkre93E38/yRwzfOVBzlyLZVbbl5je6kX2X7xByLrD1rgkq7lyJYLRoz7l5dotqFenJdu27uKbb2dSsmQxc8yCed9Ssqi/eQv+cIIVM7Zdeq/7S0ZN30uNyZMn07RpU1q3bk3t2rXx9fXlp59+Mu/PlCkTK1asIFOmTPj7+9OpUye6dOlCSIiKryIiIvL8U1HKhgQEBODr6/vYR0tv376dWrVq4ebmRv78+XnnnXe4c+ev0RUGg4Fly5ZZHJM1a1bmz58PQOHChQGoWLEiBoOBunXrAg9GarVo0YKPP/6YPHnyUKJECQC+/vprqlSpQpYsWfD19aVDhw4WUwj+C5o068TCr7/j2LGTHDp0jDd6DqBgwXxUrlTO2qnZnBavduWbb37g+PFTHD58nDd7D6ZAgXxUrFgWAE/PLHTt+hrDhn7E1q27OPj7Efq8OQR//yq8+GJFK2efcebtPoNvFldCGpenbO6s5M3qTvXCucifzQN4MEpq0f5z9KpWjJeL+/KCtydjXinP1dh4Np96sFbM2eu32XHuKqMalaVsnmxUzJedYQGlWXv8ClGx96x5eRlq7epNbFi3lbNnLnDm9Hk+DpnMndg4qrxUwRxzN+4eUVHXzNvt27HWS9iG6b3uLxk1fS8lW7ZsYcqUKebXrq6uzJgxgxs3bnDnzh1++umnZGtFFSxYkFWrVhEXF8fVq1f59NNPcXTUs2pERETk+aeilA3JlCkTY8eOZfr06Vy6dCnZ/jNnztCoUSNat27NoUOHWLJkCdu3b6d///6pPseePXsA2LBhA+Hh4Rbfxm7cuJETJ06wfv16VqxYAUBiYiJjxozhjz/+YNmyZZw/f55u3bo93YXaOC8vTwBu3Lxl3USeA56eWQC4+f/3qmLFMjg7O7N58w5zzMmTZwgLu0TVqpWskaJVbD0TiZ9vVgYv38/LM9bTbsGv/PhHmHn/5ei7XLsTT9WCf01rzOLiRNncWfnjyoORkoeu3CKLiyOlfbOaY6oWzImDwcCRK7cy6lJsioODA61aN8Hdw529uw+a29u0a86p87vZsXslHwa/h5ubnnKWGvb8XpdR0/dERERE5PH0NZuNadmyJRUqVGDUqFHMnTvXYl9oaCgdO3ZkwIABABQvXpxp06ZRp04dZs6cmarHTefKlQuAHDlyJPsm1sPDgzlz5uDs7Gxue+ONN8w/FylShGnTpvHiiy8SGxtL5syZ//V88fHxxMfHW7SZTKZ0XScrPRkMBiZ9OpodO/Zw9OgJa6dj0wwGAxM+GcnOnXs5duwkAD4+uYiPjyc6OsYiNirqGj4+uayRplVcuhXH9wcv0KlKYXpWK8aRiGgmbDqKUyYHmpfJx7U7D0Y65fCwXA8mu4cL1+88+O/l2p14srtb7nd0cMDTzYlrdyz/m/qvK+X3Ams3foerqwt3YuPo3OEtTpw4DcCP3//CxbDLhIdHUbpMSYJDhlCseBG6duxn5axtm97rRERERMQWqChlg8aPH0+9evUYPHiwRfsff/zBoUOHWLRokbnNZDJhNBo5d+4cpUqVeqrzli1b1qIgBQ8eZx0cHMwff/zBzZs3MRqNAISFhaXqqT+hoaGMHj3aos3gkBlDJs+nyvVZmT5tLKVLl6DOyy2tnYrNmzxlDH5+JQgIaGPtVGyO0WTCz9eLd2qXBKCkjxdnrt3mh4MXaF4mn5Wze/6cPnWOOjWa4+mZheYtGvH5FxNo1qgjJ06cZsG8Jea448dOEhkRxfKVX1OocAHOnwt7TK/2zd7f657F2lAiIiIi8uQ0fc8G1a5dm8DAQIKCgizaY2NjefPNNy0eLf3HH39w6tQpihZ98AQlg8GA6R+LXiQmJqbqvB4eHhav79y5Q2BgIJ6enixatIi9e/eydOlSIPULoQcFBREdHW2xGRyypOrYjDZ1ykc0eSWAgIZtuXw53Nrp2LSJk0bTuHE9Gjdqz5XLEeb2yMiruLi4mKcFPeTtnZPIyKsZnabV5MrsStEclr/nhbNnJvz2XQByejwY1Xj9HyOebtyJN4+eyunhwo04y/33jUZi7iaS08O+nriVmJjIubNh/HHwKGOCJ3Lk8HHefKtrirH79/0BQJEiBTIyxeeK3us0fU9ERETEVmiklI0aN24cFSpUMC84DlCpUiWOHTtGsWLFHnlcrly5CA//6x8Zp06dIi4uzvz64UiopKSkZMf+059//sn169cZN24c+fPnB2Dfvn1PdB0uLi7JHllti1P3pk75iBavNqJ+g7acP3/R2unYtImTRtO8eSCNAttz4YLl2me//36EhIQE6tatzvLlawAoXrwIBQrkY/fuA9ZI1yrK583G+RuWi21fuHmH3J4PnnKW18uNnB4u7Am7TkkfLwBi4xM5HH6LthUKAlAuT1Zux9/nWEQ0fr4PYvZcuI7RZKJMnqwZdzE2yMHBAWcX5xT3lS33YMRoRIT9FEGfhN7rHkiH9cpFREREJB2oKGWjypYtS8eOHZk2bZq5bejQoVSrVo3+/fvTs2dPPDw8OHbsGOvXr+ezzz4DoF69enz22Wf4+/uTlJTE0KFDcXL66zH03t7euLm5sWbNGvLly4erqyteXl4p5lCgQAGcnZ2ZPn06ffr04ciRI4wZM+bZXrgVTJ82ltfbt6BV6ze4fTvWvPZRdPRt7t2zn6ecpcbkKWN47bVXafdaL2Jj7/ztXsVw7148MTG3WbDgO8aN/4CbN6OJuX2biRNH89tv+9m793crZ59xOlUuTLfFO5nz22kalsjNkfBb/HgojA8bPnhKocFgoGPlwszedYoC2TzI6+XGjO0nyZXZhZeL+wBQJEcWahTORcjaQ4xoWJb7SUbGbTxKYKk8eGe2n4W8Pwx+jw3rt3Hp4hUyZ/agzWvNqFmrKm1avEGhwgVo07YZ69dt4caNW5QuU4KPQ0ewY/sejmmdpGT0XvcXjXgSERERsQ0qStmwkJAQliz5a72UcuXKsXXrVkaMGEGtWrUwmUwULVqUdu3amWMmTpxI9+7dqVWrFnny5GHq1Kns37/fvN/R0ZFp06YREhLCyJEjqVWrFlu2bEnx/Lly5WL+/PkMHz6cadOmUalSJT799FOaN2/+zK7ZGvr2eTANaNPGHy3a3+gxkIVff2eNlGxW796dAVi7bolF+5u9B/PNNz8AMPT9MRiNRhYtnomLizMbNmxj4IAPMzxXayqTOyuTWlRm2rYTfLnzFHm93Bjysh9N/PKaY7q9VIS7ifcZs/Ywt+MTqZg3G5+3eQkXx0zmmLFNKhC68ShvLvkNB4OB+i/4MrR+aWtcktXkypWDmV9MwMfXm5iY2xw98idtWrzBls07yJvXlzovV6dPv664u7tz+VI4v/y8lokTPrd22jZJ73V/0ZpSIiIiIrbBYPrnAkQiz5ijc95/D5IUuTg6/XuQpOjatFbWTuG5lHfgL9ZO4bkVEx/370GSovsJl59p/7/6pv0BDbUifkjHTCQtYmJi8PLyIjo6Gk/PdH5wSv/+6dufLfj/0fRP4tUDO55BIta1vFKNJz6m4ZpDzyAT61rXqNwTHzPz95XPIBPr6VuxyZMfpPcGQO8N8mRS+/daC52LiIiIiIiIiEiG0/Q9ERERsSsmNH1PRERExBaoKCUiIiJ2xaiFC0RERERsgopSIiIiYleMGiklIiIiYhNUlBIRERG7oul7IiIiIrZBRSkRERGxK0ZrJyAiIiIigIpSIiIiYmc0UkpERETENjhYOwEREREREREREbE/GiklIiIidkXT90RERERsg4pSIiIiYldUlBIRERGxDSpKiYiIiF3RmlIiIiIitkFFKREREbErRtWkRERERGyCilIiIiJiV4waKSUiIiJiE/T0PRERERERERERyXAaKSUiIiJ2xWTtBEREREQEUFFKRERE7IyeviciIiJiG1SUEhEREbtiNGhNKRERERFboKKUiIiI2BVN3xMRERGxDSpKiYiIiF3R9D0RERER26CilIiIiNgVo2bviYiIiNgEB2snICIiIiLPrxkzZlCoUCFcXV2pWrUqe/bsSdVx3377LQaDgRYtWjzbBEVERMRmqSglIiIidsWIIc3bk5g5cyblypXD09MTT09P/P39Wb16tXn/vXv36NevHzly5CBz5sy0bt2ayMhIiz7CwsJo0qQJ7u7ueHt7M2TIEO7fv58u9yE9LFmyhEGDBjFq1CgOHDhA+fLlCQwMJCoq6rHHnT9/nsGDB1OrVq0MylRERERskYpSIiIiYldMT7E9iXz58jFu3Dj279/Pvn37qFevHq+++ipHjx4FYODAgfzyyy98//33bN26lStXrtCqVSvz8UlJSTRp0oSEhAR27tzJggULmD9/PiNHjnyq609PkyZNolevXnTv3h0/Pz9mzZqFu7s7X3311SOPSUpKomPHjowePZoiRYpkYLYiIiJia1SUEhEREbtiNKR9i4+PJyYmxmKLj49P8TzNmjXjlVdeoXjx4rzwwgt8/PHHZM6cmd9++43o6Gjmzp3LpEmTqFevHpUrV2bevHns3LmT3377DYB169Zx7NgxvvnmGypUqEDjxo0ZM2YMM2bMICEhISNvWYoSEhLYv38/AQEB5jYHBwcCAgLYtWvXI48LCQnB29ubHj16pOo8Kd1zERER+W/QQucizxFHh0zWTuG5VWn4dmun8FyKPLfW2ik8tyqX6WjtFOQRnubpe6GhoYwePdqibdSoUQQHBz/2uKSkJL7//nvu3LmDv78/+/fvJzEx0aKgU7JkSQoUKMCuXbuoVq0au3btomzZsvj4+JhjAgMD6du3L0ePHqVixYpPcSVP79q1ayQlJVnkB+Dj48Off/6Z4jHbt29n7ty5HDx4MNXnSemei4iIyH+DilIiIiJiV550Gt7fBQUFMWjQIIs2FxeXR8YfPnwYf39/7t27R+bMmVm6dCl+fn4cPHgQZ2dnsmbNahHv4+NDREQEABERESkWfB7ue97cvn2bzp07M3v2bHLmzJnq4/55z2NiYsifP/+zSFFEREQymIpSIiIiYleMT7ZeuQUXF5fHFqH+qUSJEhw8eJDo6Gh++OEHunbtytatW9OegA3JmTMnmTJlSrY4e2RkJL6+vsniz5w5w/nz52nWrJm5zWh8MG7N0dGREydOULRo0WTHPek9FxERkeeH1pQSEREReUacnZ0pVqwYlStXJjQ0lPLlyzN16lR8fX1JSEjg1q1bFvF/L+j4+vqmWPB5uM/anJ2dqVy5Mhs3bjS3GY1GNm7ciL+/f7L4kiVLcvjwYQ4ePGjemjdvzssvv8zBgwc1+klERMQOqSglIiIidsX4FNtTn9toJD4+nsqVK+Pk5GRR0Dlx4gRhYWHmgo6/vz+HDx8mKirKHLN+/Xo8PT3x8/NLh2ye3qBBg5g9ezYLFizg+PHj9O3blzt37tC9e3cAunTpQlBQEACurq6UKVPGYsuaNStZsmShTJkyODs7W/NSRERExAo0fU9ERETsSnoUl1IjKCiIxo0bU6BAAW7fvs3ixYvZsmULa9euxcvLix49ejBo0CCyZ8+Op6cnb7/9Nv7+/lSrVg2Ahg0b4ufnR+fOnZkwYQIRERF88MEH9OvXz2ams7Vr146rV68ycuRIIiIiqFChAmvWrDGvfRUWFoaDg74DFRERkZSpKCUiIiJ2xfQUa0o9iaioKLp06UJ4eDheXl6UK1eOtWvX0qBBAwAmT56Mg4MDrVu3Jj4+nsDAQD7//HPz8ZkyZWLFihX07dsXf39/PDw86Nq1KyEhIRlzAanUv39/+vfvn+K+LVu2PPbY+fPnp39CIiIi8txQUUpERETsSkaNlJo7d+5j97u6ujJjxgxmzJjxyJiCBQuyatWq9E5NRERExCaoKCUiIiJ2JaOKUiIiIiLyeCpKiYiIiF0xWTsBEREREQH09D0REREREREREbECjZQSERERu2LMoIXORUREROTxVJQSERERu6I1pURERERsg4pSIiIiYldUlBIRERGxDSpKiYiIiF3RQuciIiIitkFFKREREbErWlNKRERExDbo6XsiIiIiIiIiIpLhNFJKRERE7IrWlBIRERGxDSpKiYiIiF3RmlIiIiIitkFFKREREbErRpWlRERERGyCilIiIiJiVzR9T0RERMQ2qCglIiIidkXjpERERERsg4pSIiIiYlc0UkpERETENjhYOwEREREREREREbE/Kkr9B23ZsgWDwcCtW7ceG1eoUCGmTJmSITmJiIjYCqMh7ZuIiIiIpB8VpayoW7duGAwGDAYDzs7OFCtWjJCQEO7fv/9U/VavXp3w8HC8vLwAmD9/PlmzZk0Wt3fvXnr37v1U5/ovGPp+f3btXMnN6ye4cukPfvxhLi+8UNTaadmkQe/1YfPWpVwK/4PT5/aw6H+zKFa8sEWMt3dOvpj9KSfP/MaVyMNs276c5q8GWilj2+Dg4MA7Q99k/d5l/H5hG2v3/ETfQW9YxDRoUpc5301j15/rOR61h5JlilspW+tq2LorZWo0TrZ9NHEGAN36v59s3+gJ01Ps61Z0DPVbdKJMjcbE3I7NyMuwCQ4ODvR7vzer9/zInnNbWPnb9/Qe2N0iJnvObIyZ+gEbDv7M7rObmbl4MgUK57NSxhnHiCnNm4iIiIikH60pZWWNGjVi3rx5xMfHs2rVKvr164eTkxNBQUFp7tPZ2RlfX99/jcuVK1eaz/FfUrtWNWbOXMC+/QdxdHTko5BhrF65mLLl6xIXd9fa6dmUGjWrMvvLbzhw4BCOmTIxMngwS5cvoGqVQPO9+mL2p3h5edL+td7cuH6TNq81Z/7C6dSt1YJDh45Z+Qqso+fbXWjfrTVBb4/m1ImzlClfirHTPuR2TCzfzPkOADd3Nw7s/oM1yzcyZvIIK2dsPd/OmYrR+NeKP6fOXqDXgOE0fLmWua1N80b079nZ/NrV1SXFvkaGTuGFooWJvHr92SVsw97o35nXurbkg3fHcObEWUqXL0XIlBHExsSyeO73AEydP577ifd5t9tQ7ty+Q+c3X+fL76fRsnYH7sbds/IVPDsqLYmIiIjYBo2UsjIXFxd8fX0pWLAgffv2JSAggJ9//pmbN2/SpUsXsmXLhru7O40bN+bUqVPm4y5cuECzZs3Ili0bHh4elC5dmlWrVgGW0/e2bNlC9+7diY6ONo/KCg4OBiyn73Xo0IF27dpZ5JaYmEjOnDlZuHAhAEajkdDQUAoXLoybmxvly5fnhx9+ePY36Rlr0qwTC7/+jmPHTnLo0DHe6DmAggXzUblSOWunZnNat+zO4kU/8ufxUxw58id9+7xPgQJ5qVCxjDnmpaqV+GLWQg7sP8T58xf5dMIMom/FWMTYm4ovlmPTmm1s3bCDKxfDWbdiEzu27KZspdLmmJ+/X83nE+eyc9seK2ZqfdmzZSVnjuzmbeuO3eTPm5sXK5Y1x7i6uFjEZPbwSNbPt0tXEBMbS7cOrTMyfZtS/sWybF77K79u2MmVixGsX7GZXVv2UKaiHwAFi+SnfJWyfDTsE44ePM75M2F8NHQCrq4uNG7RwMrZP1vGp9hEREREJP2oKGVj3NzcSEhIoFu3buzbt4+ff/6ZXbt2YTKZeOWVV0hMTASgX79+xMfHs23bNg4fPsz48ePJnDlzsv6qV6/OlClT8PT0JDw8nPDwcAYPHpwsrmPHjvzyyy/Exv41xWXt2rXExcXRsmVLAEJDQ1m4cCGzZs3i6NGjDBw4kE6dOrF169ZndDesw8vLE4AbN29ZN5HngJdnFgBu3ow2t+3ZfYBWrZuQLZsXBoOB1m2a4uLqwvZfd1srTav7fe8hqtWqQqEiBQAoUbo4laqW59eNO62cmW1LTExkxbrNtGzSEIPhr8V8Vq7fTM1X2tGiUx8mz5zH3XuWI3rOnLvArHmLCf1gMAaD/f6Z+2PvYarWqkLBIvkBeMGvGBWrlmf7pl3Ag1G1APH3EszHmEwmEuITqVi1fMYnnIE0fU9ERETENmj6no0wmUxs3LiRtWvX0rhxY5YtW8aOHTuoXr06AIsWLSJ//vwsW7aMtm3bEhYWRuvWrSlb9sHogSJFiqTYr7OzM15eD4oDj5vSFxgYiIeHB0uXLqVz5wfTYhYvXkzz5s3JkiUL8fHxjB07lg0bNuDv728+5/bt2/niiy+oU6dOiv3Gx8cTHx+f7Fr//g9MW2IwGJj06Wh27NjD0aMnrJ2OTTMYDISO/4BdO/dx/NhJc3u3Lm8zb8E0zl88QGJiInFx9+j0el/Onr1gxWyta/a0BWTO4sHKnd+RlGQkUyYHpoydyYof11o7NZu2cdsubsfG0uKVv0btNGlQlzy+PuTKmZ2Tp88xeeZXnA+7xNTQDwFISEhgSPB43uvXk9y+3ly8EmGt9K1u7vSFeGRxZ/n2b82/d9NDv2DVT+sAOHf6PFcuhfPuiL6EDBnP3bi7dH6zPb55fcjpncPK2T9bKi2JiIiI2AYVpaxsxYoVZM6cmcTERIxGIx06dKBVq1asWLGCqlWrmuNy5MhBiRIlOH78OADvvPMOffv2Zd26dQQEBNC6dWvKlUv7dDNHR0dee+01Fi1aROfOnblz5w7Lly/n22+/BeD06dPExcXRoIHllI6EhAQqVqz4yH5DQ0MZPXq0RZvBITOGTJ5pzvVZmj5tLKVLl6DOyy2tnYrNmzh5NKX8XqBRA8tpnyM+HISXlyfNm3bm+rUbNGnWgHkLp9M4sB3Hjp58RG//bY1fDaBp60YM6fMhp06cpVSZFwgaM4ioyGssX7LS2unZrJ9WrKVmtSp45/qrQNL21VfMP79QtDC5cmanxztBhF26QoF8eZgyaz5FCuanWWA9a6RsUwKb16dJq0CG9R3FmRPnKFGmOO+HDOBq5DV+/m4V9+8nMfCNIEZPGs6OE+u4f/8+u7ft49eNO232iwMRERER+W9RUcrKXn75ZWbOnImzszN58uTB0dGRn3/++V+P69mzJ4GBgaxcuZJ169YRGhrKxIkTefvtt9OcS8eOHalTpw5RUVGsX78eNzc3GjVqBGCe1rdy5Ury5s1rcZyLS8qLDAMEBQUxaNAgi7ZsOUqmOcdnaeqUj2jySgAv12/F5cvh1k7Hpn0ycRSBjerxSmB7rvxtJErhwgV4s08Xqr7YiD+PP1gD7ciRP6le/UV69e7MwHc/tFbKVjV41DvMmb6AVcvWA3Dq+Bny5MtN73e6qij1CFciIvlt30GmjP3gsXFl/R68n1y8HE6BfHnYvf8PTp09T/naTQAw/f+QmFpN2tGrS3uLBdL/6waN7M/cz75mzfINAJz68wy58/nS4+0u/PzdgzUIjx86wWsBXcmcxQMnZyduXr/FolVzOPrHn9ZM/ZnT2lAiIiIitkFFKSvz8PCgWLFiFm2lSpV68I317t3m6XvXr1/nxIkT+Pn5mePy589Pnz596NOnD0FBQcyePTvFopSzszNJSUn/mkv16tXJnz8/S5YsYfXq1bRt2xYnJycA/Pz8cHFxISws7JFT9VLi4uKSrGhli9/AT53yES1ebUT9Bm05f/6itdOxaZ9MHEXTZg1p0rgjFy5cstjn5u4KYPH0NICkpCQcHOx3bR83N1eMRssJQ/Z+T/7N0pXryZ7Ni9r+Lz027s9TZwDImSM7AJM/HkF8wl9rJB05fpIPx05mweefkj9v7meXsA1ydXPF9I//Fo1JRgwOyd+DY2/fAaBA4Xz4lS/JZ+O/zJAcrUVrQ4mIiIjYBhWlbFDx4sV59dVX6dWrF1988QVZsmRh2LBh5M2bl1dffRWAAQMG0LhxY1544QVu3rzJ5s2bKVWqVIr9FSpUiNjYWDZu3Ej58uVxd3fH3d09xdgOHTowa9YsTp48yebNm83tWbJkYfDgwQwcOBCj0UjNmjWJjo5mx44deHp60rVr1/S/ERlk+rSxvN6+Ba1av8Ht27H4+OQCIDr6Nvfu/XcfiZ4WEyePpk3b5nRo/yaxt2Px9s4JQEzMbe7di+fkibOcOX2eKdM+4oPhody8cYsmTRvwcr2avNaml5Wzt57N637lzQHdCL8UwakTZ/ErW4JufTrw0/9+Mcd4ZfUkdz4fvP//969w0YIAXIu6wbWo61bJ21qMRiPLVq7n1cYBODpmMreHXbrCqvVbqOX/Ilm9PDl5+hzjp31BlQplKFGsMAAF8uWx6OvmrRgAihTMj2eW5A+D+C/bun47vd7tRvjlSM6cOEvJMiXo3Kc9y/63whzToFk9bl6/SfilSIqXKsrQjwayefU2dm39bz8FUiUpEREREdugopSNmjdvHu+++y5NmzYlISGB2rVrs2rVKvPIpaSkJPr168elS5fw9PSkUaNGTJ48OcW+qlevTp8+fWjXrh3Xr19n1KhRBAcHpxjbsWNHPv74YwoWLEiNGjUs9o0ZM4ZcuXIRGhrK2bNnyZo1K5UqVWL48OHpeu0ZrW+fBwW1TRt/tGh/o8dAFn79nTVSslk9e3UCYNWa/1m0933zfRYv+pH79+/TpnUPRocMYcn3s/HwcOfs2Qv06T2E9eu2WCFj2/BR0Ke8O+xNRo5/n+w5sxEVeY3vFi7l84lzzDEvB9YidPoo8+tJs8cC8Nkns5nxyewMz9madu39nfDIKFo2aWjR7uTkxG/7fufr75Zx9949fL1z0aBuTd7s1t5Kmdq20OGT6D+0NyPGDSZ7juxcjbzKDwuXMWvSV+aYXN45GBL8DjlyZedq1DV++W4NX0z+6jG9/jdo+p6IiIiIbTCYTCZ9YSgZytE5778HSYo8nF2tncJzK4/7f/tpYs/KoWPfWjuF51blMh2tncJz61DErmfa/zuF2v170CNMO78kHTORtIiJicHLy4vo6Gg8PdP5wSn9+6dvf7bgs8+e+JBXD+x4BolY1/JKNf496B8arjn0DDKxrnWNnvzBSDN//2+tf9m3YpMnP0jvDYDeG+TJpPbvtUZKiYiIiF3RSCkRERER26BVdkVERESegdDQUF588UWyZMmCt7c3LVq04MSJExYx9+7do1+/fuTIkYPMmTPTunVrIiMjLWLCwsJo0qQJ7u7ueHt7M2TIEO7fv5+RlyIiIiLyTKgoJSIiInbFiCnN25PYunUr/fr147fffmP9+vUkJibSsGFD7ty5Y44ZOHAgv/zyC99//z1bt27lypUrtGrVyrw/KSmJJk2akJCQwM6dO1mwYAHz589n5MiR6XY/RERERKxF0/dERETErjzNYprx8fHEx8dbtLm4uODi4pIsds2aNRav58+fj7e3N/v376d27dpER0czd+5cFi9eTL169YAHDzopVaoUv/32G9WqVWPdunUcO3aMDRs24OPjQ4UKFRgzZgxDhw4lODgYZ2fnp7gaEREREevSSCkRERGxK08zUio0NBQvLy+LLTQ0NFXnjY6OBiB79uwA7N+/n8TERAICAswxJUuWpECBAuza9WCx9127dlG2bFl8fHzMMYGBgcTExHD06NH0uiUiIiIiVqGRUiIiImJXnmah86CgIAYNGmTRltIoqWTnNBoZMGAANWrUoEyZMgBERETg7OxM1qxZLWJ9fHyIiIgwx/y9IPVw/8N9IiIiIs8zFaVERETErpieYgLfo6bq/Zt+/fpx5MgRtm/fnuZzi4iIiPzXaPqeiIiI2BXjU2xp0b9/f1asWMHmzZvJly+fud3X15eEhARu3bplER8ZGYmvr6855p9P43v4+mGMiIiIyPNKRSkRERGRZ8BkMtG/f3+WLl3Kpk2bKFy4sMX+ypUr4+TkxMaNG81tJ06cICwsDH9/fwD8/f05fPgwUVFR5pj169fj6emJn59fxlyIiIiIyDOi6XsiIiJiV55m+t6T6NevH4sXL2b58uVkyZLFvAaUl5cXbm5ueHl50aNHDwYNGkT27Nnx9PTk7bffxt/fn2rVqgHQsGFD/Pz86Ny5MxMmTCAiIoIPPviAfv36pWkaoYiIiIgtUVFKRERE7MrTLHT+JGbOnAlA3bp1LdrnzZtHt27dAJg8eTIODg60bt2a+Ph4AgMD+fzzz82xmTJlYsWKFfTt2xd/f388PDzo2rUrISEhGXQVIiIiIs+OilIiIiJiV4ymjBkpZUrFeVxdXZkxYwYzZsx4ZEzBggVZtWpVeqYmIiIiYhNUlBIRERG7kjElKRERERH5NypKiYiIiF0xqiwlIiIiYhP09D0REREREREREclwGiklIiIidiWjnr4nIiIiIo+nopSIiIjYlYx6+p6IiIiIPJ6KUiIiImJXtKaUiIiIiG1QUUpERETsiqbviYiIiNgGFaVERETErmj6noiIiIht0NP3RERExK6YTKY0b5LcjBkzKFSoEK6urlStWpU9e/Y8Mnb27NnUqlWLbNmykS1bNgICAh4bLyIiIv9tKkqJiIiISJosWbKEQYMGMWrUKA4cOED58uUJDAwkKioqxfgtW7bw+uuvs3nzZnbt2kX+/Plp2LAhly9fzuDMRURExBaoKCUiIiJ2xYgpzZtYmjRpEr169aJ79+74+fkxa9Ys3N3d+eqrr1KMX7RoEW+99RYVKlSgZMmSzJkzB6PRyMaNGzM4cxEREbEFKkqJiIiIXTE+xSZ/SUhIYP/+/QQEBJjbHBwcCAgIYNeuXanqIy4ujsTERLJnz/7ImPj4eGJiYiw2ERER+W/QQuciz5G4hHvWTuG5dSpBU0PSokCxptZO4bl1qlcJa6cgj6Cn76WPa9eukZSUhI+Pj0W7j48Pf/75Z6r6GDp0KHny5LEobP1TaGgoo0ePfqpcRURExDZppJSIiIjYFU3fsw3jxo3j22+/ZenSpbi6uj4yLigoiOjoaPN28eLFDMxSREREniWNlBIRERG7oqfopY+cOXOSKVMmIiMjLdojIyPx9fV97LGffvop48aNY8OGDZQrV+6xsS4uLri4uDx1viIiImJ7NFJKRERE7IrWlEofzs7OVK5c2WKR8oeLlvv7+z/yuAkTJjBmzBjWrFlDlSpVMiJVERERsVEaKSUiIiIiaTJo0CC6du1KlSpVeOmll5gyZQp37tyhe/fuAHTp0oW8efMSGhoKwPjx4xk5ciSLFy+mUKFCREREAJA5c2YyZ85stesQERER61BRSkREROyKFjpPP+3atePq1auMHDmSiIgIKlSowJo1a8yLn4eFheHg8NfA/JkzZ5KQkECbNm0s+hk1ahTBwcEZmbqIiIjYABWlRERExK5owfL01b9/f/r375/ivi1btli8Pn/+/LNPSERE5BlquOaQtVNId+saPX59x2dJRSkRERGxK1roXERERMQ2qCglIiIidkUjpURERERsg4pSIiIiYle0ppSIiIiIbVBRSkREROyKUdP3RERERGyCw7+HiIiIiIiIiIiIpC+NlBIRERG7onFSIiIiIrZBRSkRERGxK1roXERERMQ2qCglIiIidkVFKRERERHboKKUiIiI2BWTFjoXERERsQla6FxERETsihFTmrcntW3bNpo1a0aePHkwGAwsW7bMYr/JZGLkyJHkzp0bNzc3AgICOHXqlEXMjRs36NixI56enmTNmpUePXoQGxv7NLdARERExCaoKCUiIiLyjNy5c4fy5cszY8aMFPdPmDCBadOmMWvWLHbv3o2HhweBgYHcu3fPHNOxY0eOHj3K+vXrWbFiBdu2baN3794ZdQkiIiIiz4ym74mIiIhdMWXgmlKNGzemcePGKedhMjFlyhQ++OADXn31VQAWLlyIj48Py5Yto3379hw/fpw1a9awd+9eqlSpAsD06dN55ZVX+PTTT8mTJ0+GXYuIiIhIetNIKREREbErJpMpzVt8fDwxMTEWW3x8fJryOHfuHBEREQQEBJjbvLy8qFq1Krt27QJg165dZM2a1VyQAggICMDBwYHdu3c/3Y0QERERsTIVpURERMSuPM2aUqGhoXh5eVlsoaGhacojIiICAB8fH4t2Hx8f876IiAi8vb0t9js6OpI9e3ZzjIiIiMjzStP3RERExK48zdP3goKCGDRokEWbi4vL06YkIiIiYpdUlBIRERG7kpan6D3k4uKSbkUoX19fACIjI8mdO7e5PTIykgoVKphjoqKiLI67f/8+N27cMB8vIiIi8rzS9D0RERGxK6an+F96Kly4ML6+vmzcuNHcFhMTw+7du/H39wfA39+fW7dusX//fnPMpk2bMBqNVK1aNV3zEREREcloKkql0ZYtWzAYDNy6dcvaqaQotfkVKlSIKVOmZEhOIiIi9iY2NpaDBw9y8OBB4MHi5gcPHiQsLAyDwcCAAQP46KOP+Pnnnzl8+DBdunQhT548tGjRAoBSpUrRqFEjevXqxZ49e9ixYwf9+/enffv2evKeiIiIPPfSvSjVrVs3DAZDsq1Ro0ap7qNu3boMGDAgvVOzOX+/V87OzhQrVoyQkBDu37//1H1Xr16d8PBwvLy8AJg/fz5Zs2ZNFrd371569+791Of7L+jbpyunT/5GbMwZdm7/hRerVLB2Ss+dIUP6kZhwmYmfjrZ2Ks8N/d493nvD+hF+65jF9uueFeb9Li7OjP3kA46e3cnpS/uYs3AKOXPlsGLG1uHcoB2ZP1lqsbkPmW7e79K6D+7DZuIx9ls8Rs3HtVsQhlx5U+7MPQvuI2aT+ZOl4OqeQVeQsYwmU5q3J7Vv3z4qVqxIxYoVARg0aBAVK1Zk5MiRALz//vu8/fbb9O7dmxdffJHY2FjWrFmDq6uruY9FixZRsmRJ6tevzyuvvELNmjX58ssv0+dmiIiIiFjRM1lTqlGjRsybN8+iLb0XATWZTCQlJeHo+Hwvi/XwXsXHx7Nq1Sr69euHk5MTQUFBT9Wvs7NzqtaayJUr11Od57+ibdvmfPrJKN7qN4w9e3/nnbd7smrlIvzK1Obq1evWTu+5UKVyeXr17MShQ8esncpzQ793qfPnsVO81qKH+XXS3wr3o8cOI6BhHXp3G8jt6Nt8/MkHzP16Kq826mSNVK0qKSKMe1+OMr82JSX9te/SGRIPbMN06yoG9yw4N2iHW69RxIX2AZPRoh/Xtv0whl/AIWvODMs9o6X3NLzHqVu37mMXVjcYDISEhBASEvLImOzZs7N48eJnkZ6IiIiIVT2T6XsuLi74+vpabNmyZQMeTCtzdnbm119/NcdPmDABb29vIiMj6datG1u3bmXq1KnmUUTnz583T0dbvXo1lStXxsXFhe3bt2M0GgkNDaVw4cK4ublRvnx5fvjhB3PfD49bu3YtFStWxM3NjXr16hEVFcXq1aspVaoUnp6edOjQgbi4OPNx/9bv3925cwdPT89k+5ctW4aHhwe3b9/+13tVsGBB+vbtS0BAAD///DMAN2/epEuXLmTLlg13d3caN27MqVOnzMdeuHCBZs2akS1bNjw8PChdujSrVq2yuO5bt26xZcsWunfvTnR0tPmeBgcHA5bT9zp06EC7du0s8ktMTCRnzpwsXLjwie/L82Tgu72YM3cxCxZ+x/Hjp3ir3zDi4u7SvVt7a6f2XPDwcGfBws/o0/d9bt68Ze10nhv6vUud+0lJXI26Zt5u3LgFQBbPzLzeuTWjRoxnx7bdHPrjGAP7jeClapWoVKWcdZO2BmMSptu3zBtxf/3tub97PcZzxzDdvIrx8lkS1i7GIVsuDNm9Lbpw9A/E4OZB4tblGZx8xsrIkVIiIiIi8mgZvqbUw6l5nTt3Jjo6mt9//50PP/yQOXPm4OPjw9SpU/H396dXr16Eh4cTHh5O/vz5zccPGzaMcePGcfz4ccqVK0doaCgLFy5k1qxZHD16lIEDB9KpUye2bt1qcd7g4GA+++wzdu7cycWLF3nttdeYMmUKixcvZuXKlaxbt47p0/+a6pDafgE8PDxo3759stFh8+bNo02bNmTJkiXV98fNzY2EhATgwfS+ffv28fPPP7Nr1y5MJhOvvPIKiYmJAPTr14/4+Hi2bdvG4cOHGT9+PJkzZ07WZ/Xq1ZkyZQqenp7mezp48OBkcR07duSXX34hNjbW3LZ27Vri4uJo2bLlE9+X54WTkxOVKpVj46a/CqUmk4mNm7ZTrVplK2b2/Jg+bSyrV21k09/uoTyefu9Sr0iRAvx+fAu/HVzLjC8nkDffg6eUlatQGmdnJ37dussce/rUOS5dvEKVlypYKVvrcciZG/cP5uI+bCYurw/A8KiRTk4uOFaph/F6BKZb18zNBu98OAe8xr1vpyYbPfVfYysLnYuIiIjYu2cy923FihXJiiPDhw9n+PDhAHz00UesX7+e3r17c+TIEbp27Urz5s0B8PLywtnZGXd39xSnn4WEhNCgQQMA4uPjGTt2LBs2bDA/paZIkSJs376dL774gjp16piP++ijj6hRowYAPXr0ICgoiDNnzlCkSBEA2rRpw+bNmxk6dOgT9ftQz549zes45c6dm6ioKFatWsWGDRtSdc9MJhMbN25k7dq1vP3225w6dYqff/6ZHTt2UL16deDBmhL58+dn2bJltG3blrCwMFq3bk3ZsmXNOabE2dkZLy8vDAbDY6f0BQYG4uHhwdKlS+ncuTMAixcvpnnz5mTJkiVN9yU+Pp74+Phk12owGFJ1XzJCzpzZcXR0JCrymkV7VNRVSpYoaqWsnh+vvdacihXLUM2/ibVTea7o9y51ft93iHffGsGZ0+fw8cnFoKFvsWz119T1b463d07i4xOIibYcjXo16hq5vP+7U89SkhR2iqQl0zFdvYwhS7YH0/Pe+pi4ie9C/D0AHP0b4dKkCwYXN4xRl7g7ezQk/f9UyEyOuHYcRMLKhQ8KVdl9rHg1z55GPImIiIjYhmdSlHr55ZeZOXOmRVv27NnNPzs7O7No0SLKlStHwYIFmTx5cqr7rlKlivnn06dPExcXZy5SPZSQkGBeUPShcuX+msrh4+ODu7u7RRHHx8eHPXv2PHG/D7300kuULl2aBQsWMGzYML755hsKFixI7dq1H3s9Dwt4iYmJGI1GOnToQHBwMBs3bsTR0dHicc85cuSgRIkSHD9+HIB33nmHvn37sm7dOgICAmjdurXFdT4pR0dHXnvtNRYtWkTnzp25c+cOy5cv59tvv03zfQkNDWX0aMtFrw0OmTFk8kxznmI78uXLw6SJITR+5fVkxUeR9LBpw18jyY4fPcmB/YfYe2gDzVs24t5d/c49lHTiwF8vwi9wN+wkHsO/xLFcDe7v3QjA/d+3kXTqjwdFqzqv4tppMHdnBMH9RJxf6Ywx6hL3Dzy/o16fhEY8iYiIiNiGZ1KU8vDwoFixYo+N2blzJwA3btzgxo0beHh4pLrvhx5OM1u5ciV581o+ReifC6s7OTmZfzYYDBavH7YZjcYn7vfvevbsyYwZMxg2bBjz5s2je/fu/zoi6GEBz9nZmTx58jzRwu09e/YkMDDQPP0wNDSUiRMn8vbbb6e6j3/q2LEjderUISoqivXr1+Pm5mZ+cmJa7ktQUBCDBg2yaMuWo2Sa83sWrl27wf379/H2sRxZ4e2di4jIq1bK6vlQqVJZfHxysWf3GnObo6MjtWpV4623uuGRubD5vyuxpN+7tImJvs3ZM+cpXLggW7fsxMXFGU+vLBajpXJ55+Rq1LXH9GIH7sVhvHYFh5y5LdpM9+IwXQvnXthJPEK+xrFMVe4f3E6mYmVx8C2AY9kHI3P5/z9dHsELSdz0Awnrvs34axARERGR/zyrPLruzJkzDBw4kNmzZ7NkyRK6du3Khg0bcHB4sMSVs7MzSX97atCj+Pn54eLiQlhYWIpTx9Iqrf126tSJ999/n2nTpnHs2DG6du36r8c8qoBXqlQp7t+/z+7du83T965fv86JEyfw8/Mzx+XPn58+ffrQp08fgoKC/q+9O4+rMf3/B/46p1ULYSIZIntkX4bImDGaMrZhGGNn0CBEEcbSRIxtxm7GLmMdPg3Gvk4la/YlsmaNUFJK57x/f/h1viXMSHWfOq/n49GDrvuu8zp397nOOe9zXdeNRYsWvbEo9V+PaaNGjVCqVCmsW7cO27dvxzfffKMr4GXluJiZmWUqWOnT1D3g1WLuERFn8Fmzxti8eSeAVxk/a9YY8xcs+5efNmz79oWiZq3PMrQtXjQTkZFXMW36PBak3oHnXdZYWFrAoWxp/LluC86cOo+UlJdo0vQT/L15NwCgXPky+LiUPY4fPaVsUKWZmkNd1A6pJ9418kkFGL/q31+snAqVsalui7pUeZh38kLSgjGQR/dzOGzu4/Q9IiIiIv2QI0Wp5ORk3L+f8UWssbExPvroI2g0GnTt2hVubm7o1asXvvzySzg7O2PGjBnw9fUF8OqKcEeOHMGNGzdgZWWVYepfetbW1vDx8YG3tze0Wi0aN26MuLg4hIWFoWDBgv+pKJSdv7dw4cL4+uuv4evrixYtWuDjjz/O0u0DQIUKFdCmTRv07dsXv/32G6ytreHn54eSJUuiTZs2AIChQ4fC3d0dFStWxJMnT7B//35UqVLljb+vTJkySEhIwN69e1GjRg1YWFjAwsLijft+9913WLhwIS5fvoz9+/d/8HHJC36ZtQjLlvyCExFncOzYSQz26gtLywJYvmKd0tH0WkLCc5w/H5mh7fnzRMTGPsnUTpnxvPt34wJ8sXvHfkRH34WdXTH4jBoErUaD4D//xrP4BKwJ2ogJk0biyZM4JMQnYOLUMTh25CQijp9ROnquMv2qB1IvHIc8iYGqYBGYtvgW0Grx8lQIVEWKw7iGCzSXT0Gex0NVqChMm30NvEyB5uKraX8Sez/DhDaV5asLdGgfRAMvEt9wi3kbp+8RERER6YccKUrt2LEDJUqUyNBWqVIlXLp0CZMmTcLNmzexdetWAECJEiXw+++/o3PnzmjRogVq1KgBHx8f9OjRA05OTkhKSsL169ffelsBAQGwtbXF5MmTce3aNdjY2KB27dq6RdWzKqu/t0+fPli9ejV69+79QbcPvLp635AhQ/DVV18hJSUFrq6u2LZtm27kkkajwcCBA3H79m0ULFgQX3755VvX52rUqBE8PT3RqVMnxMbGYvz48ZgwYcIb9+3SpQsmTZoEBwcH3eLwaXLqeCttw4bNsP2oCCaM84GdnS1Onz6Pll91RYyhTwGiHMXz7t+VsC+O+Yuno3ARG8Q+eoyjhyPQsnlnxMY+AQCMHz0FWq0Wi1fOgpmpCQ7sC4Pf8ACFU+c+VaGiMP9uGFSW1pCEOGhuXETiXD/geTxgZASjsk4wadIKqgKWr7ZfO4/EeX6Q53FKR1eE5POrCxIRERHlFSoRjmHPTkFBQfD29sbdu3dhamr67z9ggIxNS/77TvRG+jXxMW9hR5c1thaFlI6QZ13pW0npCHmW1bT/5ejvdyia9YuC3Iw1rFF4+ig+Ph6FChVCXFwcChbM5gunDBqUvb9PH8yd+94/0iYiLAeCKOuv2i7/vtNrWuzIf4/3XV++f/+34OTfOZBEOT/UysIVo9k3AGDfkIZ9w3/zX5+vFVlTKj9KTEzEvXv3MGXKFPTv358FKSIiIj3Fz+OIiIiI9INa6QD5xdSpU1G5cmXY2dlh1KhRSschIiKit9BCsvxFRERERNmHRalsMmHCBLx8+RJ79+6FlZWV0nGIiIiIiIiIiPQap+8RERGRQeH0PSIiIiL9wKIUERERGRQti1JEREREeoFFKSIiIjIowrWhiIiIiPQCi1JERERkUDh9j4iIiEg/sChFREREBoVX0SMiIiLSD7z6HhERERERERER5TqOlCIiIiKDwul7RERERPqBRSkiIiIyKLz6HhEREZF+YFGKiIiIDApHShERERHpBxaliIiIyKBwoXMiIiIi/cCiFBERERkUjpQiIiIi0g8sShEREZFB4ZpSRERERPpBrXQAIiIiIiIiIiIyPBwpRURERAZFuKYUERERkV5gUYqIiIgMCqfvEREREekHFqWIiIjIoHChcyIiIiL9wKIUERERGRRO3yMiIiLSD1zonIiIiAyKiGT5KyvmzZuHMmXKwNzcHA0aNMDRo0ez+R4p633v34YNG1C5cmWYm5vD2dkZ27Zty6WkREREpG9YlCIiIiKDkptFqXXr1mHYsGEYP348IiIiUKNGDbi5uSEmJiYH7lnue9/7d+jQIXTu3Bl9+vTByZMn0bZtW7Rt2xbnzp3L5eRERESkD1iUIiIiIsohM2fORN++fdGrVy84OTlh4cKFsLCwwNKlS5WOli3e9/7NmjULX375JXx9fVGlShUEBASgdu3amDt3bi4nJyIiIn3ANaWIiIjIoHzIilLJyclITk7O0GZmZgYzM7NM+6akpODEiRMYNWqUrk2tVqN58+YIDw//gBT6ISv3Lzw8HMOGDcvQ5ubmhuDg4LfezuvHPC4uDgAQHx//AenfIiUl+3+n0rJwnF4mPM+BIMrKyvmS+jwhB5IoKyvHISkhMQeSKCdLfQf7BgDsG9Kwb3i/3/lvI81ZlKJcl5pyR+kIb5WcnIzJkydj1KhRb3yDQW/G45Z1PHZZx2OXdYZ+7D7keWjChAnw9/fP0DZ+/HhMmDAh076PHj2CRqNB8eLFM7QXL14cly5dynIGfZGV+3f//v037n///v233s7kyZMzHXMAKFWqVBZSG6BFi5ROoBcKKR1AT/A4AMOVDqAv2DcA4GMiTU4eh2fPnqFQobffgkp4XWQinfj4eBQqVAhxcXEoWLCg0nHyDB63rOOxyzoeu6zjscu69xkpdffuXZQsWRKHDh1Cw4YNde0jRozAwYMHceTIkRzPm5Oycv9MTU2xYsUKdO7cWdc2f/58+Pv748GDB2+8ndePuVarxePHj1G0aFGoVKpsvEe5Jz4+HqVKlUJ0dLTBPgZ5DF7hcXiFx+EVHodXeBzyxzEQETx79gz29vZQq9++chRHShERERH9R28rQL3JRx99BCMjo0zFlgcPHsDOzi4n4uWqrNw/Ozu79z4ebzrmNjY2WQutZwoWLJhn32xkFx6DV3gcXuFxeIXH4RUeh7x/DN41QioNFzonIiIiygGmpqaoU6cO9u7dq2vTarXYu3dvhpFFeVVW7l/Dhg0z7A8Au3fvzhfHg4iIiN4fR0oRERER5ZBhw4ahR48eqFu3LurXr49ff/0Vz58/R69evZSOli3+7f51794dJUuWxOTJkwEAQ4YMQdOmTTFjxgy0bNkSa9euxfHjx/H7778reTeIiIhIISxKEaVjZmaG8ePHG+TCvx+Cxy3reOyyjscu63jsck+nTp3w8OFDjBs3Dvfv30fNmjWxY8eOTIt951X/dv9u3bqVYR2JRo0aYfXq1fjxxx8xevRoVKhQAcHBwahWrZpSd0ERfAzyGKThcXiFx+EVHodXeBwM6xhwoXMiIiIiIiIiIsp1XFOKiIiIiIiIiIhyHYtSRERERERERESU61iUIiIiIiIiIiKiXMeiFBERERERERER5ToWpYiIiIiIiIiIKNexKEUGLyQkBF27dkXDhg1x584dAEBQUBBCQ0MVTkZElH3Y1xHlH1qtFgDAi2jzGBDlprS+R0kPHz5UOgJlMxalyKBt3LgRbm5uKFCgAE6ePInk5GQAQFxcHAIDAxVOR0SUPdjXEeUvavWrl/DR0dEKJ1FOQkICAEClUrEwZSDCwsL0oihiyNL6nsjISEUedxMnTsSQIUMM+jxIew2Xn7AoRQZt4sSJWLhwIRYtWgQTExNdu4uLCyIiIhRMlndw9MV/Ex8f/5+/6N14zr0/9nVE+c/WrVvRqFEj3L59W+koue7ChQsoV64clixZAoCFKSD/jxg7deoUmjRpgoCAAIMuSOiDP/74A9988w1UKlWu3Wba+X3o0CE4OTnpimOG5sSJE2jXrl2+Gy1mmH9Nov8vMjISrq6umdoLFSqEp0+f5n6gPIajL/47GxsbFC5c+J1fafvQ2/Gcyxr2dUT5T4ECBVCwYEHcvXsXgH5Mq8kN0dHR6Ny5M8zMzODr64ulS5cCMNzCVNp9TkpKemN7flGzZk0sXLgQgYGBCAwMNJjzXR81bdoUt27dwuLFi3PtNtP+3nFxcTA3N8+129Unp0+fhqurKypVqgRbW1tde354rBsrHYBISXZ2doiKikKZMmUytIeGhsLR0VGZUHlI2uiL7t27Y+3atbp2FxcXTJw4UcFk+mf//v1KR8gXeM5lDfs6orxNq9VmGhnw+eefw8HBAb6+vjh48KBBjBxITU3FmjVrUL58efzwww/Yu3cvhg4dCgDo3bs3VCrVG49VfqZSqbB9+3bMnz8fpqam+OKLL9CtWzdYWlpCRHJ1NEtOWLRoEapWrYpPPvkE/fr1g1qtRv/+/QEAo0ePNqi/tRJefzy9fPkSxYoVQ5cuXRAaGooePXrAyMgoR/8OCQkJsLKyAgCkpKTkiyLM+zp9+jQaNmyIYcOGZXq9m9cf4wCLUmTg+vbtiyFDhmDp0qVQqVS4e/cuwsPD4ePjg7FjxyodT+9x9MV/17RpU6Uj5As857KGfR1R3pb2hi8xMREWFha69rFjx8LLywt79uxB8+bN80UR4l2MjY3x+eefo2TJkmjevDmcnZ0hIhkKU2q1Ot8fh/QOHTqENm3aYODAgTh16hRWrFiBI0eOYPbs2bC2ts7Tx0JE4O/vDysrK6xatQq1a9fG999/DwAsTOWStGN748YNlClTRrcEQIsWLfDNN9+gf//+aNiwYY7d/pQpU3DixAnMmDEDpUuXhkajgY2NDQDozm2tVguVSqUbLZlXz/e3OXv2LJo0aYLhw4cjICBA1z5mzBg8evQIv/32m4LpsokQGTCtVisTJ04US0tLUalUolKpxNzcXH788Uelo+UJZcuWld27d4uIiJWVlVy9elVERFasWCFVqlRRMlqe8Pz5c7l48aKcPn06wxe9Hc+5rGFfR5T3LVy4UOzt7cXf318uXbokIiLx8fHSoEEDGTBggMLpctaZM2dk8ODBkpqammnbnTt3ZNSoUWJtbS2LFy8WEZHk5GTZvXu3PH36NLej5qrLly/LtGnTZMaMGSIikpqaKrNnz5aGDRtKt27dJD4+XkRENBqNkjGzRKvViohISkqK1KxZU6pWrSpHjx7V3ZdFixaJWq2WgICAPHn/9F3a8RcRWbVqlTg6Osrw4cPl4sWLum1du3aVjh076s6znLBt2zZRqVTSo0cPiYqKkooVK0pwcPBb909ISMixLEp4+fKluLm5iUqlksePH+vap0yZIkWLFpXNmzcrmC77sChFJK9evJw/f16OHDkiz549UzpOnhEYGChOTk5y+PBhsba2lpCQEFm1apXY2trK7NmzlY6nt2JiYqRly5aiVqvf+EVvx3Puw7CvI8o70r/RTkpKkocPH8rIkSPFw8NDLC0tZcSIEXL8+HH5559/pHjx4nL48GEF0+acU6dOiZmZmUyYMCFDe/rjc/v2bV1h6vfff5fhw4eLpaWlPHjwILfj5prLly+Lq6urlCpVSpYuXaprT05Oljlz5sgnn3wiPXv2lLi4OAVTfpiXL1+KyKvCVLVq1ViYyiXpj2VKSopcunRJFi9eLOXLl5dPPvlEWrVqJefPn5cpU6ZIkyZN5N69e5l+7kNNmzZNTp48KSIi+/btE2NjY+ndu7eULVtWSpUqJe3atZNmzZpJs2bN5KuvvhI3NzepUqWK/Pnnn9mWQV9ERUVJpUqVpHHjxqLRaOTnn3+WIkWKyK5duzLt+6bCfV7AohQZtKCgIHn+/LnSMfIsjr7Imu+++05cXFzk2LFjYmlpKbt27ZKgoCCpVKmSbN26Vel4eo3nXNawryPKW9K/uZs6daqMGTNGrl+/LiKvRgIEBQXJV199JQ4ODlKvXj0pWbKk/PrrryKSd9+UvMmpU6fEwsJCRo0a9a/73rlzR/z8/ESlUomNjY0cPXo0FxIqJz4+Xnx8fMTe3l46dOiQYWRLSkqKzJ8/XypXriyenp4ZtuU1KSkpun/fVpgyMzMTPz8/FqayQfpjOH36dOndu7fcvHlTRESePXsmf/75p7Rs2VKcnJykU6dOolKpZPjw4dma4dGjR1KzZk1p0aKFbnTQvn37xNzcXFQqlbRr105Gjx4tAwcOFE9PT/Hz8xNfX18ZM2ZMtubQJ9euXZOyZcuKra2tFC1aVDdrIP1je+HChbJ9+3alIn4QFqXIoH300UdiaWkpnTt3lr///jtfvZDLTRx98X7s7OzkyJEjIiJibW0tkZGRIiLy119/iYuLi5LR8gyec++HfR1R3jRixAgpVqyYLFmyRO7cuZNhW2xsrJw9e1Y6duwoDg4OUrp0aXny5IkyQXPA2bNnxdraWvz8/DK0/+9//5MzZ8688We+++47KVSokJw/fz43IuaqNxWWnj17JuPGjZMaNWrIyJEjdQUckVdFnN9//11XzMxL3lZES0lJkapVq2YqTM2ePVuKFi0qDx8+zM2Y+dqIESOkePHisnTpUomKisq0fePGjRIYGCh2dnZSo0YNuXbtWrbe/rx588TJyUnWr1+v+zsfPnxYTE1N5fvvv5fY2Ni3/mxeL06m5X/93+vXr0uDBg2kQoUK8ujRoww/M27cOFGpVHLx4sXcDZtNWJQig/by5UvZsmWLfPfdd2JpaSm2trYyYMAACQsLUzpansDRF1ljbW2te5FYunRpCQ0NFZFXn4IUKFBAwWT6j+dc1rCvI8p7tm3bJh9//HGmET+vv+HSaDRy9OhRadSokcydO1dE3v6mPi/x8fERlUolO3bs0BVbJk2aJKamppmKUlqtVpYsWSJFixaVEydOKBE3R6X9PQ8fPiy//vqrzJgxQ/bv3y8ir0bOjRkzRurXry8jR47UTXnLq9Lu64EDByQgIED69Okj4eHhuiJE+sLUsWPHdI+H/FSQVdqePXukdOnScvDgwUzbXv9Q68KFC/LRRx/JwoULP/h2X//dn376qdSrVy9D2/79+8XY2Fh69Ogh0dHRH3yb+ub8+fPi6ekpR44cyfBYTl+YKl++vDRq1Ej3QcW4ceOkQIECcvz4cUUyZwcWpYj+v+fPn8uqVavEw8NDTE1NxdHRUelIeo+jL7Kmbt26smPHDhERadWqlXTr1k1u374tI0aM4Hn3L3jOfTj2dUR5w7Jly6Ru3boSHx+v6+vS3rC/XnhITU2V9u3bS48ePXI7Zo7q3LmzFC5cWEJCQmTSpElia2ure/583dmzZ7N9tIY++fPPP6VgwYLyySefSM2aNUWlUsmYMWNEo9FIQkKCjB49WlxcXGTgwIF5vjC1adMmsbGxkdatW4u7u7sULVpUpk6dqvtALyUlRWrUqCH29vb5sgiptEWLFkn16tUzfAiY1vekFUe0Wq2uWDxs2DBp06ZNhpF672v69OkydOjQDBcniIqKksKFC2eaHvjPP/+IqamptGnTJl8VI1NTU8Xd3V3MzMykVKlS4unpKbNmzRKRjB80XL9+XcqVKyeff/65DB06NM8XpERYlCLK4OHDhzJnzhypWrUqF5z+Dzj6ImuCgoJk2bJlIiJy/Phx+eijj0StVou5ubmsXbtW2XB6judc9mBfR6T/Jk6cKMWLF9d9n1Zo0Gg0sn//ft00jbQ3Kz/88IO0aNFCXrx4kedHSqUvqnzzzTeiUqnE2tpatm3bpmAq5URGRoq9vb0sWrRINBqNJCcny8qVK8XExETGjRsnIiJxcXEyZMgQad68eZ5e4P3w4cNSsmRJ3eLtGo1GTExMxM7OTsaPHy+3bt0SkVfT+Bs2bKi7Ci99uLR+Y/HixVK5cuUMU4a1Wq1oNBr5448/5PLlyxl+rnXr1tK2bdssF0NjY2OlSJEiolKppHLlyrJz507d39nf319q1qypGxmYVhTbtWuX9OzZM0u3p88WLFgg/v7+cvToUZk9e7aUKlVKvvzySwkMDMwwZfH69etSsmRJUalUEhERoWDi7MGiFBm8tFED7u7uYmpqKuXKlZMff/wxz87JVQpHX2Td8+fP5cSJE1wL4T3xnHs/7OuI9NPb1j85d+6cODo6ire3d4Yi09OnT+WLL77IcMW1kydPSu3atXVXq8oP0o+E7devn5iYmMi2bdskOTlZwVQ5b9asWXLhwoUMbceOHZOKFSvKtWvXMpwLy5YtE7VaLYcOHRKRV1P5YmJicjVvdtJoNLJ+/XoZOXKkiLxa1sDBwUEGDx4s/v7+olarZeLEiXLlyhWFk+YPb+t7wsLCxMzMTKZMmSIvXrzQtScmJoqHh4f88ssvIvKqUHXv3j0pV66cHDt2LEsZ0s7n+fPny4ABA6R3797SokUL6du3r+zZs0eePHkiFStWFC8vL13m14tfeb0In96FCxekUKFC8tdff4nIq/s7a9YssbS0FEdHR5kyZYpu2Y+bN2/KjRs3lIybbViUIoPWqVMn3WiLgQMH6p7UKWs4+uLfpaSkiKOjY6YXnJQ1POf+G/Z1RPop/ZvC48ePS3h4uO7iF4mJiTJu3DipV6+e9OzZUy5fvix79uyRli1bSq1atTK9MXt94dv8IH1hqmPHjmJjYyPBwcH5sjCl1WolISFBKlWqlGkkyqFDh0SlUumm6KT97dPesKeNvs6LXp+SeuvWLTl//rwkJSWJm5ub9OnTR/c4KVWqlFhbW8vPP/8sL1++zFfFiNyWvu85duyY7N69W86dO6d7bE2bNk1UKpX4+fnJ1q1bJSQkRL744gupWbNmpr4nO9b6PHXqlDRr1kw2bNggkZGR4u/vL8WLF5c5c+bItGnTRK1W60ZL5ae/+/Xr13UFqDTTpk2Ttm3b6qYydunSRapUqSK+vr7SokULUavVMmzYMCXi5hgWpcigfffdd1yX5gNx9MX7s7e3Z1HqA/Cce3/s64j0T/o3VmPGjBEHBwepUKGCmJmZycyZM+XFixcSHx8v8+fPl+rVq4u5ublUqVJFmjdvrlu7JTU1Nc9faerfvF6YsrW1lfXr13/Q+jX6KO18SLu/4eHhcvbsWV17q1at5LPPPsvwXJeUlCQ1a9aUFStW5H7gbJB233bt2iXjx4+Xmzdv6rbdvHlTqlevLlu2bBERkXv37km3bt1k9OjRHCn1gdL3PX5+flK5cmUpWrSoNG3aVDw9PSUpKUlEXq0tVaVKFSlatKjUqFEjU9/zIebPny+TJ0/O0LZixQopWLCg7jVyeHi4VK9eXb777jtRqVRSsWJFuX///gfdrj65c+eOfPTRR1KlShVZtWqVrn3nzp1Sq1YtuX//vvTr10/s7Ozk1KlTIiISHR0t69evz3dXGGVRioiyjKMvsmbSpEnSo0ePPL8QqRJ4zhFRfhMQECAlSpSQffv2iYjIgAEDxMzMTMaMGSOJiYm6/Y4cOSLXr1/XFaEM6Tkk/Rtgd3d3KVOmjDx79kzBRDnn5cuXkpKSIiVKlJCaNWvq3nxu3rxZvvjiC3F1dZWQkBA5efKkjB49WooVK6ZbADwv2rhxo1hbW8vw4cMzFNxOnjwpJUqUkN9//12uXr0qEyZMkIYNG/IKvNkoMDBQ7Ozs5MCBA5KSkiI//PCDWFhYSMeOHXXHOTo6WqKiouTy5cvZ0vdotVq5e/eu9OjRQ4yNjaVly5ayfft23QgtLy8v6dKli9y9e1dEXhVuZs+eLVWqVJHOnTt/4D3WL/v37xe1Wi316tWTNm3aZBjxmLaWXokSJeT06dPKhcwlKhEREBmQ2bNno1+/fjA3N8fs2bPfue/gwYNzKVXe1KVLF3Tp0gVubm4wMjJSOk6e0a5dO+zduxdWVlZwdnaGpaVlhu2bNm1SKJn+4zn337GvI9JPWq0WarUaAHD58mUMHToU/fv3R5s2bRAcHIzevXvDw8MDq1evxpgxYzBgwACUKFHirb8jLxMRqFQqXLlyBUlJSXj+/DkaNmyYaTsAaDQaXb9/584dlCxZUpHMOSXtvr548QLm5uZ48OABGjZsCDs7O6xYsQIVKlTAtm3bsGTJEvzvf/9DpUqVoNFosG7dOtSqVUvp+Fly4cIFuLm5Yfz48fj+++8zbR88eDCWLl0KOzs7PHv2DNu3b0ft2rUVSJo/pO83rl+/ju+++w5jx46Fh4cHdu/ejXbt2qFdu3Y4duwY6tSpgyVLlsDc3Pytv+NDnT59Gn379kVSUhJq1qyJuXPn4sKFC/jll1/Qq1cvuLu7A3j12H/06BGKFy8OIGO/kNf16dMHERERKFeuHJ48eYLu3bujR48eOH78OLp27Yrx48ejc+fO+abPfxsWpcjglC1bFsePH0fRokVRtmzZt+6nUqlw7dq1XExGhqJXr17v3L5s2bJcSkL5Gfs6Iv2T/s3U5cuXUbFiRaxcuRIdO3bEiRMn0KlTJ4wcORJeXl74/vvvsWbNGvTr1w8TJkxAoUKFFE6fvdKOxcaNGzFs2DAYGRnh4cOHcHV1xfjx41GvXr1MbzzTF6byk7RjceDAAYSGhqJz584oV64cHj58iNq1a6NUqVK6whQAnDlzBgUKFEChQoVQrFgxhdNn3b59+zBs2DBs374dxYoVg5GRUaY337t374ZWq0XlypXh4OCgYNq8LX3fc/jwYTRo0ADr169H06ZNcfXqVXzzzTfw9/dH37598d1332H9+vVo1qwZtm7dCjMzs2zJsGbNGhw7dgxhYWGoWrUq3N3d0b59e8yZMwdLlizB06dPMWPGDKxYsQKpqanYsWPHO+9HXpacnAwzMzNs27YNGzZsQOfOnfHbb7/h4cOHGDBgAL799lu4uLjA0dERQUFBSsfNcSxKEdF74egLym0854goP0j/Znvw4MFYsmQJYmJioNVqYW1tjSFDhiA2NhZLliyBmZkZRowYgfDwcGi1WoSGhuaLN2KvO3ToENzc3DBr1izUqVMHANC5c2cUKVIEs2fPRu3atfPNm9C3SV+c69WrF3x9fdG6dWtUr14dKpUKMTExqF27NkqXLo1FixbByckp3xyPlStXol+/foiNjYWlpWWGouPx48dhZ2eHjz/+WOGUeV/6x9CoUaOwd+9e/PnnnyhdujQAYNiwYUhISMDcuXNhamqKn376CSEhIahWrRpmzJiRLSN0fH19sWHDBnzyySewsrJCSEgIrl69qivGJCYmYsiQIThx4gSqVauGTZs2YeTIkZg8efIH37a+iI6OxvHjx9GuXTtdW1ohftCgQejYsSM8PT0RExODMWPGoGDBgvDw8MCqVavw1VdfKZg8F+T2fEEifeLv7//GuemJiYni7++vQCL9V6ZMGd0VfsqUKfPWr7JlyyqcVH81a9ZMnjx5kqk9Li5OmjVrlvuB9BzPuQ/Hvo5If1y+fFl69eolBw8eFJFXa6y8fPlS3NzcpGfPnrp1W9q0aSOHDx/W/Vx+uuJU2n2ZOnWqNGnSJMOV1NKuKNe2bVslI+ao1xdpP3z4sBQtWlQWLVqUof3hw4ciIvLgwQNxcHCQatWq5auLety4cUMqV64sI0aM0F1pLG39sJ49e8qUKVPy/UL+uenKlSvyxRdf6PqeNB07dpSmTZuKyKvHZocOHWT+/Pm67R/6N5gxY4bY2dnJsWPHMlxlccaMGVKgQAFp3769bt/ly5dLjx49RKVSiZeX1wfdrj65deuWFC1aVFQqlXh4eMi6det0V1rdvHmzNGnSRGJiYuTChQvy9ddfyxdffCHDhw+Xdu3aya1btxROn/M4UooMmpGREe7du5dp6HNsbCyKFSsGjUajUDLKz9RqNe7fv5/pvIuJiUHJkiXx8uVLhZJRfsW+jkg/rFmzBuPGjUPhwoWxbds2FClSRDcKYe7cuRg8eDBatWqFGzduQKPR4NSpUzA2Ns43o4XS7seJEydQp04djBkzBtu2bcPJkycBAElJSShQoADCwsLQsmVLhISEwNnZWeHU2Wv48OGoWbMmunXrpjses2fPxqZNm3DgwAE8f/4ce/bswcqVK3H16lUMHDgQffv2xf3799G8eXNs3boVZcqUUfpuvJe0+3n8+HFcuHAB8fHxaNCgAerVq4dx48Zh165daNiwIcaMGYPY2FgEBQXh999/x8GDB1GlShWl4+cLU6dOxYYNG1CoUCGsWbMGtra20Gq1UKlUWLJkCRYsWABTU1MAQFxcHM6cOfPBfY+IIDExEe3atcNXX32FwYMHI630oFKpEBcXh2XLlmHUqFGYPHkyhg4dCgB48OABLl26hKZNm+p+T17v/27evIkOHTrAxMQEycnJqF27Nnbv3o3Ro0fDxsYGQUFBGDBgANzd3XH+/HkMHToUJUuWxKRJk/Ld+nlvYqx0ACIlva2TO336NIoUKaJAorzlp59+go+PDywsLDK0JyUlYdq0aRg3bpxCyfTTmTNndP+/cOEC7t+/r/teo9Fgx44dBvHE8yF4zmUN+zoiZaRN2Uv7NykpCXZ2djh37hxSU1OhVqvx8uVLmJiYYNCgQTAxMcHhw4fh6OiIadOmwdjYOF+to6RSqfD333+jVatWOH78OL766ivMnDkTv//+O/r164cCBQoAeNVn2drawsrKSuHE2c/MzExXaNNqtTAyMoKtrS1u3bqFgIAAhIaGwszMDKampvjyyy/Rv39/1K9fHzVq1MCZM2fy5GLHadMT+/XrhyZNmuDWrVtYunQp2rdvj/Hjx0OtVmPr1q0oXrw4qlSpgqSkJOzcuZMFqQ/w+tpcTZs2RUBAAF6+fIkrV67A1tZWt71jx45Qq9U4duwYzMzMMH369Gzpe1QqFZ4+fYqjR4/C29s7QzsAFCpUCB07dsTKlStx4sQJ3fbixYvrFjXPLwt8Ozg4YPXq1fDz84NWq4WHhwdatmyJWbNmwcbGBn///TcePnyIzz//HFWrVsXs2bNhbW1tOO8LFBmfRaQwGxsbKVy4sKjVat3/074KFiwoarVaBgwYoHRMvadWq+XBgweZ2h89eiRqtVqBRPpNpVKJWq0WtVotKpUq05eFhYUsWbJE6Zh6jefc+2FfR6Qfjh8/LiKvpsH8+eefUrVqVWncuLHcv39fRDJeYj39VJkPufS6PoqOjpaff/5Z5s6dKyIiz549k1GjRomjo6MsWLBARESeP38uY8eOFScnJ4mJiVEybrZ6ffrl9u3bZfHixfLy5Uu5ceOGDBs2TJydnaV///4SGhoqIq+metarV083zSevTuE8c+aM2Nvby8KFC0VEJCIiQszNzcXPz09EXp3zcXFxsnnzZjl69KjcvXtXybj5ypEjR3SPozNnzoiVlZW0atVKrl+//s6fy66+Jz4+XmxtbWXSpEmZtqWdzz/++KNUrVpVXr58me/6vNddunRJ3N3dpUWLFhIZGSkJCQkSHh4uX331lQQFBYlI3n2cfwiOlCKD9Ouvv0JE0Lt3b/j7+2e4oo2pqSnKlCmT4ZLE9GbC0Rfv5fr16xARODo64ujRo7C1tdVtMzU11V15ht6O59z7YV9HpLzQ0FC4urpi1qxZ8PLywtdff43U1FTMmzcP3bt3x8qVK1G8eHHdiKn0owKMjfPPS/Xz58+jY8eOSE5Oxty5cwEAVlZW6N27N9RqNby9vfHLL7/AysoKt27dws6dOzM8T+Z1rz93bd++HXPmzIFarUavXr0wY8YMPH36FDY2Nrp9VqxYgcTERF2bvk9hetuolsuXL6N06dLo378/rl+/jnbt2qF79+66RawvXLiAatWqoVWrVrkdOV/buXMn+vTpg6FDh6JXr15wdnbGgQMH4OrqihEjRmDatGm6Kxq+/rfLrr5HpVLBwcEBf//9Nzp16oRy5coBgG4aHwA8efIEDRs2hLGxMVJTU7PldvVVpUqVMGvWLAwaNAheXl4YN24cXFxcsGXLFt0++v44zwn555mO6D306NEDwKtLpjdq1AgmJiYKJ8pbChcuDJVKBZVKhYoVK2boPDUaDRISEuDp6algQv2U/omf3g/PuaxhX0ekvKpVq2LcuHEYNmwY1Go1Bg4ciI4dO0JEsGDBAvTs2RNLly5FiRIllI6ao5KTk1G9enX89ddfiI6O1rWXL18eY8aMwTfffIPdu3fD1tYWTZo0gaOjo4Jps1/ahyr379+HnZ0dZs2aBVNTU/Tv3x9arRadO3fWFZ8OHDiA9evXY+3atdi3b1+m9QD1UVpRIzo6Grt27YJWq0XlypXRpEkTmJiYoHjx4oiOjoarqys8PDwwf/58AEBISAh27dqFokWL5vvHQG5zc3NDy5Yt8ccff0CtVqN79+6oU6cO/vnnHzRt2hRqtRqBgYFwdHTMsSlyVlZWmDp1Klq0aIGAgACMGzcOjo6OutdxMTEx2Lt3L+7du4djx46hW7duGDBggG4qb35UoUIF3RqCAQEB+PHHH9G4cWOlYymKC50T/X8vXrxASkpKhraCBQsqlEa/rVixQjf64tdff+Xoi/e0cuXKd27v3r17LiXJO3jOvb/4+HhdHxYfH//OfdnXEWWPt43mfPr0KWbPno0JEyZg7ty5GDBgAEQE69evh7+/P9zc3PDLL78okDjnpB2Ls2fPQq1Wo2rVqjh//jwmTpyIf/75B/PmzUPbtm0BIF+tm/Umacdi69atmDVrFrp06YKePXsCAHx8fDBnzhwsWLAA3377LZKSkvDrr7/i3LlzCAgIQLVq1ZQN/x+kFaTOnDmD1q1bo3jx4rh69SpsbGwwc+ZMVK9eXfeBkqenJ2bNmqX7WS8vL9y4cQOrVq3K8NxO7yd93/P642ngwIEICQlBz5490aNHDxQtWhQRERGoW7cuRo8ejYkTJ+Z4vvnz52Po0KFo3Lgx2rVrh2bNmuHSpUsICAhAkSJF0L9/fxgZGcHV1VW3nlR+d+XKFQwbNgyPHj3CL7/8gk8++UTpSMrJ9QmDRHrk+fPnMnDgQLG1tdWt9ZP+i97twIEDmS5rTP/OxsYmw5elpaWoVCoxMzOTwoULKx1Pr/Gc++/Sr7+Vfj2z9F9p7USUvaZPny5r167N0PbkyRPx9/cXlUolixcvFpFXa+ns3r1bUlNTlYiZY9LWRNm4caOUKFFCJk+eLLdv3xYRkZMnT0qPHj3EyclJ/vrrr0w/k18FBweLmZmZ/PrrrxIREZFh2/Dhw8XU1FSWLl0qIiJPnz6Vp0+fKhHzvaWtgXb69GmxsLAQPz8/ef78uezevVvs7e3F3d1dREQWL14sJiYmMnXqVLl586ZERUWJr6+vFC5cWM6dO6fkXchXFi1aJMuWLZOkpKQM7T/88IOUKlVKfvnlF3n06JGIiERGRubaGk5arVZ27NghlStXFisrKzEyMpIGDRpI//79c+X29dXFixelQ4cOcvPmTaWjKIojpcigDRw4EPv370dAQAC6deuGefPm4c6dO/jtt98wZcoUdOnSRemIeQZHmn2YK1eu4IcffoCvry/c3NyUjqNXOOInaw4ePAgXFxcYGxvj4MGD79w37bLLRJQ1km6UQkJCAn744Qds3LgRa9asQZs2bXT7PXz4EJ07d8a+ffswc+ZM3SXQgfw3Wmj//v1o3bo1Zs6cia+//hpFixbVbYuIiMDs2bNx8uRJ/Pjjj/jmm28UTJrzHj58iNatW6Nt27YYOXKkrj0lJQWmpqYAAF9fX8yYMQMrV65E165dlYqaJdHR0ahduzaaNWuG9evX69rr16+Pp0+f4tixYzA2Nsa6deswcOBAFC9eHBYWFlCpVFi1ahVq1aqlYPq87fW1oJo1a4YHDx5g/PjxaNOmDczNzXXbXF1d8eDBA3z33XcYMmSIbrpoampqrq1f9+TJEyQmJiImJgYlS5bUTU3Nb/3f+0jfDxgqFqXIoJUuXRorV67Ep59+ioIFCyIiIgLly5dHUFAQ1qxZg23btikdUa8lJiZixIgRWL9+PWJjYzNt12g0CqTKu44fP46uXbvi0qVLSkfRK0ZGRrh37x6KFSsGtVr9xqkxaW8Iec4RUW5L/6YwKioKZcqUwaNHjxAYGIgVK1Zg+fLlaNeunW5/Ly8vhIeHo0CBAvjnn38A5K+FbdP6Yy8vLzx+/Bh//PGHblv6N79nz57F+PHjce/ePezevRuWlpb56jikd+PGDbi4uGDRokXw8PDIsC19QXP06NHo1q0bqlSpokTMLLtx4wY6duyIEiVKYMSIEXBxccHkyZMxZswY1K1bFyVKlEDRokXx1VdfwcbGBklJSXBwcICtra3BTNXKCen7nsjISFSqVAkA0L59e1y5cgWjRo1C27Ztdesz9e/fH7t378Znn32GRYsW6c3jTd4y7ZkMBxc6J4P2+PFj3UKaBQsWxOPHjwEAjRs3xg8//KBktDzB19cX+/fvx4IFC9440ozej7GxMe7evat0DL2zb98+3ZX19u/fr3CavGnHjh2wsrLSLaQ5b948LFq0CE5OTpg3bx4KFy6scEKivCn9m8Jx48YhIiICvXv3xtdffw1vb29otVr06tULRkZGaN26NV68eIFHjx5h7NixuhFU+e3z4bQ3lxcuXNC9SU47TmkFqevXr8PZ2Rn+/v4oWrQorKysFMubk9LebGu1WlhaWuLJkyeZth06dAiRkZHo3bs3AgMDFUybdWXKlMEff/yBwYMHY+rUqShWrBj++usvrF+/HvXr18eJEydw7tw5eHp6wtLSErVr18bGjRuVjp2npe97JkyYgL///hsTJ06Em5sbNm7ciLZt22LKlCnQarVo2bKlrhi4fPlyNG7cGCqVSm+KQfqQgZTFkVJk0KpXr445c+agadOmaN68OWrWrInp06dj9uzZmDp1Km7fvq10RL3GkWZZs3nz5gzfiwju3buHuXPnolSpUti+fbtCySi/cnZ2xs8//wwPDw+cPXsWdevWxfDhw7F//35UrlwZy5YtUzoiUZ42duxYLFiwACtXrkSdOnV0oz9u3ryJX3/9FbNmzcKnn36Khw8fwtjYGMePH4eRkZHevCnMCYMHD8bOnTsREhKCYsWK6d5E3717FwsXLkTXrl1RsWJFpWNmu/R/0/T/d3Nzw7179xAcHJzhyoJ+fn6IjIzEypUrYW1trUjm7HL58mUMGjQIISEhCAgIgI+PT4btsbGx2L9/P2rUqIEKFSoolDJ/GTduHH777TcsXrwYtWrVwscff6zb1qlTJ1y6dAlGRkYwMTFBfHw8zp07ByMjo0zT/oiUxKIUGbRffvkFRkZGGDx4MPbs2YNWrVpBRPDy5UvMnDkTQ4YMUTqiXrOyssKFCxdQunRpfPzxx9i0aRPq16+v+wQ0ISFB6Yh66fUXASqVCra2tvjss88wY8YMXhL5HTjiJ2usrKxw7tw5lClTBhMmTMC5c+fw559/IiIiAh4eHrh//77SEYnyrPPnz6NTp06YMWPGG9cETEpKwrZt27Bnzx589NFHGD9+PIyNjfPNGipphRcRgYjonuP2798PPz8/VKhQATNnztStHTN27FisWbMG//zzD+zt7ZWMnu3SjsWePXuwfv16REdHo27durq1w5o2bQqVSoUBAwbAxsYGYWFhWLlyJcLCwuDs7Kxs+Gxy9epVDBgwAEZGRhg9erTu+frly5cwMTFROF3+cu3aNbRt2xYTJkzA119/rWtPf6wXLVqEa9euQUQwceJEGBsbsyBFeodFKaJ0bt68iRMnTqB8+fKoXr260nH0HkeaUW7jiJ+sKVKkCEJDQ+Hk5ITGjRuje/fu6NevH27cuAEnJyckJiYqHZEozzp58iTc3d2xZcsW1KtXL8O2lJQUvHz5EpaWlhmKULm5sHBOSl+EWbNmDWJiYuDi4gIfHx8YGxtj0aJFWLlyJaKjo1G/fn3ExcXh2LFj2LdvH2rWrKl0/BwRHByM7t27o0uXLqhWrRpGjx6N+vXrY/Xq1bCyskKXLl1w8+ZNxMXFwcHBATNnzkSNGjWUjp2trly5gsGDB0NEMHbsWLi4uCgdKV86evQo3NzccPjwYVSqVCnDyLwXL15kWOQ8TX4phlP+whIpUToODg74+uuvWZD6j3r16oXTp08DeDX8fN68eTA3N4e3tzd8fX0VTqf/UlJSEBkZidTUVKWj5BnXr1+Hk5MTAGDjxo1o1aoVAgMDMW/ePE57fIfGjRtj2LBhCAgIwNGjR9GyZUsAr6ZapB/qT0TvptVqM7U9e/YMiYmJur48/ZVow8LCsHHjRqSkpGR4I5gfClLAq5G+wcHB6NChA1JTU/HJJ5/A398fP/zwA+7cuYO+ffti1qxZ6NmzJ0xMTFCnTh2Eh4fn24LU3bt34e/vj4kTJ2LBggXw9PSEqakpnJ2dUbRoURQoUACbNm3Cnj17EBYWhr/++ivfFaQAoEKFCpg9ezZMTEzg4+ODw4cPKx0pz0vf9yQlJQEA7O3tYW1tjdDQUACvHo9p/dD27dvx559/Zvo9LEiRPuJIKTJos2fPfmO7SqWCubk5ypcvD1dXV3bg/xFHmv03iYmJGDRoEFauXAngVWHA0dERXl5eKFmyJPz8/BROqL844idrbt26hQEDBiA6OhqDBw9Gnz59AADe3t7QaDRv7QuJ6P+kn/Iyd+5cJCQk6Prrtm3bIiIiAseOHdOtJ5WUlIR27dqhWrVqmD59umK5c0LaiIyzZ8+ibdu28PX1haenJ5KSklCqVCk8efIELVu2xJw5c+Dg4KB03ByVfnRKTEwM3N3d8c8//+Dhw4dwcXFBy5Yt8fvvvwMAQkJC4OLiYjBTpy5duoSxY8dixowZKF26tNJx8qz0fc+CBQug1Wrh4eEBW1tbdOrUCRqNBr6+vvj8888BvBoN1bJlS9jb22Pp0qVKRif6T1iUIoNWtmxZPHz4EImJibq1aJ48eQILCwtYWVkhJiYGjo6O2L9/P0qVKqVwWsovhgwZgrCwMPz666/48ssvcebMGTg6OuKvv/7ChAkTcPLkSaUj6q3WrVsjJSUFLi4uCAgIwPXr11GyZEns2rULgwYNwuXLl5WOSET5nK+vL9auXYvvv/8evXr1QunSpXHq1CkMGTIEZ8+exdixY/HixQvs378f9+7dw8mTJ/PNyKhHjx7B2NgYNjY20Gg0+Oeff3Dw4EFMmDABt2/fRpMmTdCuXTt8++23aNq0Kbp06YJhw4bpRrjmV+vXr0dcXBzat2+PWrVqYeLEifjpp5/w2WefYd68eTA2NkZkZCS8vb0xduxYNGzYUOnIuSYlJQWmpqZKx8gXfH19sWLFCkydOhXNmzfHxx9/jHPnzqFXr14wNzeHs7Mzypcvj//97394+vRpvup7KH9jUYoM2po1a/D7779j8eLFKFeuHAAgKioK/fv3R79+/eDi4oJvv/0WdnZ2bxwCa+g40ixrHBwcsG7dOnzyySewtrbG6dOn4ejoiKioKNSuXRvx8fFKR9RbHPGTdRqNBsHBwbh48SIAoGrVqmjdujUfn0TvYf369Rg8ePAb14968OABJk+ejNDQUBQoUADly5fH77//DhMTk3yxhlRUVBRatGiBFi1aICAgALa2tnj8+DHu3LkDJycndOzYEdbW1li4cCFMTU3RoEEDnDhxAl26dMGyZcvy/P1PL/3oqHPnzqFx48bw9/fHkCFD4O3tjYULF+Kzzz7D33//rfuZMWPGYOfOndi8eXO+W+Cdct6GDRvg7e2Nv/76C3Xq1AHwfyOoLl++jBUrVmD79u0oUqQISpUqpet7uIYU5QUsSpFBK1euHDZu3JhpbYOTJ0+iffv2uHbtGg4dOoT27dvj3r17yoTUYxxpljUWFhY4d+4cHB0dMxSlTp8+DVdXV8TFxSkdkfKZqKgoeHh44M6dO6hUqRIAIDIyEqVKlcLff/+tK8oT0bv99NNPOHPmDP7880/dm73XC06PHz9GoUKF8tWi5lqtFv7+/ggICMBnn32GqlWrYvTo0bqpigkJCfjiiy/Qt29f9O7dG1qtFsOHD8eXX36JMmXK6PqdvOxNVyw7d+4cNmzYgBcvXuDnn38GAISHh2PixIm4c+cOhg8fDjMzM4SGhmLFihX4559/8uUaUpTzJk2ahAMHDmDr1q0wNTWFSqV64zmZnJwMMzMzAPmj7yHDYBgTmone4t69e29cZDo1NVV3iXR7e3s8e/Yst6PlCYGBgahXrx6uXLmC2NhYxMbG4vLly2jQoAFmzZqFW7duwc7ODt7e3kpH1St169bN8Olp2qetixcvNqgh/Vml0WiwceNGTJw4ERMnTsT//vc/aDQapWPptcGDB6NcuXKIjo5GREQEIiIicOvWLZQtWxaDBw9WOh6RXkpbWDj9AsOxsbG4ceMGtFotjIyMICIwNjZGcnKyrl8vUqSIriCVtj2vU6vVaNeuHQoVKgSVSoXIyEhMmTIFjx49AgA8f/4c169f162r9eOPP2Ljxo1o0KBBvipI3blzB+vWrcPq1auxZcsWTJ48GfPmzcPTp091+zZs2BA+Pj5wcXHB4MGDMXnyZFy+fBkhISEsSNF7Sxs/EhUVpSs4qVQqaDQaqNVqaDQa7N27F9evXwcAXUEqv/Q9ZCCEyIB5eHhI7dq1JSIiQtcWEREhderUkZYtW4qIyObNm6VatWpKRdRrjo6OcvLkyUztERERUrZsWRERCQsLEzs7u1xOpt9CQkLEyspKPD09xdzcXIYMGSJffPGFWFpayvHjx5WOp9euXLkiFSpUEAsLC6lVq5bUqlVLLCwspFKlShIVFaV0PL1lYWEhZ86cydR+6tQpsbS0VCARkX5bs2aN9OrVSyIjIyUhIUHXvmjRIildurRs2bJFkpKSdO2PHz8WFxcX2bBhgxJxc5RWq5XU1FQRERk7dqwMHz5cxo4dK3Xq1JGhQ4fK/fv3ReTV6yUTExNxdHSUkiVLZnhtlZdpNBoRETl9+rQ4OjqKk5OTmJiYSJ06daR169bi7u4upUqVeuProZiYGHnx4kWGc4joXZ48eaI750RePf5ERLZv3y5mZmaydOnSDPs/ePBA2rdvL1u2bMnVnETZiSOlyKAtWbIERYoUQZ06dWBmZgYzMzPUrVsXRYoUwZIlSwAAVlZWmDFjhsJJ9RNHmmVN48aNcerUKaSmpsLZ2Rm7du1CsWLFEB4erlsngN6MI36yxszM7I2Pw4SEBC5AS/Sa+Ph4/Pjjj9i6dSs6dOiAIUOGYPny5QCA77//Hs7OzvD29sa6desQFRWFixcvomvXrkhNTUW7du2UDZ+NHj9+jJiYGKhUKt0UIQcHB4SGhmLEiBHo1q0bQkNDMWXKFDx48ACtWrVCZGQkNm3ahOPHj6NWrVoK34MPlzZC6syZM2jYsCE6dOiA3bt3488//8RHH32ER48eoVmzZnBwcMD48eNx5swZAK9GqWg0Gtja2sLMzAyWlpYK3xPKC9atW4fq1atj3LhxCA4OBvB/o+lr1qyJ77//HhMmTMDcuXPx8OFDnD17Fr1798aNGzfg7u6uYHKiD8M1pYjw6pK1aVftqlSpUr4Yap4bWrZsifv372Px4sW6F58nT55E3759YWdnh61bt2LLli0YPXo0zp49q3Bayg8sLS1x+PBhODs7Z2g/ffo0XFxckJCQoFAy/da9e3dERERgyZIlqF+/PgDgyJEj6Nu3L+rUqaN7w01Er6YIjx07Fg4ODqhXrx727duHSZMm4YsvvkCzZs3Qr18/dO7cGbdv38bhw4dRo0YNmJub459//sk3CwtfuXIF7u7uMDc3R2BgYIbXRp999hnq1auHn3/+GRMnTsSWLVvQpEkTDB8+HCVKlFA4efaLjo5G7dq10axZM6xfv17XvnDhQowaNQqnT59GREQE5s6dCysrKwQEBGR6jiL6NyICT09PrF+/HjNmzICvry86dOiAOnXqoF+/fgCAmzdvYunSpZg+fTqsrKxQqFAhFC9eHPv27cs3fQ8ZJo6UIgLg6OiISpUqwcPDgwWp98CRZu9HrVbDyMjonV+c//9uHPGTNbNnz0a5cuXQsGFDmJubw9zcHC4uLihfvjxmzZqldDwivWJkZIQmTZrA19cXxsbG8PHxwb1791C5cmUMHDgQzZs3R7169TB06FDs27cPCxcuRFhYmO4qe3n9TaFWq8Xy5ctx//59xMbGYsKECRg7diwGDBiAZ8+eoWvXrnj48CFSUlLw448/onXr1tiyZQvmzp2bYf2t/EKj0aBs2bJITk5GaGiorr1cuXJQqVR4/vw52rZti759+yIpKQlDhgzB+fPnFUxMeZFKpYKfnx/KlCkDJycnhIeHw9zcHOvXr4ezszOCgoJgbGwMf39/XLx4EatXr8ayZctw8ODBfNP3kOHiSCkyaImJifDy8sKKFSsAAJcvX4ajoyO8vLxQsmRJ+Pn5KZwwb+BIs//mr7/+euu28PBwzJ49G1qtFi9evMjFVHkLR/x8mLSpRgBQpUoVlC9fXuFERPpr4MCBAIB58+YBAKpWrYqKFSuiTJkyiIyMxI4dOxAUFIQuXboAePPV2fKqe/fu4eeff8bNmzdRpEgRdO7cGaNGjYK9vT2eP3+Offv2YcmSJejVqxcAYPr06ejQoQPKlCmjbPAccuXKFQwePBharRa//vorSpUqBUdHR/Tq1Ut31T0AWLlyJTZu3Ih58+bh448/VjAx5TUigsTERAwePBhly5bFjz/+CODVh24FCxZEtWrVEBMTg2HDhqFBgwZo2rSp7mc5QoryPAXXsyJS3ODBg6VOnToSEhIilpaWcvXqVRERCQ4Olpo1ayqcLu9ITk6WS5cuycuXL5WOkudcunRJ2rZtK0ZGRtK9e3e5ceOG0pH02pMnT6RNmzaiVqvF1NRUTE1NRa1WS9u2beXp06dKx9M7Go1GpkyZIo0aNZK6devKyJEjJTExUelYRHnC4sWLxcXFRR4/fiy1atUSFxcXiYuLExGR27dvy5o1a/L1896dO3dk4MCB0qhRI1mwYIGIiPz9998yfPhwUalU+XJR93e5fPmyuLu7S9OmTaVw4cIydOhQ3baUlBTd/+Pj45WIR/nEunXrxMrKSh4/fiwiIrVq1ZKmTZvKqVOnZM6cOVKsWDHp0aOHbgF0ovyAI6XIoDk4OGDdunX45JNPYG1tjdOnT8PR0RFRUVGoXbs24uPjlY6o1zjSLOvu3r2L8ePHY8WKFXBzc8PkyZNRrVo1pWPpLa1Wi2nTpmHz5s1ISUlB6dKl0aNHD6hUKo74eYeAgABMmDABzZs3R4ECBbBz50507twZS5cuVToaUZ5Qv359HD9+HK6urti0aROKFCmSaZ/U1NR8O/X63r17CAwMRHh4OLp27YqhQ4cCAK5duwZHR0dlwyngypUr8PT0xNWrV7Fy5Uq4uroCeDXKBfi/RamJPkT37t3x8ccfIzg4GEWKFMHmzZt1fc+VK1dQrly5fDMqkwjgmlJk4B4+fIhixYplan/+/DlfWPwHaQt8HjhwAObm5rr25s2bY926dQom019xcXEYOXIkypcvj/Pnz2Pv3r3YsmULC1L/YtKkSRg9ejSsrKxQsmRJbNu2DcHBwWjVqhULUu+wcuVKzJ8/Hzt37kRwcDC2bNmCP/74I1+u+0KUndKKDIMHD0bVqlUxY8YMFClSBG/6LDe/FqQAoESJEhgzZgwaNmyINWvWIDAwEMCrtTg1Go3C6XJfhQoV8Ntvv6FKlSoIDAxEWFgYgFfFKL5upOzi7OyMKVOmoGLFitixY4euICUiqFChAtRqNZ/HKV9hUYoMWt26dfH333/rvk97QbF48WI0bNhQqVh5RnBwMObOnYvGjRtneDFWtWpVXL16VcFk+mnq1KlwdHTE1q1bsWbNGhw6dAhNmjRROlaewOJK1ty6dQseHh6675s3bw6VSoW7d+8qmIpI/6U9pzVr1gyxsbHYvXt3hnZDYmdnhzFjxqB+/frYtm0bxo8fDwAGu4ZN+fLlMXv2bJiYmMDHxweHDx9WOhLlIa+/bkn/fVrR28fHB/Xr10epUqVgZWWl256+/+FIKcpP8u9HO0T/QWBgINzd3XHhwgWkpqZi1qxZuHDhAg4dOoSDBw8qHU/vcaTZ+/Hz80OBAgVQvnx5rFixQjft8XWbNm3K5WT6713FFS4m+3apqakZRjECgImJCV6+fKlQIqK8pWTJkhg1ahT8/f3RunVrODk5KR1JEWmFqVGjRuHQoUOIjY1F0aJFlY6lmAoVKmDatGkYO3Ys7O3tlY5DeURSUhIKFCgAANi+fTvc3d0zFJdUKpVu0fL27dtj+/btuHXrFkqXLq1UZKJcwaIUGbTGjRvj1KlTmDJlCpydnbFr1y7Url0b4eHhcHZ2Vjqe3ksbaebl5QWAI83+Tffu3VmsyyIWV7JGRNCzZ0+YmZnp2l68eAFPT09YWlrq2lgIJXo7Dw8PHD9+HJUrV1Y6iqLs7OwwZcoUADDoglSaypUr448//oCpqanSUSgP2Lx5M+bNm4edO3fC29sbmzdvRlhYGOzs7DLslzYCsVWrVhg5ciT279+PHj16KBGZKNdwoXMiyrLQ0FC4u7uja9euWL58Ofr3759hpFmdOnWUjkj5hFqthru7e4biypYtW/DZZ5+xuPIOaZdr/zfLli3L4SREeZuIZBjFQET0Ps6ePQtXV1eUKFECd+7cQWhoKJydnXV9S3parRZqtRqrVq3Ct99+m6/XrSMCWJQiog909epVTJkyBadPn0ZCQgJq166NkSNHcqQZZSsWV4iIiCgv+/bbb7F+/Xq4urpi9+7dMDEx+U8/l5+v8EkEsChFBkqtVv/rNCqVSoXU1NRcSkRERERERPnF66OgNm3ahNTUVAwdOhS1atVCUFCQ7qqe6ffjiEwyNCxKkUH666+/3rotPDwcs2fPhlarxYsXL3IxVd7Boh4RERER0ZulTcEDgNjYWFhZWemWIDh16hS+/PJL1KlTB3/88QdsbGwAAKtWrULXrl2VikykGBaliP6/yMhI+Pn5YcuWLejSpQt++uknODg4KB1LL7GoR0RERESUWfqRTz/99BMOHDiAR48eYdSoUfj0009RokQJnD59Gl9++SWqVasGX19f/PLLL3j8+DHCw8MzXJGPyBCwKEUG7+7duxg/fjxWrFgBNzc3TJ48GdWqVVM6Vp7Doh4RERERGbL0I6QWLFiAsWPHYsyYMQgLC8PRo0fRrVs39O3bF2XKlMHly5fh7u4OKysrWFlZ4cCBAzAxMXnj4udE+RnLsGSw4uLiMHLkSJQvXx7nz5/H3r17sWXLFhak3tPdu3fRt29fODs7IzU1FadOncKKFStYkCLSI8+fP1c6AhERUb6XVpA6e/YsLly4gOXLl8Pb2xt//vknBg0ahE2bNuG3337D9evXUbFiRVy4cAFr165FSEgITExMkJqayoIUGRwWpcggTZ06FY6Ojti6dSvWrFmDQ4cOoUmTJkrHylNY1CPKO4oXL47evXsjNDRU6ShERET52q5du+Di4oL169cj/aSkESNGoHfv3ggODsbixYtx5coVmJmZoUqVKlCr1dBqtbzKHhkkTt8jg6RWq1GgQAE0b978nVe32LRpUy6myjumTp2Kn3/+GXZ2dggMDESbNm2UjkRE7xAcHIzly5dj27ZtKFOmDHr37o3u3bvD3t5e6WhERER52pum240aNQq//vorBg0ahJEjR+Kjjz7SbZsxYwYmTZqEwMBAeHp65nZcIr3DohQZpJ49e/6nobHLli3LhTR5D4t6RHnTw4cPERQUhOXLl+PixYtwc3ND79690bp1a346S0RE9J7SryGl1WqRmpoKU1NTAMDw4cPx559/Yvjw4ejatSuKFCmi+7nVq1ejU6dO73wdTWQoWJQiovfGoh5R3jdnzhz4+voiJSUFH330ETw9PeHn5wcLCwuloxEREem99AWp+fPnIyQkBElJSahcuTKmTJkCAPD29kZwcDC8vb0zFaYAQKPRsDBFBo9FKSIiIgPx4MEDrFixAsuXL8fNmzfRrl079OnTB7dv38bPP/8Me3t77Nq1S+mYREREeYafnx9WrlyJfv36wd7eHp6enujSpQuCgoIAAMOGDcPmzZvRu3dvDBo0CAULFlQ4MZF+4Vh9IiKifG7Tpk1YtmwZdu7cCScnJwwYMABdu3aFjY2Nbp9GjRqhSpUqyoUkIiLKY44fP47//e9/WLt2LVxdXbFjxw6Ym5tnuIDSzJkz8fjxY0RERMDa2lrBtET6iUUpIiKifK5Xr1749ttvERYWhnr16r1xH3t7e4wZMyaXkxEREeVdMTExsLCwgKurK4KDg9GtWzf88ssv6NevH+Li4rB//360bdsWy5cvh1arhUqleuPC6ESGjEUpIiKifO7evXv/ulZUgQIFMH78+FxKRERElLekX0MqNTUVxsbGKFWqFKytrTFjxgz4+/tj+vTp6N+/PwDgzJkzWLp0KSpWrAgnJyeo1eoMv4OIXmFRigza8+fPYWlpqXQMIqJsFx8f/87v0+P6FkRERG+XvpgUFBQEMzMzNGvWDEWKFIGJiQlGjx6NESNG6ApSL168wM8//wwrK6sMU+NZkCLKjEUpMmjFixdHx44d0bt3bzRu3FjpOERE2cbGxuZfpwekTSHQaDS5lIqIiCjvSSsm+fr6IigoCIGBgUhNTUXJkiUxYsQIXL16FRcvXsTcuXNRuHBhLFu2DDExMYiIiIBKpeIIKaJ34NX3yKAFBwdj+fLl2LZtG8qUKYPevXuje/fusLe3VzoaEdEHOXjw4H/et2nTpjmYhIiIKO9bvnw5Ro8ejc2bN6NOnToZPvjZvHkz1q9fj127dsHZ2Rl2dnZYvnw5TExMdFP9iOjNWJQiAvDw4UMEBQVh+fLluHjxItzc3NC7d2+0bt2aTyJERERERAbOy8sLjx8/xh9//KFre73gFBsbCysrK5iZmb1xOxFlxjGERABsbW0xbNgwnDlzBjNnzsSePXvQoUMH2NvbY9y4cUhMTFQ6IhHRBwkJCUHXrl3RqFEj3LlzB8CrdTFCQ0MVTkZERKS/tFotRASRkZG6AlNam7GxMV6+fIl//vkHsbGxKFq0qK4glbadiN6NRSkiAA8ePMDUqVPh5OQEPz8/dOjQAXv37sWMGTOwadMmtG3bVumIRERZtnHjRri5uaFAgQKIiIhAcnIyACAuLg6BgYEKpyMiItIfr08kUqvVUKlU+PLLL7Fp0yYcPXpU1wa8usLtkiVLcPny5Qw/92/rOhLRK5y+RwZt06ZNWLZsGXbu3AknJyd8//336Nq1K2xsbHT7XL16FVWqVEFKSopyQYmIPkCtWrXg7e2N7t27w9raGqdPn4ajoyNOnjwJd3d33L9/X+mIREREiku/IHlsbCySkpLw8ccfAwBu3bqFQYMGISoqCr/99hvq1KmDx48fw9PTE7GxsQgNDYWRkZGS8YnyJI4nJIPWq1cvfPvttwgLC0O9evXeuI+9vT3GjBmTy8mIiLJPZGQkXF1dM7UXKlQIT58+zf1AREREeiZ9QSogIABbtmzBrVu30KBBA4wePRoNGjTAhAkTMHPmTHz22WcoXbo0TE1NYW1tjbCwMBgZGfEqe0RZwKIUGbR79+7BwsLinfsUKFAA48ePz6VERETZz87ODlFRUShTpkyG9tDQUDg6OioTioiISA+ICFQqla6YNG7cOCxevBiBgYFo0KABPDw8MGLECIwcORIeHh4ICgpCz549cf/+fRQsWBAtW7aEkZERFzUnyiI+asjgxMfHv/P79AoWLJjTcYiIclzfvn0xZMgQLF26FCqVCnfv3kV4eDh8fHwwduxYpeMREREp4uLFi6hSpYru+5CQEAQHB2P16tX49NNPERYWhgcPHkClUsHHxwcighYtWqB58+YZfo9Go2FBiiiL+Mghg2NjY/OvCw+mfWKi0WhyKRURUc7x8/ODVqvF559/jsTERLi6usLMzAw+Pj7w8vJSOh4REVGuGzVqFK5fv461a9fqpt3Z2NjAy8sLn376Kfbs2YNvv/0WCxYswHfffYfSpUtj2rRpiI+PR6dOnTJM0+NaUkRZx4XOyeAcPHjwP+/btGnTHExCRJS7UlJSEBUVhYSEBDg5OcHKykrpSERERIo4fPgw6tatC2NjY9y9exf29vZITk7G06dPYWNjg6+//hq1atXCTz/9BJVKhWbNmuHYsWPo3r07FixYoHR8onyDI6XI4LDQRESGytTUFE5OTkrHICIiUkxwcDDatm2LTz75BACwYcMGjBgxAqtXr0bDhg1RvHhxPHv2DI8ePYKtrS3UajU0Gg3KlSuH6dOno3bt2grfA6L8hUUpMnghISH47bffcO3aNWzYsAElS5ZEUFAQypYti8aNGysdj4jog7148QJz5szB/v37ERMTA61Wm2F7RESEQsmIiIhyz6pVq+Dl5YVr165h2LBhAAArKys4OztjyJAhmDt3LurXrw8AUKlU2LRpE549e4b9+/cjNjYWtWvX1hWpOGWPKHvwepVk0DZu3Ag3NzcUKFAAERERSE5OBgDExcUhMDBQ4XRERNmjT58+mDp1KhwcHPDVV1+hTZs2Gb6IiIgMwSeffAJPT08sWrQIU6dOBQC4u7tj6NCh+Pjjj+Hp6Ynw8HBYW1tjw4YN0Gq12Lt3LywsLHDs2DGo1WpotVoWpIiyEdeUIoNWq1YteHt7o3v37rC2tsbp06fh6OiIkydPwt3dHffv31c6IhHRBytUqBC2bdsGFxcXpaMQEREpIm1004MHD7Bw4UKsXbsWgwYNwsCBAwEAe/fuxdy5c3Hz5k3MmTMHLi4uSExMhIjAwsICKpUKqampvMoeUTbjSCkyaJGRkXB1dc3UXqhQITx9+jT3AxER5YCSJUvC2tpa6RhERESKEBHd6KY9e/bg/v37ePDgAX788UfMmjULAPD5559j0KBBcHBwgJeXF8LDw2FhYaErSIkIC1JEOYBFKTJodnZ2iIqKytQeGhoKR0dHBRIREWW/GTNmYOTIkbh586bSUYiIiHKdSqUCAIwePRre3t6oVasW/P39Ua9ePcyZMwfTp08HkLkwdeLECd3Ppv1LRNmLpV4yaH379sWQIUOwdOlSqFQq3L17F+Hh4fDx8cHYsWOVjkdElC3q1q2LFy9ewNHRERYWFjAxMcmw/fHjxwolIyIiyh23b9/Gtm3bMHv2bHz77bcAgC+//BLz58/HnDlzUKBAAQwcOBCff/451Go1Zs+ejUmTJmHx4sUoUqSIwumJ8i8Wpcig+fn5QavV4vPPP0diYiJcXV1hZmYGHx8feHl5KR2PiChbdO7cGXfu3EFgYCCKFy/OT3uJiMjgWFhYICYmBjExMbq2ChUqYODAgdi2bRvGjx+P2NhYjBs3Ds2aNcPly5exePFiaDQaBVMT5X8sSpFBU6lUGDNmDHx9fREVFYWEhAQ4OTnByspK6WhERNnm0KFDCA8PR40aNZSOQkRElOO0Wq3uSnlp/5qbm6Nhw4Y4f/487t+/Dzs7OwBA+fLlUb9+fVy6dAnXrl3TLWYeFxeHqKgoqNVc8YYoJ/ERRgTA1NQUTk5OqF+/PgtSRJTvVK5cGUlJSUrHICIiynFr167F999/j8uXL+ue+9RqNSwsLPD1119j7dq1+P333xEdHQ0ASEhIQFJSEgYMGIBly5bpFjP/4osvcPDgQRQtWlSx+0JkCFQiIkqHIFLKixcvMGfOHOzfvx8xMTHQarUZtkdERCiUjIgo++zatQv+/v6YNGkSnJ2dM60pVbBgQYWSERERZZ/4+HjUrl0b8fHxsLOzQ/369dGkSRP06NFDt8+8efPw008/wdnZGYULF0Z0dDRevHiBEydOwMjICFqtFiqVilPdiXIJi1Jk0Lp06YJdu3ahQ4cOb1xnZfz48QolIyLKPmlTD17v40QEKpWK62UQEVG+oNFoMHbsWDg4OKBevXrYt28fJk2aBA8PD1SpUgUjR46EiYkJwsPDsWvXLpw7dw4lS5bEtGnTYGJiAo1GAyMjI6XvBpFBYVGKDFqhQoWwbds2uLi4KB2FiCjHHDx48J3bmzZtmktJiIiIctb27dvRqVMnhIaGonr16njx4gUCAwMxceJEVK9eHd999x3atGmDSpUqZfi5tLWkiCh3sShFBs3JyQlr165F9erVlY5CRERERETZYODAgQBeTdUDgKpVq6JixYooX748Tp8+jT179mDRokXo06cPgP8bOUxEuY8LnZNBmzFjBkaOHImbN28qHYWIKEeFhISga9euaNSoEe7cuQMACAoKQmhoqMLJiIiIslft2rVx+vRpPHnyBLVr10bhwoWxYsUKTJs2DcuWLcOaNWsyrDPFghSRcliUIoNWt25dvHjxAo6OjrC2tkaRIkUyfBER5QcbN26Em5sbChQogIiICCQnJwMA4uLiEBgYqHA6IiKi7NWnTx+kpKSgaNGiKFiwIDZv3qy7qEfJkiXRqVMnGBsbIzU1VeGkRMTpe2TQmjdvjlu3bqFPnz5vXOg8/ScoRER5Va1ateDt7Y3u3bvD2toap0+fhqOjI06ePAl3d3fcv39f6YhERETZIm0q3qpVq/Dzzz9j+fLlqFOnDqfoEekpruRGBu3QoUMIDw9HjRo1lI5CRJRjIiMj4erqmqm9UKFCePr0ae4HIiIiyiFphadmzZphxIgR2L17N+rUqcOCFJGe4vQ9MmiVK1dGUlKS0jGIiHKUnZ0doqKiMrWHhobC0dFRgUREREQ5q2TJkhg1ahSmT5+OCxcuKB2HiN6CRSkyaFOmTMHw4cNx4MABxMbGIj4+PsMXEVF+0LdvXwwZMgRHjhyBSqXC3bt38ccff8DHxwc//PCD0vGIiIhyhIeHB1q2bInKlSsrHYWI3oJrSpFBU6tf1WVfH86bNudco9EoEYuIKFuJCAIDAzF58mQkJiYCAMzMzODj44OAgACF0xEREeWc9K/rjYyMlI5DRK9hUYoM2sGDB9+5vWnTprmUhIgoZ2g0GoSFhaF69eqwsLBAVFQUEhIS4OTkBCsrK6XjEREREZEBY1GKiIgonzM3N8fFixdRtmxZpaMQEREREelwTSkyeCEhIejatSsaNWqEO3fuAACCgoIQGhqqcDIiouxRrVo1XLt2TekYREREREQZsChFBm3jxo1wc3NDgQIFEBERgeTkZABAXFwcAgMDFU5HRJQ9Jk6cCB8fH2zduhX37t3jRR2IiIiISC9w+h4ZtFq1asHb2xvdu3eHtbU1Tp8+DUdHR5w8eRLu7u64f/++0hGJiD5Y2kUdgIwXduBFHYiIiIhIScZKByBSUmRkJFxdXTO1FypUCE+fPs39QEREOWD//v1KRyAiIiIiyoRFKTJodnZ2iIqKQpkyZTK0h4aGwtHRUZlQRETZrGzZsihVqlSGUVLAq5FS0dHRCqUiIiIiIkPHNaXIoPXt2xdDhgzBkSNHoFKpcPfuXfzxxx/w8fHBDz/8oHQ8IqJsUbZsWTx8+DBT++PHj3lFPiIiIiJSDEdKkUHz8/ODVqvF559/jsTERLi6usLMzAw+Pj7w8vJSOh4RUbZIWzvqdQkJCTA3N1cgERERERERFzonA6bRaBAWFobq1avDwsICUVFRSEhIgJOTE6ysrJSOR0T0wYYNGwYAmDVrFvr27QsLCwvdNo1GgyNHjsDIyAhhYWFKRSQiIiIiA8aRUmSwjIyM0KJFC1y8eBE2NjZwcnJSOhIRUbY6efIkgFcjpc6ePQtTU1PdNlNTU9SoUQM+Pj5KxSMiIiIiA8eiFBm0atWq4dq1a1xThYjypbSr7vXq1QuzZs1CwYIFFU5ERERERPR/OH2PDNqOHTswatQoBAQEoE6dOrC0tMywnW/giCg/ePjwIWxtbd+47ezZs3B2ds7lRERERERELEqRgVOr/+8ClOkXAU5bFFij0SgRi4goW9nZ2WHJkiVo2bJlhvbp06dj7NixSEpKUigZERERERkyTt8jg5Y2tYWIKD8bNmwY2rdvj169emHmzJl4/PgxunfvjrNnz2L16tVKxyMiIiIiA8WRUmTQbt26hVKlSmW6VLqIIDo6GqVLl1YoGRFR9jp58iS6deuG5ORkPH78GA0aNMDSpUthZ2endDQiIiIiMlDqf9+FKP8qW7YsHj58mKn98ePHXPyciPKV8uXLo1q1arhx4wbi4+PRqVMnFqSIiIiISFEsSpFBS1s76nUJCQkwNzdXIBERUfYLCwtD9erVceXKFZw5cwYLFiyAl5cXOnXqhCdPnigdj4iIiIgMFKfvkUEaNmwYAGDWrFno27cvLCwsdNs0Gg2OHDkCIyMjhIWFKRWRiCjbmJmZwdvbGwEBATAxMQEAXL16FV27dkV0dDRu376tcEIiIiIiMkRc6JwM0smTJwG8Gil19uxZmJqa6raZmpqiRo0a8PHxUSoeEVG22rVrF5o2bZqhrVy5cggLC8OkSZMUSkVEREREho4jpcig9erVC7NmzULBggWVjkJERERERERkULimFBm0qVOnvrUgdfbs2VxOQ0SUvTw8PBAXF6f7fsqUKXj69Knu+9jYWDg5OSmQjIiIiIiIRSkycM7Ozvj7778ztU+fPh3169dXIBERUfbZuXMnkpOTdd8HBgbi8ePHuu9TU1MRGRmpRDQiIiIiIhalyLANGzYM7du3xw8//ICkpCTcuXMHn3/+OaZOnYrVq1crHY+I6IO8PkOfM/aJiIiISJ+wKEUGbcSIEQgPD0dISAiqV6+O6tWrw8zMDGfOnEG7du2UjkdERERERESUb7EoRQavfPnyqFatGm7cuIH4+Hh06tQJdnZ2SsciIvpgKpUKKpUqUxsRERERkT4wVjoAkZLCwsLQtWtXFClSBGfOnEFYWBi8vLywbds2LFy4EIULF1Y6IhFRlokIevbsCTMzMwDAixcv4OnpCUtLSwDIsN4UEREREVFuUwkXmCADZmZmBm9vbwQEBMDExAQAcPXqVXTt2hXR0dG4ffu2wgmJiLKuV69e/2m/ZcuW5XASIiIiIqLMWJQig3bw4EE0bdo0U7tWq8WkSZMwduxYBVIRERERERER5X8sShERERERERERUa7jQudkkDw8PBAXF6f7fsqUKXj69Knu+9jYWDg5OSmQjIiIiIiIiMgwcKQUGSQjIyPcu3cPxYoVAwAULFgQp06dgqOjIwDgwYMHsLe3h0ajUTImERERERERUb7FkVJkkF6vxbI2S0RERERERJS7WJQiIiIiIiIiIqJcx6IUGSSVSgWVSpWpjYiIiIiIiIhyh7HSAYiUICLo2bMnzMzMAAAvXryAp6cnLC0tAQDJyclKxiMiIiIiIiLK97jQORmkXr16/af9li1blsNJiIiIiIiIiAwTi1JERERERERERJTruKYUERERERERERHlOhaliIiIiIiIiIgo17EoRUREREREREREuY5FKSIiIiIiIiIiynUsShERERERERERUa5jUYqIiIiIiIiIiHIdi1JERERERERERJTrWJQiIiIiIiIiIqJc9/8ADG/jCkilyqwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the best model that was saved\n",
    "optimal_batch_size = study.best_params['batch_size']\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=optimal_batch_size, shuffle=False)\n",
    "\n",
    "# Use the actual best model now\n",
    "results = quick_eval_manual('best_model_optuna.pt', test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b032764-a079-492a-b358-da6668785134",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e65c4ae4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e65c4ae4",
    "outputId": "3c9dac27-9f21-4679-b2dd-26df5b2fcb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STUDY RESULTS ===\n",
      "Best trial: 2\n",
      "Best QWK: 0.9374\n",
      "Best params: {'learning_rate': 4.7412352298523686e-05, 'batch_size': 16, 'label_smoothing': 0.14864590596800178, 'epochs': 12, 'warmup_ratio': 0.053072966467540166, 'weight_decay': 0.14067329738635054, 'attention_dropout': 0.31630050099253554, 'hidden_dropout': 0.30284169042309084}\n",
      "\n",
      "=== ALL TRIALS ===\n",
      "Trial 0: QWK = 0.9366\n",
      "Trial 1: QWK = 0.9361\n",
      "Trial 2: QWK = 0.9374\n",
      "Trial 3: QWK = 0.9363\n",
      "Trial 4: QWK = 0.9368\n",
      "Trial 5: QWK = 0.9312\n",
      "Trial 6: QWK = 0.9331\n",
      "Trial 7: QWK = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Check study results\n",
    "print(\"=== STUDY RESULTS ===\")\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best QWK: {study.best_value:.4f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "# Compare all trials\n",
    "print(\"\\n=== ALL TRIALS ===\")\n",
    "for trial in study.trials:\n",
    "    print(f\"Trial {trial.number}: QWK = {trial.value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d791d4-dd18-4051-bd39-3a1a533a38e8",
   "metadata": {},
   "source": [
    "### Model Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a772083",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a772083",
    "outputId": "c4b5645f-45df-48a2-b56b-3155669f968d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEST MODEL ANALYSIS ===\n",
      "============================================================\n",
      "MODEL SPECIFICATIONS:\n",
      "   • Model Size: 514.62 MB\n",
      "   • Total Parameters: 134,903,813\n",
      "   • Trainable Parameters: 134,903,813\n",
      "   • Inference Time: 202.11 ms per request\n",
      "============================================================\n",
      "PREDICTION ANALYSIS:\n",
      "   • True label distribution: {np.int64(2): 889, np.int64(1): 915, np.int64(3): 1275, np.int64(0): 488, np.int64(4): 790}\n",
      "   • Predicted label distribution: {np.int64(2): 1019, np.int64(1): 805, np.int64(3): 1154, np.int64(0): 510, np.int64(4): 869}\n",
      "   • Unique predictions: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
      "   • Number of classes predicted: 5\n",
      "============================================================\n",
      "✅ Model is predicting all 5 classes!\n",
      "📊 Efficiency Metrics:\n",
      "   • Parameters per MB: 262,143\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the best model is predicting\n",
    "import torch\n",
    "from torch.serialization import safe_globals\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the entire model directly\n",
    "with safe_globals({RobertaForSequenceClassification}):\n",
    "    model = torch.load('./best_bert_model_so_far/model_bert.pt', map_location=device, weights_only=False)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Calculate model metrics\n",
    "model_size_mb = get_model_size(model)\n",
    "total_params, trainable_params = get_model_parameters(model)\n",
    "\n",
    "# Get a sample batch for inference timing\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "sample_batch = next(iter(val_loader))\n",
    "inference_time_ms = measure_inference_time(model, sample_batch, device)\n",
    "\n",
    "# Check predictions on validation data\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Analyze predictions\n",
    "from collections import Counter\n",
    "pred_dist = Counter(all_predictions)\n",
    "true_dist = Counter(all_true_labels)\n",
    "\n",
    "print(\"=== BEST MODEL ANALYSIS ===\")\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SPECIFICATIONS:\")\n",
    "print(f\"   • Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"   • Total Parameters: {total_params:,}\")\n",
    "print(f\"   • Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"   • Inference Time: {inference_time_ms:.2f} ms per request\")\n",
    "print(\"=\" * 60)\n",
    "print(\"PREDICTION ANALYSIS:\")\n",
    "print(f\"   • True label distribution: {dict(true_dist)}\")\n",
    "print(f\"   • Predicted label distribution: {dict(pred_dist)}\")\n",
    "print(f\"   • Unique predictions: {sorted(set(all_predictions))}\")\n",
    "print(f\"   • Number of classes predicted: {len(set(all_predictions))}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(set(all_predictions)) == 5:\n",
    "    print(\"✅ Model is predicting all 5 classes!\")\n",
    "elif len(set(all_predictions)) > 1:\n",
    "    print(f\"✅ Model is predicting {len(set(all_predictions))} classes (better than before!)\")\n",
    "else:\n",
    "    print(\"❌ Model still predicting only 1 class\")\n",
    "\n",
    "print(f\"📊 Efficiency Metrics:\")\n",
    "print(f\"   • Parameters per MB: {total_params/model_size_mb:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "853444bd",
   "metadata": {
    "id": "853444bd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "006900248ab044bb94aedfa8a64b2d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0370530f965b436c8653e8ac911fbbfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "095cba7d8b754a2abc9be0a0e5598f93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d123104f1c94fc7aeca0379bd4cf89f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_498e7f4dbd8f4d2c8a0f75d57ef23fc6",
      "placeholder": "​",
      "style": "IPY_MODEL_e7bb540823674f6a8d4c1493e22b31b8",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "0d8463be55df462ba54cfb61aaf104e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10134821bf254743ad96bc3f02a4f9f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13feaf9ad6724ea188a1ba405e08392d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14be82be076d44eb8642de8837e62294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acb8051f99dd478dadbf754d00b34c30",
       "IPY_MODEL_b53720ca6095451e9279cabbbf64201b",
       "IPY_MODEL_e2d1ff38fddd4e82a9f4290acbe5dcdc"
      ],
      "layout": "IPY_MODEL_fa80ac5acb3e4a26ac385f5506d431a0"
     }
    },
    "17a631c59eca4558a083348e87d5af81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d79fc89547f4bc08c4ce2a4e6ace4e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24111e81d7884d1fba4ad2db372cc50f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2af65b536632441080017da7137d8a52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dbe7d6f29f44265920ae349e6799e63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305f91a1665d43b4988c73e034a93bc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30e85081d3f14e71a5f0db06c5eb4a3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_603b27009a234abdaa946080e4486e47",
      "placeholder": "​",
      "style": "IPY_MODEL_8438931fee98450e9835804f4366d3cb",
      "value": " 949/949 [00:00&lt;00:00, 25.5kB/s]"
     }
    },
    "3265bfa4994747d0a0bcbba7124fc760": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "356a4342c81743399fb66600b064cb99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ac2eb670ad7463f9487748fc7b1c0dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4895799049d49cea9d4bd98c3211ce3",
       "IPY_MODEL_50d4d2004a7843c0a2161369f830df60",
       "IPY_MODEL_9b05323233b440618348691aab0f2082"
      ],
      "layout": "IPY_MODEL_829d16b388a4493d95a7657e273da264"
     }
    },
    "3d9491215c0a471f87d32083030e5ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d9e305c443244698e8ea57f91298c6f",
      "placeholder": "​",
      "style": "IPY_MODEL_10134821bf254743ad96bc3f02a4f9f8",
      "value": "config.json: 100%"
     }
    },
    "3fcafcce6b544d38b4262965bed2583b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4045cf73e69b4a3bb3b63b1e010c5607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42bf7fe8ab0849069990771c1635842a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_305f91a1665d43b4988c73e034a93bc5",
      "placeholder": "​",
      "style": "IPY_MODEL_be536f4ec2b147d4b7fdc33fb20a1eaa",
      "value": " 1.08M/? [00:00&lt;00:00, 22.8MB/s]"
     }
    },
    "498e7f4dbd8f4d2c8a0f75d57ef23fc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a35771d315c46da9ee6552e4e48b7b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50ae317e621743aa9b5cff652166e3a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eddbecafc0e14ac1a1c7b026237c7322",
       "IPY_MODEL_5441b398a6b3406fbd61655b05dbf4d3",
       "IPY_MODEL_f71be797887b4052a6b5e3dd0cde9d6d"
      ],
      "layout": "IPY_MODEL_d53ddf7de05b4409ace7e43b939229c8"
     }
    },
    "50d4d2004a7843c0a2161369f830df60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa21ad2599f8442fb9a655077c16bd58",
      "max": 167,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a35771d315c46da9ee6552e4e48b7b8",
      "value": 167
     }
    },
    "53ff43592b8e4dda8f5f615db5583a6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5441b398a6b3406fbd61655b05dbf4d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17a631c59eca4558a083348e87d5af81",
      "max": 539679413,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8735be100c04ee8954b47c300c1fb58",
      "value": 539679413
     }
    },
    "55c28984848741ddb4ae005c278c491e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0370530f965b436c8653e8ac911fbbfc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095cba7d8b754a2abc9be0a0e5598f93",
      "value": 1
     }
    },
    "560897643dbd464bb29cffcc2af894b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbe7d6f29f44265920ae349e6799e63",
      "placeholder": "​",
      "style": "IPY_MODEL_915e2981f56a4fbba9de15fb714ae145",
      "value": "vocab.txt: "
     }
    },
    "57994cfce6ce41e7bdb80ab12f62828e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d943ba338a446ef81e1ac65339f92e0",
      "placeholder": "​",
      "style": "IPY_MODEL_cbad80f213a5437c884eb1d7a6ffe1b6",
      "value": " 843k/? [00:00&lt;00:00, 8.46MB/s]"
     }
    },
    "57e4d681649d4e498f7552e670d09d8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d943ba338a446ef81e1ac65339f92e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "603b27009a234abdaa946080e4486e47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68788c83cfc94ffc92b471bb65d24f36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "692271fe5a804d589ef167c9884f31f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e9ee454831f4a0b8a64b1c8111c0e28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "714ba282fe51486aa60d2442f6ce4c6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a724691df4442c947c5e02151d5e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e9ee454831f4a0b8a64b1c8111c0e28",
      "placeholder": "​",
      "style": "IPY_MODEL_e10a812f7be542ca8f1a7f8fc5b80d10",
      "value": "bpe.codes: "
     }
    },
    "778696b04de643af9376c7d2dded756f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d50020689b94a0fb1180d7f7d7741cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2af65b536632441080017da7137d8a52",
      "placeholder": "​",
      "style": "IPY_MODEL_d9ef9051b4fb4395b76b9a01b8ea2153",
      "value": " 22.0/22.0 [00:00&lt;00:00, 523B/s]"
     }
    },
    "7d78543c851c4a76a3c167b4ea2794c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8027714395d84a00b278b3c2f533d10a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "829d16b388a4493d95a7657e273da264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8438931fee98450e9835804f4366d3cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "845de3a718484277a8f4619b0e94448b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f5f09dcd01d4d9bad9f673b8c18d4f0",
      "placeholder": "​",
      "style": "IPY_MODEL_1d79fc89547f4bc08c4ce2a4e6ace4e1",
      "value": "added_tokens.json: 100%"
     }
    },
    "89b03e781b6d4dd68c40fb895a0c2e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_845de3a718484277a8f4619b0e94448b",
       "IPY_MODEL_eed1e9ab6356430993407915403cef6b",
       "IPY_MODEL_7d50020689b94a0fb1180d7f7d7741cd"
      ],
      "layout": "IPY_MODEL_98fbe14bbc144c66bba463ef15352628"
     }
    },
    "8da16dd4572d4236824cfa2a5b2310cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_560897643dbd464bb29cffcc2af894b5",
       "IPY_MODEL_b2246c43b2454d7ba9975af4d375ed93",
       "IPY_MODEL_57994cfce6ce41e7bdb80ab12f62828e"
      ],
      "layout": "IPY_MODEL_006900248ab044bb94aedfa8a64b2d7a"
     }
    },
    "8df85062cabb4049b6747ef23ad3698c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e002d6815754ab7958915b42a73c93e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906ed3473d534f95af0ca0a59a0116fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9120fdcc9f064436baa24c30e9d10be3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "915e2981f56a4fbba9de15fb714ae145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98fbe14bbc144c66bba463ef15352628": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ab0859342134e9790f3a25298d410dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d123104f1c94fc7aeca0379bd4cf89f",
       "IPY_MODEL_9e50434ecc9c40938281391881e811dc",
       "IPY_MODEL_a85c8479c5ef4ea89bf9c232ff866aad"
      ],
      "layout": "IPY_MODEL_53ff43592b8e4dda8f5f615db5583a6c"
     }
    },
    "9b05323233b440618348691aab0f2082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_356a4342c81743399fb66600b064cb99",
      "placeholder": "​",
      "style": "IPY_MODEL_692271fe5a804d589ef167c9884f31f9",
      "value": " 167/167 [00:00&lt;00:00, 5.46kB/s]"
     }
    },
    "9b807e5466604d858e7c3471bc78c640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72a724691df4442c947c5e02151d5e05",
       "IPY_MODEL_55c28984848741ddb4ae005c278c491e",
       "IPY_MODEL_42bf7fe8ab0849069990771c1635842a"
      ],
      "layout": "IPY_MODEL_f64080fc8e5f4da99590da1a63d2e8f1"
     }
    },
    "9d9e305c443244698e8ea57f91298c6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e50434ecc9c40938281391881e811dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13feaf9ad6724ea188a1ba405e08392d",
      "max": 338,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24111e81d7884d1fba4ad2db372cc50f",
      "value": 338
     }
    },
    "9f5f09dcd01d4d9bad9f673b8c18d4f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a85c8479c5ef4ea89bf9c232ff866aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3265bfa4994747d0a0bcbba7124fc760",
      "placeholder": "​",
      "style": "IPY_MODEL_8df85062cabb4049b6747ef23ad3698c",
      "value": " 338/338 [00:00&lt;00:00, 7.62kB/s]"
     }
    },
    "acb8051f99dd478dadbf754d00b34c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9120fdcc9f064436baa24c30e9d10be3",
      "placeholder": "​",
      "style": "IPY_MODEL_cd1d085caa4c4fc2ab9858048eeee2c6",
      "value": "model.safetensors: 100%"
     }
    },
    "ad68ef71375d4a9e92ad0d76210fab30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2246c43b2454d7ba9975af4d375ed93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_906ed3473d534f95af0ca0a59a0116fc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d78543c851c4a76a3c167b4ea2794c9",
      "value": 1
     }
    },
    "b53720ca6095451e9279cabbbf64201b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e002d6815754ab7958915b42a73c93e",
      "max": 539634372,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad68ef71375d4a9e92ad0d76210fab30",
      "value": 539634372
     }
    },
    "be536f4ec2b147d4b7fdc33fb20a1eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1b1de802f37412fbba27b2b206db6a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4895799049d49cea9d4bd98c3211ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e92f2da1db7847628561da9f63a27307",
      "placeholder": "​",
      "style": "IPY_MODEL_c837e987955a436e8e889c87f277c281",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "c837e987955a436e8e889c87f277c281": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbad80f213a5437c884eb1d7a6ffe1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd1d085caa4c4fc2ab9858048eeee2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd644400d9e043fb8628a3376c7f303b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d53ddf7de05b4409ace7e43b939229c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9ef9051b4fb4395b76b9a01b8ea2153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dece572d8755490abc564e29ffe540a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57e4d681649d4e498f7552e670d09d8d",
      "max": 949,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd644400d9e043fb8628a3376c7f303b",
      "value": 949
     }
    },
    "e10a812f7be542ca8f1a7f8fc5b80d10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2d1ff38fddd4e82a9f4290acbe5dcdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4045cf73e69b4a3bb3b63b1e010c5607",
      "placeholder": "​",
      "style": "IPY_MODEL_c1b1de802f37412fbba27b2b206db6a0",
      "value": " 540M/540M [00:05&lt;00:00, 137MB/s]"
     }
    },
    "e7bb540823674f6a8d4c1493e22b31b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8735be100c04ee8954b47c300c1fb58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e92f2da1db7847628561da9f63a27307": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaff056b30be4bb4b4b60a0d2bebef0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d9491215c0a471f87d32083030e5ea9",
       "IPY_MODEL_dece572d8755490abc564e29ffe540a1",
       "IPY_MODEL_30e85081d3f14e71a5f0db06c5eb4a3d"
      ],
      "layout": "IPY_MODEL_0d8463be55df462ba54cfb61aaf104e1"
     }
    },
    "eddbecafc0e14ac1a1c7b026237c7322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_778696b04de643af9376c7d2dded756f",
      "placeholder": "​",
      "style": "IPY_MODEL_3fcafcce6b544d38b4262965bed2583b",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "eed1e9ab6356430993407915403cef6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_714ba282fe51486aa60d2442f6ce4c6d",
      "max": 22,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8027714395d84a00b278b3c2f533d10a",
      "value": 22
     }
    },
    "efb2d8e2bccb4213b6eac67741341efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f64080fc8e5f4da99590da1a63d2e8f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f71be797887b4052a6b5e3dd0cde9d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68788c83cfc94ffc92b471bb65d24f36",
      "placeholder": "​",
      "style": "IPY_MODEL_efb2d8e2bccb4213b6eac67741341efe",
      "value": " 540M/540M [00:14&lt;00:00, 73.5MB/s]"
     }
    },
    "fa21ad2599f8442fb9a655077c16bd58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa80ac5acb3e4a26ac385f5506d431a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
