{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97a51a2-6f40-49e4-9584-0355823ab416",
   "metadata": {},
   "source": [
    "## Roberta fine-tuning + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73ca99-a2a4-45b5-a0f6-cce7f327ed01",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76fDUrIIgpHU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76fDUrIIgpHU",
    "outputId": "7de53e84-2a6a-4faf-d521-3bda747f1fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q optuna\n",
    "!pip install -q evaluate\n",
    "!pip install -q emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8caf727",
   "metadata": {
    "id": "d8caf727"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import evaluate\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bbac45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41bbac45",
    "outputId": "eebe727f-61e1-4dd3-e247-b22ccbbd226e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244d7e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5244d7e5",
    "outputId": "ad68b2b1-4434-4ba1-f14b-4cbf6598bc48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmayachn3\u001b[0m (\u001b[33mmayachn3-maya-bondar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"<wandb key>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb48819-7942-41ff-a578-4887c9325e71",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a0a73c",
   "metadata": {
    "id": "d3a0a73c"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"OOT_train.csv\", encoding='latin-1')\n",
    "val = pd.read_csv(\"OOT_val.csv\", encoding='latin-1')\n",
    "test = pd.read_csv(\"OOT_test.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cadc1a",
   "metadata": {
    "id": "38cadc1a"
   },
   "outputs": [],
   "source": [
    "# train = train.head(1000)\n",
    "# val = val.head(1000)\n",
    "# test = test.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687deaa",
   "metadata": {
    "id": "4687deaa"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9966ecc5",
   "metadata": {
    "id": "9966ecc5"
   },
   "outputs": [],
   "source": [
    "#encoding the labels numerically from Sentiment\n",
    "\n",
    "ordinal_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "# map to ordinal labels\n",
    "train[\"ordinal_label_id\"] = train[\"Sentiment\"].map(ordinal_mapping)\n",
    "val[\"ordinal_label_id\"] = val[\"Sentiment\"].map(ordinal_mapping)\n",
    "test[\"ordinal_label_id\"] = test[\"Sentiment\"].map(ordinal_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b78e181",
   "metadata": {
    "id": "2b78e181"
   },
   "outputs": [],
   "source": [
    "# Concat the relevant columns into one string with seperation.\n",
    "# for example: \"Tweet: my food stock is low | Location: Canada | Date: 2020-03-17 | URL: https://t.co/abcd\"\n",
    "\n",
    "# Function to build the input string from multiple columns\n",
    "def build_augmented_input(row):\n",
    "    parts = []\n",
    "\n",
    "    if pd.notna(row.get('clean_tweet')):\n",
    "        parts.append(f\"{row['clean_tweet']}\")\n",
    "\n",
    "    if pd.notna(row.get('Location_standardized')) and row['Location_standardized'].lower() != 'unknown':\n",
    "        parts.append(f\"{row['Location_standardized']}\")\n",
    "\n",
    "    if pd.notna(row.get('TweetAt')):\n",
    "        parts.append(f\"{row['TweetAt']}\")\n",
    "\n",
    "\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# Apply to the DataFrames\n",
    "train['model_input'] = train.apply(build_augmented_input, axis=1)\n",
    "val['model_input'] = val.apply(build_augmented_input, axis=1)\n",
    "test['model_input'] = test.apply(build_augmented_input, axis=1)\n",
    "\n",
    "# Create  new DataFrames with only what's needed for modeling\n",
    "formatted_train = train[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_val = val[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_test = test[['model_input', 'ordinal_label_id']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9uFy-91QYhCT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uFy-91QYhCT",
    "outputId": "101a41c6-f006-4ea5-e224-748989803ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "ordinal_label_id\n",
      "0     5175\n",
      "1     9230\n",
      "2     6784\n",
      "3    10140\n",
      "4     5845\n",
      "Name: count, dtype: int64\n",
      "Class 0: 5000 samples (undersampled)\n",
      "Class 1: 5000 samples (undersampled)\n",
      "Class 2: 5000 samples (undersampled)\n",
      "Class 3: 5000 samples (undersampled)\n",
      "Class 4: 5000 samples (undersampled)\n",
      "Balanced dataset: 25000 total samples\n",
      "New distribution:\n",
      "ordinal_label_id\n",
      "0    5000\n",
      "1    5000\n",
      "2    5000\n",
      "3    5000\n",
      "4    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(df, target_samples_per_class=5000):\n",
    "    \"\"\"Balance dataset by undersampling\"\"\"\n",
    "    balanced_dfs = []\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    print(df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    for class_id in range(5):\n",
    "        class_data = df[df['ordinal_label_id'] == class_id]\n",
    "\n",
    "        if len(class_data) > target_samples_per_class:\n",
    "            class_data = class_data.sample(n=target_samples_per_class, random_state=42)\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (undersampled)\")\n",
    "        else:\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (kept all)\")\n",
    "\n",
    "        balanced_dfs.append(class_data)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "    print(f\"Balanced dataset: {len(balanced_df)} total samples\")\n",
    "    print(\"New distribution:\")\n",
    "    print(balanced_df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing to training data\n",
    "formatted_train = balance_dataset(formatted_train, target_samples_per_class=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13dad1",
   "metadata": {
    "id": "6c13dad1"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbce70-16fa-4baa-8c30-ae2dc9704dc4",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641d56a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267,
     "referenced_widgets": [
      "5d3f9b35f09a470697b1ad3924e09acc",
      "ab68ed1830c3423bbc27904f21aaf5f6",
      "dbd4b9f62a894b7ca84d8d508e1d107b",
      "4bd2360a82234615b975a1d90935fb81",
      "9ef4d19fdf434d3eabccc36313d5fb60",
      "8ae05f528d4747d68a2d4616761ff0b2",
      "a426be591eb346339ad701b51f3c6213",
      "a7b2163761554730a1645eba2d24cf7f",
      "6324976e748541179692883c6df2368a",
      "ff7f131a5c0441d0922627949e2f27e1",
      "c048d48ec3534b568880586209dbf443",
      "77ca4eeb992045da830bcf0a8d68f5ac",
      "6386d04666f94b1ab415b0a7f71265e5",
      "dded6da6bb994d82a2910ef788d1b2d8",
      "856bbebcf1334c03858875a9508792d4",
      "3d35c6a74ee545318fbeeb96e68b3341",
      "d5ea925ab7fe4761a574eb71075267f9",
      "75947f57bc2d4dfbb59b9e4d9fa5afac",
      "f877cf15f99545969739c8e7290e6e58",
      "c497a3c2a5864d138d5e9d14e2bb4ca7",
      "73a99b615b424d4298f68bb45fcc1ee8",
      "61e10086534c44f7b5a0b605a6be8494",
      "1693c3864eb9435bb7e9e2d0275f4c13",
      "e2dbe648ddf445c0af90dcb9447a7def",
      "919bac8386494e3eb31e182de571d210",
      "1d384f5082514794b5d833e0a7f2e5f3",
      "139a3cba0e574f188793625a48afcc62",
      "e3868097d7444927826afbbe2c95fa7b",
      "366df97bcd9943f7859b83ce0d7c19e7",
      "6e1aea27009e4292b5e34f9d5c609f61",
      "03832a4062994496ba436f4f559d4d69",
      "6554aa02e14b400ca2996f7852e0d482",
      "2d62eac39daa4adfbb64180c364e1ac9",
      "892cfbfc2c8b47e0816409eeed192f8e",
      "6d6a82b115454ca29a0d63c4a4b08b54",
      "3bb33970e76b4cc9bdeffa3a3f4945bc",
      "68d5b5164e354f5089b32ff301ff161c",
      "cd3e2a1317ea4bfb859d017dc2275b50",
      "f03f31cb1ccc48a7b191b68a35b977a0",
      "76cd9bc65ce04f60809ece0d944c4c52",
      "63af3dda74e84864aacbc55316a8181f",
      "7853784bf0c94d7c837ede06fb117f71",
      "586833fbf74d4665af37aa034257280b",
      "823197ef947e4531ae82b6225ebee846"
     ]
    },
    "id": "641d56a1",
    "outputId": "98f51fdd-522d-4e1d-9214-681f6a673a1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3f9b35f09a470697b1ad3924e09acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ca4eeb992045da830bcf0a8d68f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1693c3864eb9435bb7e9e2d0275f4c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892cfbfc2c8b47e0816409eeed192f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_data(data, max_length=128):\n",
    "    return tokenizer(\n",
    "        data['model_input'].tolist(),\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_data(formatted_train)\n",
    "val_encodings = tokenize_data(formatted_val)\n",
    "test_encodings = tokenize_data(formatted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022a3ee0",
   "metadata": {
    "id": "022a3ee0"
   },
   "outputs": [],
   "source": [
    "## define a PyTorch Dataset\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels  # Should be integers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])  # For training\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Convert labels to integers if not already\n",
    "train_labels = formatted_train['ordinal_label_id'].tolist()\n",
    "val_labels = formatted_val['ordinal_label_id'].tolist()\n",
    "test_labels = formatted_test['ordinal_label_id'].tolist()\n",
    "\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a74d9d",
   "metadata": {
    "id": "27a74d9d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define mapping between label id and sentiment for later use and conveniency\n",
    "ordinal_label2id = ordinal_mapping\n",
    "ordinal_id2label = {v: k for k, v in ordinal_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c673006c",
   "metadata": {
    "id": "c673006c"
   },
   "outputs": [],
   "source": [
    "def compute_detailed_metrics(eval_pred):\n",
    "    \"\"\"Enhanced metrics using HuggingFace Evaluate library\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Load HuggingFace metrics (cached after first load)\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "    # Compute standard classification metrics\n",
    "    results = {}\n",
    "\n",
    "    # Basic metrics\n",
    "    results.update(accuracy_metric.compute(predictions=predictions, references=labels))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
    "    results.update(precision_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(recall_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "\n",
    "    # Per-class F1 scores (HF doesn't have this built-in, so keep custom)\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "    for i, class_name in enumerate(['extremely_negative', 'negative', 'neutral', 'positive', 'extremely_positive']):\n",
    "        results[f'f1_{class_name}'] = f1_per_class[i]\n",
    "\n",
    "        # Per-class precision and recall\n",
    "        precision_per_class = precision_score(labels, predictions, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, predictions, average=None, zero_division=0)\n",
    "        results[f'precision_{class_name}'] = precision_per_class[i]\n",
    "        results[f'recall_{class_name}'] = recall_per_class[i]\n",
    "\n",
    "        # Per-class accuracy\n",
    "        class_mask = (labels == i)\n",
    "        if class_mask.sum() > 0:\n",
    "            results[f'accuracy_{class_name}'] = accuracy_score(labels[class_mask], predictions[class_mask])\n",
    "        else:\n",
    "            results[f'accuracy_{class_name}'] = 0.0\n",
    "\n",
    "    # Custom ordinal metrics (HF doesn't have these)\n",
    "    results['mae'] = np.mean(np.abs(predictions - labels))\n",
    "    results['adjacent_accuracy'] = np.sum(np.abs(predictions - labels) <= 1) / len(labels)\n",
    "\n",
    "    # Quadratic Weighted Kappa (custom)\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    try:\n",
    "        qwk = cohen_kappa_score(labels, predictions, weights='quadratic')\n",
    "        results['quadratic_weighted_kappa'] = qwk\n",
    "    except:\n",
    "        results['quadratic_weighted_kappa'] = 0.0\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b58598b",
   "metadata": {
    "id": "9b58598b"
   },
   "outputs": [],
   "source": [
    "def find_optimal_batch_size(base_batch_size):\n",
    "    \"\"\"Find the largest batch size that fits in GPU memory\"\"\"\n",
    "    if device.type == \"cpu\":\n",
    "        return base_batch_size\n",
    "\n",
    "    # Try larger batch sizes for GPU\n",
    "    for multiplier in [4, 3, 2, 1]:\n",
    "        try_batch_size = base_batch_size * multiplier\n",
    "        try:\n",
    "            # Test if this batch size fits\n",
    "            dummy_input = torch.randn(try_batch_size, 128, 768, device=device)\n",
    "            dummy_output = torch.randn(try_batch_size, 5, device=device)\n",
    "            del dummy_input, dummy_output\n",
    "            torch.cuda.empty_cache() if device.type == \"cuda\" else None\n",
    "            return try_batch_size\n",
    "        except RuntimeError:  # Out of memory\n",
    "            continue\n",
    "    return base_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Td0xg4gjBac4",
   "metadata": {
    "id": "Td0xg4gjBac4"
   },
   "outputs": [],
   "source": [
    "class SimpleMetricsLogger(TrainerCallback):\n",
    "    \"\"\"Simple callback to log detailed metrics every epoch\"\"\"\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None or not wandb.run:\n",
    "            return\n",
    "\n",
    "        # Only log when we have evaluation metrics (after each epoch)\n",
    "        if 'eval_loss' in logs:\n",
    "            current_epoch = int(state.epoch)\n",
    "\n",
    "            # Get current learning rate\n",
    "            current_lr = args.learning_rate\n",
    "            if 'learning_rate' in logs:\n",
    "                current_lr = logs['learning_rate']\n",
    "\n",
    "            #Get training loss from state history\n",
    "            train_loss = 0\n",
    "            if state.log_history:\n",
    "                # Find the most recent training loss\n",
    "                for log_entry in reversed(state.log_history):\n",
    "                    if 'train_loss' in log_entry:\n",
    "                        train_loss = log_entry['train_loss']\n",
    "                        break\n",
    "\n",
    "            detailed_metrics = {\n",
    "                \"Epoch\": current_epoch,\n",
    "                \"Stage\": 1,\n",
    "                \"Unfrozen_Layers\": 12,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Train Accuracy\": 0,  # Usually not computed during training\n",
    "                \"Validation Loss\": logs.get('eval_loss', 0),\n",
    "                \"Validation Accuracy\": logs.get('eval_accuracy', 0),\n",
    "                \"Validation Precision\": logs.get('eval_precision_macro', 0),\n",
    "                \"Validation Recall\": logs.get('eval_recall_macro', 0),\n",
    "                \"Validation F1\": logs.get('eval_f1_macro', 0),\n",
    "                \"Validation MAE\": logs.get('eval_mae', 0),\n",
    "                \"Validation Adjacent Accuracy\": logs.get('eval_adjacent_accuracy', 0),\n",
    "                \"Validation QWK\": logs.get('eval_quadratic_weighted_kappa', 0),\n",
    "                \"Learning_Rate\": current_lr,\n",
    "            }\n",
    "\n",
    "            # Log to WandB\n",
    "            wandb.log(detailed_metrics)\n",
    "\n",
    "            #Print progress to console\n",
    "            print(f\"Epoch {current_epoch}: \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, \"  # ‚Üê Now shows real values\n",
    "                  f\"Val Loss: {logs.get('eval_loss', 0):.4f}, \"\n",
    "                  f\"Val F1: {logs.get('eval_f1_macro', 0):.4f}, \"\n",
    "                  f\"QWK: {logs.get('eval_quadratic_weighted_kappa', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qHQHdNiVKd4P",
   "metadata": {
    "id": "qHQHdNiVKd4P"
   },
   "outputs": [],
   "source": [
    "def save_training_checkpoint(model, optimizer, epoch, loss, trial_params, filepath, trial_number, current_score, trainer):\n",
    "    \"\"\"Save complete training checkpoint and handle best model updates\"\"\"\n",
    "    global best_score, best_model_path\n",
    "\n",
    "    # Get the trial directory from filepath\n",
    "    trial_dir = os.path.dirname(filepath)\n",
    "\n",
    "    # Save trial checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'trial_params': trial_params,\n",
    "        'model_config': model.config.to_dict(),\n",
    "        'tokenizer_name': model_name,\n",
    "        'current_score': current_score,  # Add score to checkpoint\n",
    "        'trial_number': trial_number,\n",
    "    }\n",
    "\n",
    "    # Save all trial files in the same directory\n",
    "    torch.save(checkpoint, filepath)\n",
    "    torch.save(model.state_dict(), os.path.join(trial_dir, 'model_roberta_weights.pt'))\n",
    "    torch.save(model, os.path.join(trial_dir, 'model_roberta.pt'))\n",
    "\n",
    "    print(f\"‚úÖ Trial checkpoint saved: {filepath}\")\n",
    "    print(f\"‚úÖ Model files saved in: {trial_dir}\")\n",
    "\n",
    "    # Update best model if needed\n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "\n",
    "        # Save HuggingFace format to best model directory\n",
    "        trainer.save_model(best_model_path)\n",
    "\n",
    "        # Also save our custom format in best model directory\n",
    "        os.makedirs(best_model_path, exist_ok=True)\n",
    "        best_checkpoint_path = os.path.join(best_model_path, 'best_checkpoint.ckpt')\n",
    "        best_weights_path = os.path.join(best_model_path, 'model_roberta_weights.pt')\n",
    "        best_model_file_path = os.path.join(best_model_path, 'model_roberta.pt')\n",
    "\n",
    "        torch.save(checkpoint, best_checkpoint_path)\n",
    "        torch.save(model.state_dict(), best_weights_path)\n",
    "        torch.save(model, best_model_file_path)\n",
    "\n",
    "        print(f\"üèÜ New best model saved! Score: {current_score:.4f} (Trial {trial_number})\")\n",
    "        print(f\"üèÜ Best model files saved in: {best_model_path}\")\n",
    "\n",
    "        # Optional: Log to W&B\n",
    "        # wandb.log({\n",
    "        #     \"best_score_so_far\": current_score,\n",
    "        #     \"best_trial_number\": trial_number,\n",
    "        # })\n",
    "    else:\n",
    "        print(f\"üìä Trial {trial_number} score: {current_score:.4f} (Best: {best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68de4939",
   "metadata": {
    "id": "68de4939"
   },
   "outputs": [],
   "source": [
    "# Global variables to track best model\n",
    "best_score = 0.0\n",
    "best_model_path = \"./best_roberta_model_so_far\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a27e8-4b3a-478b-8192-aa4c52657031",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a177f371",
   "metadata": {
    "id": "a177f371"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Clean, organized objective function for Optuna hyperparameter optimization\"\"\"\n",
    "    global best_score, best_model_path\n",
    "\n",
    "    # === GPU MEMORY CLEANUP ===\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # === HYPERPARAMETER SAMPLING ===\n",
    "    # Core training parameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 3e-5, 5e-4, log=True)\n",
    "    base_batch_size = trial.suggest_categorical(\"batch_size\", [16,32,64])\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.05, 0.15)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 10, 15)\n",
    "\n",
    "    # Advanced optimization parameters\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.15)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.05, 0.15)\n",
    "\n",
    "    # Model architecture parameters\n",
    "    attention_dropout = trial.suggest_float(\"attention_dropout\", 0.3, 0.4)\n",
    "    hidden_dropout = trial.suggest_float(\"hidden_dropout\", 0.3, 0.4)\n",
    "\n",
    "    #R-drop parameter\n",
    "    # rdrop_alpha = trial.suggest_float(\"rdrop_alpha\", 0.0, 1.0)\n",
    "\n",
    "    # PRINT CHOSEN PARAMETERS\n",
    "    print(f\"TRIAL {trial.number} - TESTING THESE PARAMETERS:\")\n",
    "    print(f\"Learning Rate:      {learning_rate:.2e}\")\n",
    "    print(f\"Epochs:             {num_epochs}\")\n",
    "    print(f\"Warmup Ratio:       {warmup_ratio:.3f}\")\n",
    "    print(f\"Weight Decay:       {weight_decay:.3f}\")\n",
    "    print(f\"Attention Dropout:  {attention_dropout:.3f}\")\n",
    "    print(f\"Hidden Dropout:     {hidden_dropout:.3f}\")\n",
    "\n",
    "\n",
    "    # Optimize batch size for available hardware\n",
    "    batch_size = find_optimal_batch_size(base_batch_size)\n",
    "\n",
    "\n",
    "    # === EXPERIMENT TRACKING SETUP ===\n",
    "    wandb.init(\n",
    "        project=\"covid-tweet-sentiment-hf-roberta-regularloss\",\n",
    "        name=f\"trial_{trial.number}\",\n",
    "        config={\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"warmup_ratio\": warmup_ratio,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"attention_dropout\": attention_dropout,\n",
    "            \"hidden_dropout\": hidden_dropout\n",
    "            # \"rdrop_alpha\": rdrop_alpha ,\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # === MODEL SETUP ===\n",
    "        model = _setup_model(attention_dropout, hidden_dropout)\n",
    "\n",
    "        # === TRAINING CONFIGURATION ===\n",
    "        training_args = _create_training_args(\n",
    "            trial_number=trial.number,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            label_smoothing_factor=label_smoothing\n",
    "        )\n",
    "\n",
    "        trial_params = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"warmup_ratio\": warmup_ratio,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"attention_dropout\": attention_dropout,\n",
    "            \"hidden_dropout\": hidden_dropout\n",
    "        }\n",
    "\n",
    "        trainer = _create_trainer(model, training_args, trial.number, trial_params)\n",
    "        trainer.train()\n",
    "\n",
    "        # Set Checkpoint per trial\n",
    "        checkpoint_dir = f\"./checkpoints_roberta/trial_{trial.number}\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        final_epoch = int(trainer.state.epoch)\n",
    "        checkpoint_path = f\"{checkpoint_dir}/final_epoch_{final_epoch}.ckpt\"\n",
    "\n",
    "        # Get final training loss\n",
    "        final_loss = 0\n",
    "        if trainer.state.log_history:\n",
    "            for log_entry in reversed(trainer.state.log_history):\n",
    "                if 'train_loss' in log_entry:\n",
    "                    final_loss = log_entry['train_loss']\n",
    "                    break\n",
    "\n",
    "        eval_results = trainer.evaluate()\n",
    "        current_score = eval_results[\"eval_quadratic_weighted_kappa\"]\n",
    "\n",
    "        save_training_checkpoint(\n",
    "            model=trainer.model,\n",
    "            optimizer=None,\n",
    "            epoch=final_epoch,\n",
    "            loss=final_loss,\n",
    "            trial_params=trial_params,\n",
    "            filepath=checkpoint_path,\n",
    "            trial_number=trial.number,\n",
    "            current_score=current_score,\n",
    "            trainer=trainer\n",
    "        )\n",
    "\n",
    "        # Log GPU usage if available\n",
    "        if device.type == \"cuda\":\n",
    "            print(f\"GPU Memory Used: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "        return current_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed: {e}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    finally:\n",
    "        # === CLEANUP ===\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "def _setup_model(attention_dropout, hidden_dropout):\n",
    "    \"\"\"Setup and configure the model with dropout and freezing\"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        num_labels=5,\n",
    "        id2label=ordinal_id2label,\n",
    "        label2id=ordinal_label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # Apply dropout configuration\n",
    "    model.config.attention_probs_dropout_prob = attention_dropout\n",
    "    model.config.hidden_dropout_prob = hidden_dropout\n",
    "\n",
    "    # GPU optimizations\n",
    "    if device.type == \"cuda\":\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _create_training_args(trial_number, learning_rate, batch_size, num_epochs, warmup_ratio, weight_decay, label_smoothing_factor=0.1):\n",
    "    \"\"\"Create optimized training arguments\"\"\"\n",
    "    return TrainingArguments(\n",
    "        # output_dir=f\"./results/trial_{trial_number}\",\n",
    "\n",
    "        # Core training parameters\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,  # Larger eval batch\n",
    "        learning_rate=learning_rate,\n",
    "        label_smoothing_factor=label_smoothing_factor,\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=warmup_ratio,\n",
    "\n",
    "        # Optimization\n",
    "        optim=\"adamw_torch\",\n",
    "        weight_decay=weight_decay,\n",
    "        max_grad_norm=1.0,\n",
    "\n",
    "        # Evaluation and saving\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        save_total_limit=1,\n",
    "        # load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_quadratic_weighted_kappa\",\n",
    "        greater_is_better=True,\n",
    "\n",
    "        # Performance optimizations\n",
    "        fp16=device.type == \"cuda\",\n",
    "        # tf32=device.type == \"cuda\",\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_persistent_workers=device.type == \"cuda\",\n",
    "        dataloader_num_workers=2 if device.type == \"cuda\" else 0,\n",
    "        dataloader_drop_last=False,\n",
    "        group_by_length=True,\n",
    "        gradient_accumulation_steps=1,\n",
    "        dataloader_prefetch_factor=2 if device.type == \"cuda\" else None,\n",
    "\n",
    "        # Logging\n",
    "        logging_steps=100,\n",
    "        report_to=\"wandb\",\n",
    "        remove_unused_columns=False,\n",
    "\n",
    "        # Evaluation optimizations\n",
    "        eval_accumulation_steps=None,\n",
    "        prediction_loss_only=False,\n",
    "\n",
    "    )\n",
    "\n",
    "def _create_trainer(model, training_args, trial_number, trial_params):\n",
    "    \"\"\"ordinal loss trainer\"\"\"\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStoppingCallback(early_stopping_patience=2),\n",
    "        SimpleMetricsLogger(),\n",
    "        ]\n",
    "\n",
    "    return Trainer(  # Uses ordinal loss always\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_detailed_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3_Vh9-hdl-HE",
   "metadata": {
    "id": "3_Vh9-hdl-HE"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def save_best_hyperparameters(study, model_name=\"roberta\"):\n",
    "    \"\"\"Save the best hyperparameters found by Optuna\"\"\"\n",
    "\n",
    "    # Check if any trial completed successfully\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    if not completed_trials:\n",
    "        print(\"No completed trials found. Skipping saving best hyperparameters.\")\n",
    "        return None\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    # Save to JSON file\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_score\": best_score,\n",
    "        \"best_params\": best_params,\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "        \"total_trials\": len(study.trials),\n",
    "        \"completed_trials\": len(completed_trials)\n",
    "    }\n",
    "\n",
    "    filename = f\"best_params_{model_name}.json\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"Best hyperparameters saved to {filename}\")\n",
    "    print(f\"Best score: {best_score:.4f}\")\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    print(f\"Completed {len(completed_trials)}/{len(study.trials)} trials\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L_B3GAlccXSV",
   "metadata": {
    "id": "L_B3GAlccXSV"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07eb100c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2821ed6da4b84696a6fdbada949ef7fc",
      "92a2046435b4414da1de707e5616647e",
      "22f9cb7994fd4a67bf81f02a73afab21",
      "62ee1d3b01304d83b470219247537848",
      "baedcade0ee746e49e6ee6dfb29b8ef5",
      "ec5a153e1c734de6972a052ec481ff18",
      "df1c6ae7b76641718191d6235ba93470",
      "f6272cfb9525484ba89ad2958fc2e116",
      "36082894cdff4b4ea2fbcbd95cde35e8",
      "544a4f01e08844cabb222d3e8e35daf2",
      "29f362b8857642bda4b45cd2a33cb2c6",
      "83027707f4be4bf1b4f09c3a7a16151d",
      "eab65e368fc0400087dbefa4625fca54",
      "549166b7ad4f4c098128bd4c80f3104e",
      "1f4a6a68928b426eb852e26587bc4a9c",
      "451e74328fb4440e9c925511f623d5e3",
      "119ff29627ed46a6a22c3223766f5a3a",
      "b3617441486d402eba3e7a49aa523e58",
      "79075c00e23a4f1cb046fab73223bd6c",
      "b890d8f88b894d5a8912d510439fa5d3",
      "7ff92333757f40068a3a54a7feff9c34",
      "781ff2d42cbd47fbabed94779de35cd2",
      "b35a4cdc72ec465e97161702ae0df8f1",
      "d50c99c8a02047f59ef5b259b9cfd2c1",
      "a6482dbb156d412b82d3888e907921ab",
      "7435ba26857c40f4ac99844c23d15ad3",
      "0781a380a5be4acebbc43de221648bb2",
      "5d425cece12c447e9d959e23b2914c53",
      "0706eec76d844c37942e2fc347490eb5",
      "3e12c09bd97e41d1af906dd434212875",
      "c536190a57d747f28a2912abffba2b53",
      "fb9faf150f4d4b2f99c2fd9c398901b0",
      "935ba084b35444cdb033bd63e0840749",
      "e821e71550634d4ba1c1d5b165bf82f0",
      "44403ef97ae14190bd4d3c1df03cb02e",
      "c5ba775605404c879fe18cf9cea6741c",
      "85282a4c1f734d7f940bf33b92a52014",
      "b23837ee38f94ea1bfa0b1009469c96b",
      "c56d8af61d8b4aa99569d8c7b864fa21",
      "af99290f2db64c73b026f8b1b1543cfd",
      "1d50de1f582d402a85a270c785506d08",
      "b56bce7626144e22ba1bdb0fe935fcbe",
      "18f5e54594e64c298235412d99528578",
      "901eaa5011d84dc7925a926657f441aa",
      "a50e7258639a4462a71f17f4b00e4c99",
      "fbd5b1dec6fb4cd0870f195bcaa7a0fc",
      "3e4d1a29fb2b4ae2b74b426e570dfe72",
      "d3ccbf67d1164279ace2ec381d76e826",
      "4f985d2d1be246139246672f5281482a",
      "05295c9735714280a7855522b6f347a6",
      "e0a0ab20fc254c6e8511d3c81c7284dd",
      "b1daa66e3e3a4c5e86de6166c5904579",
      "8e5f47b812904aa2aa7e18fedaad3f20",
      "fe83c962074f4cc9a21b937a06417f04",
      "98fb681487a74d208327de07460fa650",
      "e3bb2621f09d4e1695d296891f86b98b",
      "653cbc00b5ef478191ef34bcbd3c844e",
      "00ff52cc87324652be2f158cfacc004b",
      "ba695eb30f6048039d4f1da395800e26",
      "dcab8c5c2f924a2fb146b708f562d5a8",
      "a575e347df3644edb6afa2cf2dd33c19",
      "af9030671d9344e9a2c01f2b3c686d37",
      "5bb34f6d268447d3858e6ebb2c7728c8",
      "d6bca1a0c241452eae8c1a4665272946",
      "bd18d098e9f341fdb60fc716bafd618f",
      "9288a74ba9f74b33afa22836d34b9efb"
     ]
    },
    "id": "07eb100c",
    "outputId": "4ac4c158-aa4f-48f5-910a-75280190730b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 12:44:54,324] A new study created in memory with name: no-name-003c7642-7dcd-46d2-b3e5-e4293adf27cb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 0 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      2.92e-04\n",
      "Epochs:             14\n",
      "Warmup Ratio:       0.073\n",
      "Weight Decay:       0.066\n",
      "Attention Dropout:  0.386\n",
      "Hidden Dropout:     0.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_124454-xcsk97pd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/xcsk97pd' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/xcsk97pd' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/xcsk97pd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2821ed6da4b84696a6fdbada949ef7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83027707f4be4bf1b4f09c3a7a16151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='1372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 392/1372 04:55 < 12:23, 1.32 it/s, Epoch 4/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.004826</td>\n",
       "      <td>0.671793</td>\n",
       "      <td>0.661955</td>\n",
       "      <td>0.671601</td>\n",
       "      <td>0.705139</td>\n",
       "      <td>0.675851</td>\n",
       "      <td>0.558981</td>\n",
       "      <td>0.854508</td>\n",
       "      <td>0.854508</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.671848</td>\n",
       "      <td>0.425137</td>\n",
       "      <td>0.425137</td>\n",
       "      <td>0.805284</td>\n",
       "      <td>0.822770</td>\n",
       "      <td>0.788526</td>\n",
       "      <td>0.788526</td>\n",
       "      <td>0.607835</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>0.553725</td>\n",
       "      <td>0.553725</td>\n",
       "      <td>0.742976</td>\n",
       "      <td>0.630742</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.417489</td>\n",
       "      <td>0.924719</td>\n",
       "      <td>0.828528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.124800</td>\n",
       "      <td>0.821617</td>\n",
       "      <td>0.767501</td>\n",
       "      <td>0.766345</td>\n",
       "      <td>0.760432</td>\n",
       "      <td>0.790638</td>\n",
       "      <td>0.756432</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.671858</td>\n",
       "      <td>0.684032</td>\n",
       "      <td>0.660109</td>\n",
       "      <td>0.660109</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.856810</td>\n",
       "      <td>0.827897</td>\n",
       "      <td>0.827897</td>\n",
       "      <td>0.743986</td>\n",
       "      <td>0.822412</td>\n",
       "      <td>0.679216</td>\n",
       "      <td>0.679216</td>\n",
       "      <td>0.832736</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.291026</td>\n",
       "      <td>0.947670</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.853100</td>\n",
       "      <td>0.892344</td>\n",
       "      <td>0.756025</td>\n",
       "      <td>0.757975</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.773499</td>\n",
       "      <td>0.730829</td>\n",
       "      <td>0.591139</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.634119</td>\n",
       "      <td>0.651672</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.852154</td>\n",
       "      <td>0.882992</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.761980</td>\n",
       "      <td>0.763179</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.313978</td>\n",
       "      <td>0.938260</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.768648</td>\n",
       "      <td>0.769362</td>\n",
       "      <td>0.786432</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>0.799564</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.697517</td>\n",
       "      <td>0.721120</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>0.838226</td>\n",
       "      <td>0.942416</td>\n",
       "      <td>0.754781</td>\n",
       "      <td>0.754781</td>\n",
       "      <td>0.736725</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.824221</td>\n",
       "      <td>0.769484</td>\n",
       "      <td>0.887342</td>\n",
       "      <td>0.887342</td>\n",
       "      <td>0.294469</td>\n",
       "      <td>0.940555</td>\n",
       "      <td>0.870426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35a4cdc72ec465e97161702ae0df8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e821e71550634d4ba1c1d5b165bf82f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50e7258639a4462a71f17f4b00e4c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bb2621f09d4e1695d296891f86b98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.0048, Val F1: 0.0000, QWK: 0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 0.8216, Val F1: 0.0000, QWK: 0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.8923, Val F1: 0.0000, QWK: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.7964, Val F1: 0.0000, QWK: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.8308, Val Loss: 0.7964, Val F1: 0.0000, QWK: 0.8704\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_0/final_epoch_4.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_0\n",
      "üèÜ New best model saved! Score: 0.8704 (Trial 0)\n",
      "üèÜ Best model files saved in: ./best_roberta_model_so_far\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÜ</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñà‚ñÜ‚ñá‚ñá</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÖ‚ñÜ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñà‚ñá‚ñÅ‚ñá‚ñá</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñà‚ñÜ‚ñà‚ñà</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÑ‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÜ</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñá‚ñÖ‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÅ‚ñà‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñá‚ñÖ‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÜ</td></tr><tr><td>eval/f1_positive</td><td>‚ñÅ‚ñá‚ñà‚ñá‚ñá</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÅ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñà</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÑ</td></tr><tr><td>eval/precision_negative</td><td>‚ñÉ‚ñÑ‚ñÅ‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÇ</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñà‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñà‚ñá‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÖ‚ñÜ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñà‚ñá‚ñÅ‚ñá‚ñá</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñà‚ñÜ‚ñà‚ñà</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÑ‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÜ‚ñà‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÑ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>4</td></tr><tr><td>Learning_Rate</td><td>0.00029</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.83078</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.76865</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.94056</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.7964</td></tr><tr><td>Validation MAE</td><td>0.29447</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.87043</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.76865</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.75205</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.88734</td></tr><tr><td>eval/accuracy_negative</td><td>0.67541</td></tr><tr><td>eval/accuracy_neutral</td><td>0.75478</td></tr><tr><td>eval/accuracy_positive</td><td>0.77804</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.94056</td></tr><tr><td>eval/f1</td><td>0.76936</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.77508</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.82422</td></tr><tr><td>eval/f1_negative</td><td>0.69752</td></tr><tr><td>eval/f1_neutral</td><td>0.83823</td></tr><tr><td>eval/f1_positive</td><td>0.73672</td></tr><tr><td>eval/loss</td><td>0.7964</td></tr><tr><td>eval/mae</td><td>0.29447</td></tr><tr><td>eval/precision</td><td>0.78643</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.79956</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.76948</td></tr><tr><td>eval/precision_negative</td><td>0.72112</td></tr><tr><td>eval/precision_neutral</td><td>0.94242</td></tr><tr><td>eval/precision_positive</td><td>0.69958</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.87043</td></tr><tr><td>eval/recall</td><td>0.76952</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.75205</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.88734</td></tr><tr><td>eval/recall_negative</td><td>0.67541</td></tr><tr><td>eval/recall_neutral</td><td>0.75478</td></tr><tr><td>eval/recall_positive</td><td>0.77804</td></tr><tr><td>eval/runtime</td><td>6.2841</td></tr><tr><td>eval/samples_per_second</td><td>693.342</td></tr><tr><td>eval/steps_per_second</td><td>1.432</td></tr><tr><td>total_flos</td><td>2891577938817888.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>392</td></tr><tr><td>train/grad_norm</td><td>2.91509</td></tr><tr><td>train/learning_rate</td><td>0.00027</td></tr><tr><td>train/loss</td><td>0.6906</td></tr><tr><td>train_loss</td><td>0.83078</td></tr><tr><td>train_runtime</td><td>299.4671</td></tr><tr><td>train_samples_per_second</td><td>1168.743</td></tr><tr><td>train_steps_per_second</td><td>4.581</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/xcsk97pd' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/xcsk97pd</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_124454-xcsk97pd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 12:50:52,726] Trial 0 finished with value: 0.8704257608882765 and parameters: {'learning_rate': 0.00029176184737646536, 'batch_size': 64, 'label_smoothing': 0.06578337081435587, 'num_epochs': 14, 'warmup_ratio': 0.07333428729811922, 'weight_decay': 0.06627383179240057, 'attention_dropout': 0.38585144580527303, 'hidden_dropout': 0.37965759612471295}. Best is trial 0 with value: 0.8704257608882765.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      3.55e-05\n",
      "Epochs:             15\n",
      "Warmup Ratio:       0.124\n",
      "Weight Decay:       0.065\n",
      "Attention Dropout:  0.366\n",
      "Hidden Dropout:     0.346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_125052-ore51hia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/ore51hia' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/ore51hia' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/ore51hia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2940' max='2940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2940/2940 19:31, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>1.019028</td>\n",
       "      <td>0.614184</td>\n",
       "      <td>0.607446</td>\n",
       "      <td>0.615032</td>\n",
       "      <td>0.649760</td>\n",
       "      <td>0.677338</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.525694</td>\n",
       "      <td>0.571979</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.685273</td>\n",
       "      <td>0.725786</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>0.523261</td>\n",
       "      <td>0.573970</td>\n",
       "      <td>0.480784</td>\n",
       "      <td>0.480784</td>\n",
       "      <td>0.707250</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.808861</td>\n",
       "      <td>0.808861</td>\n",
       "      <td>0.502180</td>\n",
       "      <td>0.904062</td>\n",
       "      <td>0.782339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.918600</td>\n",
       "      <td>0.931190</td>\n",
       "      <td>0.696580</td>\n",
       "      <td>0.690178</td>\n",
       "      <td>0.709403</td>\n",
       "      <td>0.730566</td>\n",
       "      <td>0.762906</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.817623</td>\n",
       "      <td>0.817623</td>\n",
       "      <td>0.670991</td>\n",
       "      <td>0.728553</td>\n",
       "      <td>0.621858</td>\n",
       "      <td>0.621858</td>\n",
       "      <td>0.808858</td>\n",
       "      <td>0.839178</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.671610</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.725577</td>\n",
       "      <td>0.592622</td>\n",
       "      <td>0.935443</td>\n",
       "      <td>0.935443</td>\n",
       "      <td>0.373422</td>\n",
       "      <td>0.939178</td>\n",
       "      <td>0.850627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.745237</td>\n",
       "      <td>0.792288</td>\n",
       "      <td>0.792374</td>\n",
       "      <td>0.805106</td>\n",
       "      <td>0.795720</td>\n",
       "      <td>0.816369</td>\n",
       "      <td>0.836559</td>\n",
       "      <td>0.797131</td>\n",
       "      <td>0.797131</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.769870</td>\n",
       "      <td>0.709290</td>\n",
       "      <td>0.709290</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>0.894207</td>\n",
       "      <td>0.798650</td>\n",
       "      <td>0.798650</td>\n",
       "      <td>0.758308</td>\n",
       "      <td>0.731245</td>\n",
       "      <td>0.787451</td>\n",
       "      <td>0.787451</td>\n",
       "      <td>0.837321</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.265779</td>\n",
       "      <td>0.947441</td>\n",
       "      <td>0.880020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.696527</td>\n",
       "      <td>0.811568</td>\n",
       "      <td>0.811191</td>\n",
       "      <td>0.811556</td>\n",
       "      <td>0.821788</td>\n",
       "      <td>0.816683</td>\n",
       "      <td>0.775322</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.762702</td>\n",
       "      <td>0.779680</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.857817</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.817773</td>\n",
       "      <td>0.817773</td>\n",
       "      <td>0.785856</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.229057</td>\n",
       "      <td>0.961900</td>\n",
       "      <td>0.906286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>0.735900</td>\n",
       "      <td>0.809961</td>\n",
       "      <td>0.810121</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.809716</td>\n",
       "      <td>0.825616</td>\n",
       "      <td>0.795066</td>\n",
       "      <td>0.858607</td>\n",
       "      <td>0.858607</td>\n",
       "      <td>0.766741</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.834267</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>0.805041</td>\n",
       "      <td>0.763176</td>\n",
       "      <td>0.851765</td>\n",
       "      <td>0.851765</td>\n",
       "      <td>0.829713</td>\n",
       "      <td>0.929356</td>\n",
       "      <td>0.749367</td>\n",
       "      <td>0.749367</td>\n",
       "      <td>0.223089</td>\n",
       "      <td>0.968786</td>\n",
       "      <td>0.908327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.735637</td>\n",
       "      <td>0.814322</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.830675</td>\n",
       "      <td>0.817029</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.744476</td>\n",
       "      <td>0.772941</td>\n",
       "      <td>0.718033</td>\n",
       "      <td>0.718033</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.916561</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.815523</td>\n",
       "      <td>0.800487</td>\n",
       "      <td>0.828715</td>\n",
       "      <td>0.774118</td>\n",
       "      <td>0.774118</td>\n",
       "      <td>0.856975</td>\n",
       "      <td>0.800880</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>0.963277</td>\n",
       "      <td>0.908134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.730182</td>\n",
       "      <td>0.826716</td>\n",
       "      <td>0.827163</td>\n",
       "      <td>0.831501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.849699</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.788421</td>\n",
       "      <td>0.760406</td>\n",
       "      <td>0.818579</td>\n",
       "      <td>0.818579</td>\n",
       "      <td>0.838567</td>\n",
       "      <td>0.821814</td>\n",
       "      <td>0.856018</td>\n",
       "      <td>0.856018</td>\n",
       "      <td>0.811722</td>\n",
       "      <td>0.831414</td>\n",
       "      <td>0.792941</td>\n",
       "      <td>0.792941</td>\n",
       "      <td>0.870199</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.831646</td>\n",
       "      <td>0.831646</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.968327</td>\n",
       "      <td>0.912203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.753481</td>\n",
       "      <td>0.820289</td>\n",
       "      <td>0.819374</td>\n",
       "      <td>0.825980</td>\n",
       "      <td>0.826541</td>\n",
       "      <td>0.839532</td>\n",
       "      <td>0.871965</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.787198</td>\n",
       "      <td>0.809469</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.850084</td>\n",
       "      <td>0.848655</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>0.792895</td>\n",
       "      <td>0.816972</td>\n",
       "      <td>0.770196</td>\n",
       "      <td>0.770196</td>\n",
       "      <td>0.852364</td>\n",
       "      <td>0.782839</td>\n",
       "      <td>0.935443</td>\n",
       "      <td>0.935443</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>0.969245</td>\n",
       "      <td>0.912207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.772264</td>\n",
       "      <td>0.818683</td>\n",
       "      <td>0.817069</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.833170</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.783305</td>\n",
       "      <td>0.821343</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.809176</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.793465</td>\n",
       "      <td>0.851619</td>\n",
       "      <td>0.742745</td>\n",
       "      <td>0.742745</td>\n",
       "      <td>0.853644</td>\n",
       "      <td>0.791351</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>0.207941</td>\n",
       "      <td>0.975671</td>\n",
       "      <td>0.920443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.753087</td>\n",
       "      <td>0.833601</td>\n",
       "      <td>0.833337</td>\n",
       "      <td>0.833568</td>\n",
       "      <td>0.842389</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>0.825919</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.804573</td>\n",
       "      <td>0.801518</td>\n",
       "      <td>0.807650</td>\n",
       "      <td>0.807650</td>\n",
       "      <td>0.844492</td>\n",
       "      <td>0.812046</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.816476</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.871173</td>\n",
       "      <td>0.877892</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.191646</td>\n",
       "      <td>0.976130</td>\n",
       "      <td>0.924915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.796399</td>\n",
       "      <td>0.827404</td>\n",
       "      <td>0.826232</td>\n",
       "      <td>0.821324</td>\n",
       "      <td>0.840495</td>\n",
       "      <td>0.829450</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.911885</td>\n",
       "      <td>0.911885</td>\n",
       "      <td>0.772622</td>\n",
       "      <td>0.823239</td>\n",
       "      <td>0.727869</td>\n",
       "      <td>0.727869</td>\n",
       "      <td>0.849724</td>\n",
       "      <td>0.834962</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>0.819326</td>\n",
       "      <td>0.849327</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.871046</td>\n",
       "      <td>0.838407</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.199908</td>\n",
       "      <td>0.974983</td>\n",
       "      <td>0.922795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.804520</td>\n",
       "      <td>0.831306</td>\n",
       "      <td>0.830248</td>\n",
       "      <td>0.828486</td>\n",
       "      <td>0.841729</td>\n",
       "      <td>0.843658</td>\n",
       "      <td>0.810964</td>\n",
       "      <td>0.879098</td>\n",
       "      <td>0.879098</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.849211</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.877390</td>\n",
       "      <td>0.877390</td>\n",
       "      <td>0.817441</td>\n",
       "      <td>0.850721</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.866948</td>\n",
       "      <td>0.826636</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.193941</td>\n",
       "      <td>0.976819</td>\n",
       "      <td>0.924934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.307100</td>\n",
       "      <td>0.829331</td>\n",
       "      <td>0.828781</td>\n",
       "      <td>0.827621</td>\n",
       "      <td>0.828043</td>\n",
       "      <td>0.838504</td>\n",
       "      <td>0.846307</td>\n",
       "      <td>0.824903</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.790509</td>\n",
       "      <td>0.840098</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.845271</td>\n",
       "      <td>0.822340</td>\n",
       "      <td>0.869516</td>\n",
       "      <td>0.869516</td>\n",
       "      <td>0.812298</td>\n",
       "      <td>0.838764</td>\n",
       "      <td>0.787451</td>\n",
       "      <td>0.787451</td>\n",
       "      <td>0.863933</td>\n",
       "      <td>0.814110</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.196924</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.923517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.825283</td>\n",
       "      <td>0.827634</td>\n",
       "      <td>0.826530</td>\n",
       "      <td>0.824014</td>\n",
       "      <td>0.837193</td>\n",
       "      <td>0.833659</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.872951</td>\n",
       "      <td>0.872951</td>\n",
       "      <td>0.780854</td>\n",
       "      <td>0.826618</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.846699</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.817998</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.866104</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.908861</td>\n",
       "      <td>0.908861</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>0.977966</td>\n",
       "      <td>0.925244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.822583</td>\n",
       "      <td>0.830847</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.828232</td>\n",
       "      <td>0.840176</td>\n",
       "      <td>0.841066</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.872951</td>\n",
       "      <td>0.872951</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.829916</td>\n",
       "      <td>0.751913</td>\n",
       "      <td>0.751913</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.876265</td>\n",
       "      <td>0.876265</td>\n",
       "      <td>0.819140</td>\n",
       "      <td>0.848027</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.868039</td>\n",
       "      <td>0.831787</td>\n",
       "      <td>0.907595</td>\n",
       "      <td>0.907595</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>0.978196</td>\n",
       "      <td>0.926170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.0190, Val F1: 0.0000, QWK: 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 0.9312, Val F1: 0.0000, QWK: 0.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.7452, Val F1: 0.0000, QWK: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.6965, Val F1: 0.0000, QWK: 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.7359, Val F1: 0.0000, QWK: 0.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.7356, Val F1: 0.0000, QWK: 0.9081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.7302, Val F1: 0.0000, QWK: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.7535, Val F1: 0.0000, QWK: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.7723, Val F1: 0.0000, QWK: 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.7531, Val F1: 0.0000, QWK: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0000, Val Loss: 0.7964, Val F1: 0.0000, QWK: 0.9228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0000, Val Loss: 0.8045, Val F1: 0.0000, QWK: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0000, Val Loss: 0.8293, Val F1: 0.0000, QWK: 0.9235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0000, Val Loss: 0.8253, Val F1: 0.0000, QWK: 0.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.0000, Val Loss: 0.8226, Val F1: 0.0000, QWK: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.5074, Val Loss: 0.8226, Val F1: 0.0000, QWK: 0.9262\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_1/final_epoch_15.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_1\n",
      "üèÜ New best model saved! Score: 0.9262 (Trial 1)\n",
      "üèÜ Best model files saved in: ./best_roberta_model_so_far\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÉ‚ñà‚ñÜ‚ñá‚ñÅ‚ñá‚ñÑ‚ñà‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_positive</td><td>‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÉ‚ñà‚ñÜ‚ñá‚ñÅ‚ñá‚ñÑ‚ñà‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_positive</td><td>‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÇ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÇ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ</td></tr><tr><td>train/learning_rate</td><td>‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>15</td></tr><tr><td>Learning_Rate</td><td>4e-05</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.50738</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.83085</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.9782</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.82258</td></tr><tr><td>Validation MAE</td><td>0.19279</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.92617</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.83085</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.87295</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.90759</td></tr><tr><td>eval/accuracy_negative</td><td>0.75191</td></tr><tr><td>eval/accuracy_neutral</td><td>0.87627</td></tr><tr><td>eval/accuracy_positive</td><td>0.79216</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.9782</td></tr><tr><td>eval/f1</td><td>0.82986</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.84107</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.86804</td></tr><tr><td>eval/f1_negative</td><td>0.78899</td></tr><tr><td>eval/f1_neutral</td><td>0.8472</td></tr><tr><td>eval/f1_positive</td><td>0.81914</td></tr><tr><td>eval/loss</td><td>0.82258</td></tr><tr><td>eval/mae</td><td>0.19279</td></tr><tr><td>eval/precision</td><td>0.82823</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.81143</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.83179</td></tr><tr><td>eval/precision_negative</td><td>0.82992</td></tr><tr><td>eval/precision_neutral</td><td>0.82</td></tr><tr><td>eval/precision_positive</td><td>0.84803</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.92617</td></tr><tr><td>eval/recall</td><td>0.84018</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.87295</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.90759</td></tr><tr><td>eval/recall_negative</td><td>0.75191</td></tr><tr><td>eval/recall_neutral</td><td>0.87627</td></tr><tr><td>eval/recall_positive</td><td>0.79216</td></tr><tr><td>eval/runtime</td><td>5.656</td></tr><tr><td>eval/samples_per_second</td><td>770.334</td></tr><tr><td>eval/steps_per_second</td><td>3.182</td></tr><tr><td>total_flos</td><td>1.0536487901772336e+16</td></tr><tr><td>train/epoch</td><td>15</td></tr><tr><td>train/global_step</td><td>2940</td></tr><tr><td>train/grad_norm</td><td>7.69822</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2983</td></tr><tr><td>train_loss</td><td>0.50738</td></tr><tr><td>train_runtime</td><td>1172.4592</td></tr><tr><td>train_samples_per_second</td><td>319.841</td></tr><tr><td>train_steps_per_second</td><td>2.508</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/ore51hia' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/ore51hia</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_125052-ore51hia/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 13:12:06,956] Trial 1 finished with value: 0.9261703976204811 and parameters: {'learning_rate': 3.551627588729587e-05, 'batch_size': 32, 'label_smoothing': 0.05996684663319153, 'num_epochs': 15, 'warmup_ratio': 0.12350792433050267, 'weight_decay': 0.0648880207916102, 'attention_dropout': 0.3659130679774672, 'hidden_dropout': 0.345793511961371}. Best is trial 1 with value: 0.9261703976204811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      2.41e-04\n",
      "Epochs:             11\n",
      "Warmup Ratio:       0.144\n",
      "Weight Decay:       0.085\n",
      "Attention Dropout:  0.376\n",
      "Hidden Dropout:     0.353\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_131206-uwyc0jiw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/uwyc0jiw' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/uwyc0jiw' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/uwyc0jiw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2156' max='2156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2156/2156 14:17, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245800</td>\n",
       "      <td>0.910492</td>\n",
       "      <td>0.739041</td>\n",
       "      <td>0.739824</td>\n",
       "      <td>0.742900</td>\n",
       "      <td>0.750166</td>\n",
       "      <td>0.723906</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.638030</td>\n",
       "      <td>0.670277</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.860435</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.742597</td>\n",
       "      <td>0.719647</td>\n",
       "      <td>0.767059</td>\n",
       "      <td>0.767059</td>\n",
       "      <td>0.789973</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.737975</td>\n",
       "      <td>0.737975</td>\n",
       "      <td>0.322699</td>\n",
       "      <td>0.944687</td>\n",
       "      <td>0.864594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>1.162163</td>\n",
       "      <td>0.568281</td>\n",
       "      <td>0.551918</td>\n",
       "      <td>0.649956</td>\n",
       "      <td>0.621346</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.440323</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.298361</td>\n",
       "      <td>0.298361</td>\n",
       "      <td>0.764398</td>\n",
       "      <td>0.913928</td>\n",
       "      <td>0.656918</td>\n",
       "      <td>0.656918</td>\n",
       "      <td>0.384850</td>\n",
       "      <td>0.432485</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.619257</td>\n",
       "      <td>0.452423</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.596052</td>\n",
       "      <td>0.873766</td>\n",
       "      <td>0.740156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.796700</td>\n",
       "      <td>0.900680</td>\n",
       "      <td>0.751205</td>\n",
       "      <td>0.748243</td>\n",
       "      <td>0.751560</td>\n",
       "      <td>0.772085</td>\n",
       "      <td>0.690355</td>\n",
       "      <td>0.534231</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.580517</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.478689</td>\n",
       "      <td>0.478689</td>\n",
       "      <td>0.839822</td>\n",
       "      <td>0.830583</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>0.779540</td>\n",
       "      <td>0.788292</td>\n",
       "      <td>0.770980</td>\n",
       "      <td>0.770980</td>\n",
       "      <td>0.824701</td>\n",
       "      <td>0.867318</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>0.299977</td>\n",
       "      <td>0.955015</td>\n",
       "      <td>0.882684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>0.892770</td>\n",
       "      <td>0.776681</td>\n",
       "      <td>0.776731</td>\n",
       "      <td>0.770487</td>\n",
       "      <td>0.796445</td>\n",
       "      <td>0.709579</td>\n",
       "      <td>0.566707</td>\n",
       "      <td>0.948770</td>\n",
       "      <td>0.948770</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.707819</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.860849</td>\n",
       "      <td>0.904585</td>\n",
       "      <td>0.821147</td>\n",
       "      <td>0.821147</td>\n",
       "      <td>0.799022</td>\n",
       "      <td>0.831919</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.860149</td>\n",
       "      <td>0.841404</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>0.276566</td>\n",
       "      <td>0.952949</td>\n",
       "      <td>0.888856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.626800</td>\n",
       "      <td>0.821409</td>\n",
       "      <td>0.788616</td>\n",
       "      <td>0.789264</td>\n",
       "      <td>0.782840</td>\n",
       "      <td>0.807738</td>\n",
       "      <td>0.729118</td>\n",
       "      <td>0.588903</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.664678</td>\n",
       "      <td>0.731932</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.871252</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.833521</td>\n",
       "      <td>0.833521</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.834459</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.855354</td>\n",
       "      <td>0.846344</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.262796</td>\n",
       "      <td>0.955933</td>\n",
       "      <td>0.892345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.918941</td>\n",
       "      <td>0.767960</td>\n",
       "      <td>0.764998</td>\n",
       "      <td>0.775232</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.798937</td>\n",
       "      <td>0.703588</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.719451</td>\n",
       "      <td>0.837446</td>\n",
       "      <td>0.630601</td>\n",
       "      <td>0.630601</td>\n",
       "      <td>0.851215</td>\n",
       "      <td>0.899749</td>\n",
       "      <td>0.807649</td>\n",
       "      <td>0.807649</td>\n",
       "      <td>0.707062</td>\n",
       "      <td>0.756708</td>\n",
       "      <td>0.663529</td>\n",
       "      <td>0.663529</td>\n",
       "      <td>0.793267</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.954430</td>\n",
       "      <td>0.954430</td>\n",
       "      <td>0.275648</td>\n",
       "      <td>0.960064</td>\n",
       "      <td>0.895882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.528600</td>\n",
       "      <td>0.853806</td>\n",
       "      <td>0.813633</td>\n",
       "      <td>0.812823</td>\n",
       "      <td>0.834094</td>\n",
       "      <td>0.804901</td>\n",
       "      <td>0.785024</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.665984</td>\n",
       "      <td>0.665984</td>\n",
       "      <td>0.784460</td>\n",
       "      <td>0.764523</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.853075</td>\n",
       "      <td>0.863899</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.794002</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>0.851960</td>\n",
       "      <td>0.792165</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.223319</td>\n",
       "      <td>0.966032</td>\n",
       "      <td>0.904974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.784292</td>\n",
       "      <td>0.834978</td>\n",
       "      <td>0.834643</td>\n",
       "      <td>0.834736</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.835010</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.801959</td>\n",
       "      <td>0.798483</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.844587</td>\n",
       "      <td>0.806551</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.821399</td>\n",
       "      <td>0.864069</td>\n",
       "      <td>0.782745</td>\n",
       "      <td>0.782745</td>\n",
       "      <td>0.877743</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.190039</td>\n",
       "      <td>0.977048</td>\n",
       "      <td>0.924997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.818025</td>\n",
       "      <td>0.831535</td>\n",
       "      <td>0.831402</td>\n",
       "      <td>0.832590</td>\n",
       "      <td>0.840011</td>\n",
       "      <td>0.845098</td>\n",
       "      <td>0.810150</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.798191</td>\n",
       "      <td>0.826698</td>\n",
       "      <td>0.771585</td>\n",
       "      <td>0.771585</td>\n",
       "      <td>0.830208</td>\n",
       "      <td>0.773036</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.896513</td>\n",
       "      <td>0.823005</td>\n",
       "      <td>0.850921</td>\n",
       "      <td>0.796863</td>\n",
       "      <td>0.796863</td>\n",
       "      <td>0.876302</td>\n",
       "      <td>0.902145</td>\n",
       "      <td>0.851899</td>\n",
       "      <td>0.851899</td>\n",
       "      <td>0.189580</td>\n",
       "      <td>0.981409</td>\n",
       "      <td>0.926923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.806962</td>\n",
       "      <td>0.837273</td>\n",
       "      <td>0.837007</td>\n",
       "      <td>0.839453</td>\n",
       "      <td>0.842531</td>\n",
       "      <td>0.850361</td>\n",
       "      <td>0.856549</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.819558</td>\n",
       "      <td>0.769399</td>\n",
       "      <td>0.769399</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.773307</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.836112</td>\n",
       "      <td>0.868243</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.183842</td>\n",
       "      <td>0.980950</td>\n",
       "      <td>0.928797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.823412</td>\n",
       "      <td>0.839569</td>\n",
       "      <td>0.839078</td>\n",
       "      <td>0.839301</td>\n",
       "      <td>0.845946</td>\n",
       "      <td>0.850202</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.793633</td>\n",
       "      <td>0.827014</td>\n",
       "      <td>0.762842</td>\n",
       "      <td>0.762842</td>\n",
       "      <td>0.832981</td>\n",
       "      <td>0.785643</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.839626</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.810980</td>\n",
       "      <td>0.810980</td>\n",
       "      <td>0.890819</td>\n",
       "      <td>0.873479</td>\n",
       "      <td>0.908861</td>\n",
       "      <td>0.908861</td>\n",
       "      <td>0.181776</td>\n",
       "      <td>0.980721</td>\n",
       "      <td>0.929784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 0.9105, Val F1: 0.0000, QWK: 0.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 1.1622, Val F1: 0.0000, QWK: 0.7402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.9007, Val F1: 0.0000, QWK: 0.8827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.8928, Val F1: 0.0000, QWK: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.8214, Val F1: 0.0000, QWK: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.9189, Val F1: 0.0000, QWK: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.8538, Val F1: 0.0000, QWK: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.7843, Val F1: 0.0000, QWK: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.8180, Val F1: 0.0000, QWK: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.8070, Val F1: 0.0000, QWK: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0000, Val Loss: 0.8234, Val F1: 0.0000, QWK: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.6301, Val Loss: 0.8234, Val F1: 0.0000, QWK: 0.9298\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_2/final_epoch_11.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_2\n",
      "üèÜ New best model saved! Score: 0.9298 (Trial 2)\n",
      "üèÜ Best model files saved in: ./best_roberta_model_so_far\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>Validation MAE</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÜ‚ñÖ‚ñà‚ñá‚ñà‚ñá‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñá‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_negative</td><td>‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÑ‚ñÅ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/f1_positive</td><td>‚ñá‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>eval/mae</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñá‚ñÅ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÖ‚ñà‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÜ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÜ‚ñÖ‚ñà‚ñá‚ñà‚ñá‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_negative</td><td>‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_positive</td><td>‚ñá‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñá‚ñà‚ñÅ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñá‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñá‚ñà‚ñÅ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñá‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>11</td></tr><tr><td>Learning_Rate</td><td>0.00024</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.63012</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.83957</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.98072</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.82341</td></tr><tr><td>Validation MAE</td><td>0.18178</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.92978</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.83957</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.86066</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.90886</td></tr><tr><td>eval/accuracy_negative</td><td>0.76284</td></tr><tr><td>eval/accuracy_neutral</td><td>0.88639</td></tr><tr><td>eval/accuracy_positive</td><td>0.81098</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.98072</td></tr><tr><td>eval/f1</td><td>0.83908</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.8502</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.89082</td></tr><tr><td>eval/f1_negative</td><td>0.79363</td></tr><tr><td>eval/f1_neutral</td><td>0.83298</td></tr><tr><td>eval/f1_positive</td><td>0.83963</td></tr><tr><td>eval/loss</td><td>0.82341</td></tr><tr><td>eval/mae</td><td>0.18178</td></tr><tr><td>eval/precision</td><td>0.8393</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.84</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.87348</td></tr><tr><td>eval/precision_negative</td><td>0.82701</td></tr><tr><td>eval/precision_neutral</td><td>0.78564</td></tr><tr><td>eval/precision_positive</td><td>0.87037</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.92978</td></tr><tr><td>eval/recall</td><td>0.84595</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.86066</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.90886</td></tr><tr><td>eval/recall_negative</td><td>0.76284</td></tr><tr><td>eval/recall_neutral</td><td>0.88639</td></tr><tr><td>eval/recall_positive</td><td>0.81098</td></tr><tr><td>eval/runtime</td><td>5.5335</td></tr><tr><td>eval/samples_per_second</td><td>787.39</td></tr><tr><td>eval/steps_per_second</td><td>3.253</td></tr><tr><td>total_flos</td><td>7726986378519312.0</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/global_step</td><td>2156</td></tr><tr><td>train/grad_norm</td><td>0.8369</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3954</td></tr><tr><td>train_loss</td><td>0.63012</td></tr><tr><td>train_runtime</td><td>858.2411</td></tr><tr><td>train_samples_per_second</td><td>320.423</td></tr><tr><td>train_steps_per_second</td><td>2.512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/uwyc0jiw' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/uwyc0jiw</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_131206-uwyc0jiw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 13:27:32,271] Trial 2 finished with value: 0.9297840127669785 and parameters: {'learning_rate': 0.0002410038500292598, 'batch_size': 32, 'label_smoothing': 0.09079127901743848, 'num_epochs': 11, 'warmup_ratio': 0.14435680747215307, 'weight_decay': 0.0849441280799004, 'attention_dropout': 0.3758622805072069, 'hidden_dropout': 0.3533269312284606}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      4.96e-05\n",
      "Epochs:             14\n",
      "Warmup Ratio:       0.144\n",
      "Weight Decay:       0.126\n",
      "Attention Dropout:  0.314\n",
      "Hidden Dropout:     0.381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_132732-syidxbpb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/syidxbpb' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/syidxbpb' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/syidxbpb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2744' max='2744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2744/2744 18:15, Epoch 14/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.437600</td>\n",
       "      <td>1.053591</td>\n",
       "      <td>0.631398</td>\n",
       "      <td>0.626026</td>\n",
       "      <td>0.632779</td>\n",
       "      <td>0.664631</td>\n",
       "      <td>0.673806</td>\n",
       "      <td>0.563361</td>\n",
       "      <td>0.838115</td>\n",
       "      <td>0.838115</td>\n",
       "      <td>0.528369</td>\n",
       "      <td>0.575290</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.703364</td>\n",
       "      <td>0.770777</td>\n",
       "      <td>0.646794</td>\n",
       "      <td>0.646794</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.604714</td>\n",
       "      <td>0.523137</td>\n",
       "      <td>0.523137</td>\n",
       "      <td>0.727577</td>\n",
       "      <td>0.649751</td>\n",
       "      <td>0.826582</td>\n",
       "      <td>0.826582</td>\n",
       "      <td>0.476475</td>\n",
       "      <td>0.909112</td>\n",
       "      <td>0.798025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>1.029444</td>\n",
       "      <td>0.677989</td>\n",
       "      <td>0.671405</td>\n",
       "      <td>0.707834</td>\n",
       "      <td>0.716637</td>\n",
       "      <td>0.771964</td>\n",
       "      <td>0.744762</td>\n",
       "      <td>0.801230</td>\n",
       "      <td>0.801230</td>\n",
       "      <td>0.677204</td>\n",
       "      <td>0.763014</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.608743</td>\n",
       "      <td>0.821788</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.516937</td>\n",
       "      <td>0.632955</td>\n",
       "      <td>0.436863</td>\n",
       "      <td>0.436863</td>\n",
       "      <td>0.682640</td>\n",
       "      <td>0.530942</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.403489</td>\n",
       "      <td>0.932752</td>\n",
       "      <td>0.835351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.776300</td>\n",
       "      <td>0.799111</td>\n",
       "      <td>0.799174</td>\n",
       "      <td>0.799632</td>\n",
       "      <td>0.799421</td>\n",
       "      <td>0.809862</td>\n",
       "      <td>0.808194</td>\n",
       "      <td>0.740614</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.734914</td>\n",
       "      <td>0.724761</td>\n",
       "      <td>0.745355</td>\n",
       "      <td>0.745355</td>\n",
       "      <td>0.842703</td>\n",
       "      <td>0.850917</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.786624</td>\n",
       "      <td>0.798707</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.882108</td>\n",
       "      <td>0.805063</td>\n",
       "      <td>0.805063</td>\n",
       "      <td>0.246959</td>\n",
       "      <td>0.957769</td>\n",
       "      <td>0.895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.763968</td>\n",
       "      <td>0.817994</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.827168</td>\n",
       "      <td>0.817579</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.855688</td>\n",
       "      <td>0.861048</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.790143</td>\n",
       "      <td>0.800967</td>\n",
       "      <td>0.779608</td>\n",
       "      <td>0.779608</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.817869</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.221712</td>\n",
       "      <td>0.963507</td>\n",
       "      <td>0.904919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.797461</td>\n",
       "      <td>0.822814</td>\n",
       "      <td>0.821742</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>0.826413</td>\n",
       "      <td>0.841785</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.764950</td>\n",
       "      <td>0.834625</td>\n",
       "      <td>0.706011</td>\n",
       "      <td>0.706011</td>\n",
       "      <td>0.846370</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>0.809415</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.836078</td>\n",
       "      <td>0.836078</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.213679</td>\n",
       "      <td>0.966491</td>\n",
       "      <td>0.910192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.833591</td>\n",
       "      <td>0.809502</td>\n",
       "      <td>0.808412</td>\n",
       "      <td>0.811861</td>\n",
       "      <td>0.827771</td>\n",
       "      <td>0.836224</td>\n",
       "      <td>0.789091</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.780712</td>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.873979</td>\n",
       "      <td>0.907879</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.763606</td>\n",
       "      <td>0.811837</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.821842</td>\n",
       "      <td>0.728250</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.226991</td>\n",
       "      <td>0.966720</td>\n",
       "      <td>0.910730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.771057</td>\n",
       "      <td>0.842782</td>\n",
       "      <td>0.843136</td>\n",
       "      <td>0.852011</td>\n",
       "      <td>0.839397</td>\n",
       "      <td>0.843011</td>\n",
       "      <td>0.886878</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.809829</td>\n",
       "      <td>0.792059</td>\n",
       "      <td>0.828415</td>\n",
       "      <td>0.828415</td>\n",
       "      <td>0.864928</td>\n",
       "      <td>0.892344</td>\n",
       "      <td>0.839145</td>\n",
       "      <td>0.839145</td>\n",
       "      <td>0.832246</td>\n",
       "      <td>0.815038</td>\n",
       "      <td>0.850196</td>\n",
       "      <td>0.850196</td>\n",
       "      <td>0.874842</td>\n",
       "      <td>0.873737</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.187973</td>\n",
       "      <td>0.971540</td>\n",
       "      <td>0.921069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.473800</td>\n",
       "      <td>0.790825</td>\n",
       "      <td>0.827634</td>\n",
       "      <td>0.826527</td>\n",
       "      <td>0.827476</td>\n",
       "      <td>0.839082</td>\n",
       "      <td>0.848790</td>\n",
       "      <td>0.835317</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.802903</td>\n",
       "      <td>0.820776</td>\n",
       "      <td>0.785792</td>\n",
       "      <td>0.785792</td>\n",
       "      <td>0.851993</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>0.877390</td>\n",
       "      <td>0.877390</td>\n",
       "      <td>0.796862</td>\n",
       "      <td>0.841325</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.859356</td>\n",
       "      <td>0.811937</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.200367</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.921085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.829321</td>\n",
       "      <td>0.828093</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.826660</td>\n",
       "      <td>0.839077</td>\n",
       "      <td>0.846229</td>\n",
       "      <td>0.810507</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.797267</td>\n",
       "      <td>0.832342</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.850613</td>\n",
       "      <td>0.843094</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.805477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.819540</td>\n",
       "      <td>0.902532</td>\n",
       "      <td>0.902532</td>\n",
       "      <td>0.199449</td>\n",
       "      <td>0.974983</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>0.838869</td>\n",
       "      <td>0.830388</td>\n",
       "      <td>0.829763</td>\n",
       "      <td>0.831453</td>\n",
       "      <td>0.838791</td>\n",
       "      <td>0.852792</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.804262</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.837765</td>\n",
       "      <td>0.809224</td>\n",
       "      <td>0.868391</td>\n",
       "      <td>0.868391</td>\n",
       "      <td>0.811183</td>\n",
       "      <td>0.839061</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.866055</td>\n",
       "      <td>0.837870</td>\n",
       "      <td>0.896203</td>\n",
       "      <td>0.896203</td>\n",
       "      <td>0.193941</td>\n",
       "      <td>0.978196</td>\n",
       "      <td>0.924295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.828502</td>\n",
       "      <td>0.837732</td>\n",
       "      <td>0.837388</td>\n",
       "      <td>0.838937</td>\n",
       "      <td>0.843404</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.866803</td>\n",
       "      <td>0.866803</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>0.831409</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.850225</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>0.821681</td>\n",
       "      <td>0.822974</td>\n",
       "      <td>0.820392</td>\n",
       "      <td>0.820392</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.855758</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.188432</td>\n",
       "      <td>0.976130</td>\n",
       "      <td>0.925138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.858108</td>\n",
       "      <td>0.831994</td>\n",
       "      <td>0.831021</td>\n",
       "      <td>0.831027</td>\n",
       "      <td>0.843184</td>\n",
       "      <td>0.855446</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.801143</td>\n",
       "      <td>0.839521</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>0.876265</td>\n",
       "      <td>0.876265</td>\n",
       "      <td>0.812551</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.781961</td>\n",
       "      <td>0.781961</td>\n",
       "      <td>0.864212</td>\n",
       "      <td>0.825836</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>0.978426</td>\n",
       "      <td>0.926740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.871511</td>\n",
       "      <td>0.828552</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.826950</td>\n",
       "      <td>0.838989</td>\n",
       "      <td>0.846530</td>\n",
       "      <td>0.809346</td>\n",
       "      <td>0.887295</td>\n",
       "      <td>0.887295</td>\n",
       "      <td>0.789076</td>\n",
       "      <td>0.842432</td>\n",
       "      <td>0.742077</td>\n",
       "      <td>0.742077</td>\n",
       "      <td>0.837134</td>\n",
       "      <td>0.809024</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.837883</td>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.978885</td>\n",
       "      <td>0.926105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.872001</td>\n",
       "      <td>0.829240</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.827375</td>\n",
       "      <td>0.839338</td>\n",
       "      <td>0.844575</td>\n",
       "      <td>0.807477</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.793064</td>\n",
       "      <td>0.841718</td>\n",
       "      <td>0.749727</td>\n",
       "      <td>0.749727</td>\n",
       "      <td>0.839344</td>\n",
       "      <td>0.816153</td>\n",
       "      <td>0.863892</td>\n",
       "      <td>0.863892</td>\n",
       "      <td>0.815440</td>\n",
       "      <td>0.836634</td>\n",
       "      <td>0.795294</td>\n",
       "      <td>0.795294</td>\n",
       "      <td>0.867397</td>\n",
       "      <td>0.834895</td>\n",
       "      <td>0.902532</td>\n",
       "      <td>0.902532</td>\n",
       "      <td>0.193482</td>\n",
       "      <td>0.979114</td>\n",
       "      <td>0.926596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.0536, Val F1: 0.0000, QWK: 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 1.0294, Val F1: 0.0000, QWK: 0.8354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.7991, Val F1: 0.0000, QWK: 0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.7640, Val F1: 0.0000, QWK: 0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.7975, Val F1: 0.0000, QWK: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.8336, Val F1: 0.0000, QWK: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.7711, Val F1: 0.0000, QWK: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.7908, Val F1: 0.0000, QWK: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.8293, Val F1: 0.0000, QWK: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.8389, Val F1: 0.0000, QWK: 0.9243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0000, Val Loss: 0.8285, Val F1: 0.0000, QWK: 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0000, Val Loss: 0.8581, Val F1: 0.0000, QWK: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0000, Val Loss: 0.8715, Val F1: 0.0000, QWK: 0.9261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0000, Val Loss: 0.8720, Val F1: 0.0000, QWK: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.5886, Val Loss: 0.8720, Val F1: 0.0000, QWK: 0.9266\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_3/final_epoch_14.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_3\n",
      "üìä Trial 3 score: 0.9266 (Best: 0.9298)\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÖ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÇ‚ñÅ‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÉ‚ñÅ‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/f1_positive</td><td>‚ñÇ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÉ‚ñÅ‚ñà‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÖ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_positive</td><td>‚ñÇ‚ñÅ‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñà</td></tr><tr><td>eval/samples_per_second</td><td>‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ</td></tr><tr><td>train/learning_rate</td><td>‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>Learning_Rate</td><td>5e-05</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.58857</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.82924</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.97911</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.872</td></tr><tr><td>Validation MAE</td><td>0.19348</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.9266</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.82924</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.88525</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.90253</td></tr><tr><td>eval/accuracy_negative</td><td>0.74973</td></tr><tr><td>eval/accuracy_neutral</td><td>0.86389</td></tr><tr><td>eval/accuracy_positive</td><td>0.79529</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.97911</td></tr><tr><td>eval/f1</td><td>0.8283</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.84457</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.8674</td></tr><tr><td>eval/f1_negative</td><td>0.79306</td></tr><tr><td>eval/f1_neutral</td><td>0.83934</td></tr><tr><td>eval/f1_positive</td><td>0.81544</td></tr><tr><td>eval/loss</td><td>0.872</td></tr><tr><td>eval/mae</td><td>0.19348</td></tr><tr><td>eval/precision</td><td>0.82738</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.80748</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.83489</td></tr><tr><td>eval/precision_negative</td><td>0.84172</td></tr><tr><td>eval/precision_neutral</td><td>0.81615</td></tr><tr><td>eval/precision_positive</td><td>0.83663</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.9266</td></tr><tr><td>eval/recall</td><td>0.83934</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.88525</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.90253</td></tr><tr><td>eval/recall_negative</td><td>0.74973</td></tr><tr><td>eval/recall_neutral</td><td>0.86389</td></tr><tr><td>eval/recall_positive</td><td>0.79529</td></tr><tr><td>eval/runtime</td><td>5.8973</td></tr><tr><td>eval/samples_per_second</td><td>738.808</td></tr><tr><td>eval/steps_per_second</td><td>3.052</td></tr><tr><td>total_flos</td><td>9834003573603216.0</td></tr><tr><td>train/epoch</td><td>14</td></tr><tr><td>train/global_step</td><td>2744</td></tr><tr><td>train/grad_norm</td><td>3.58375</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.397</td></tr><tr><td>train_loss</td><td>0.58857</td></tr><tr><td>train_runtime</td><td>1096.6206</td></tr><tr><td>train_samples_per_second</td><td>319.162</td></tr><tr><td>train_steps_per_second</td><td>2.502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/syidxbpb' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/syidxbpb</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_132732-syidxbpb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 13:46:31,411] Trial 3 finished with value: 0.9265959962592151 and parameters: {'learning_rate': 4.961108870268324e-05, 'batch_size': 32, 'label_smoothing': 0.0927589445524373, 'num_epochs': 14, 'warmup_ratio': 0.1435876918544712, 'weight_decay': 0.1262573646443622, 'attention_dropout': 0.3141810449276149, 'hidden_dropout': 0.3807897429227929}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      4.89e-05\n",
      "Epochs:             15\n",
      "Warmup Ratio:       0.112\n",
      "Weight Decay:       0.105\n",
      "Attention Dropout:  0.338\n",
      "Hidden Dropout:     0.372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_134631-likry8g0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/likry8g0' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/likry8g0' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/likry8g0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2744' max='2940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2744/2940 18:12 < 01:18, 2.51 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.476800</td>\n",
       "      <td>1.018920</td>\n",
       "      <td>0.619463</td>\n",
       "      <td>0.610650</td>\n",
       "      <td>0.627085</td>\n",
       "      <td>0.660713</td>\n",
       "      <td>0.673718</td>\n",
       "      <td>0.558704</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.523838</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.474317</td>\n",
       "      <td>0.474317</td>\n",
       "      <td>0.710775</td>\n",
       "      <td>0.808023</td>\n",
       "      <td>0.634421</td>\n",
       "      <td>0.634421</td>\n",
       "      <td>0.519699</td>\n",
       "      <td>0.596545</td>\n",
       "      <td>0.460392</td>\n",
       "      <td>0.460392</td>\n",
       "      <td>0.706357</td>\n",
       "      <td>0.587248</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.492541</td>\n",
       "      <td>0.907964</td>\n",
       "      <td>0.796601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>0.912207</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.696382</td>\n",
       "      <td>0.722016</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.730072</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.758300</td>\n",
       "      <td>0.624044</td>\n",
       "      <td>0.624044</td>\n",
       "      <td>0.821216</td>\n",
       "      <td>0.873257</td>\n",
       "      <td>0.775028</td>\n",
       "      <td>0.775028</td>\n",
       "      <td>0.574516</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.500392</td>\n",
       "      <td>0.500392</td>\n",
       "      <td>0.717608</td>\n",
       "      <td>0.574032</td>\n",
       "      <td>0.956962</td>\n",
       "      <td>0.956962</td>\n",
       "      <td>0.370209</td>\n",
       "      <td>0.939867</td>\n",
       "      <td>0.850139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>0.713282</td>\n",
       "      <td>0.802387</td>\n",
       "      <td>0.803202</td>\n",
       "      <td>0.805397</td>\n",
       "      <td>0.809808</td>\n",
       "      <td>0.810556</td>\n",
       "      <td>0.750436</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.733441</td>\n",
       "      <td>0.722930</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.797208</td>\n",
       "      <td>0.788344</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.850923</td>\n",
       "      <td>0.888430</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.242828</td>\n",
       "      <td>0.958458</td>\n",
       "      <td>0.897151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.807914</td>\n",
       "      <td>0.769566</td>\n",
       "      <td>0.767371</td>\n",
       "      <td>0.785304</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.845987</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.761305</td>\n",
       "      <td>0.799279</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.860240</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.681309</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.620392</td>\n",
       "      <td>0.620392</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.653079</td>\n",
       "      <td>0.953165</td>\n",
       "      <td>0.953165</td>\n",
       "      <td>0.277485</td>\n",
       "      <td>0.955933</td>\n",
       "      <td>0.889681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.706429</td>\n",
       "      <td>0.814781</td>\n",
       "      <td>0.813634</td>\n",
       "      <td>0.815086</td>\n",
       "      <td>0.823530</td>\n",
       "      <td>0.827447</td>\n",
       "      <td>0.815109</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.773563</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.735519</td>\n",
       "      <td>0.735519</td>\n",
       "      <td>0.852058</td>\n",
       "      <td>0.842684</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.790024</td>\n",
       "      <td>0.810900</td>\n",
       "      <td>0.770196</td>\n",
       "      <td>0.770196</td>\n",
       "      <td>0.846380</td>\n",
       "      <td>0.790979</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.219417</td>\n",
       "      <td>0.968556</td>\n",
       "      <td>0.911455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.735655</td>\n",
       "      <td>0.814551</td>\n",
       "      <td>0.813257</td>\n",
       "      <td>0.809871</td>\n",
       "      <td>0.833208</td>\n",
       "      <td>0.828911</td>\n",
       "      <td>0.748760</td>\n",
       "      <td>0.928279</td>\n",
       "      <td>0.928279</td>\n",
       "      <td>0.765884</td>\n",
       "      <td>0.804087</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.856484</td>\n",
       "      <td>0.878251</td>\n",
       "      <td>0.835771</td>\n",
       "      <td>0.835771</td>\n",
       "      <td>0.791236</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>0.750588</td>\n",
       "      <td>0.750588</td>\n",
       "      <td>0.845349</td>\n",
       "      <td>0.781720</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>0.968556</td>\n",
       "      <td>0.912755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.726910</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.829920</td>\n",
       "      <td>0.830199</td>\n",
       "      <td>0.837785</td>\n",
       "      <td>0.839650</td>\n",
       "      <td>0.798521</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.777598</td>\n",
       "      <td>0.766454</td>\n",
       "      <td>0.789071</td>\n",
       "      <td>0.789071</td>\n",
       "      <td>0.855640</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.817247</td>\n",
       "      <td>0.824421</td>\n",
       "      <td>0.810196</td>\n",
       "      <td>0.810196</td>\n",
       "      <td>0.876023</td>\n",
       "      <td>0.871089</td>\n",
       "      <td>0.881013</td>\n",
       "      <td>0.881013</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.964884</td>\n",
       "      <td>0.912705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>0.742309</td>\n",
       "      <td>0.822584</td>\n",
       "      <td>0.821532</td>\n",
       "      <td>0.818829</td>\n",
       "      <td>0.836319</td>\n",
       "      <td>0.831418</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>0.803048</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.860585</td>\n",
       "      <td>0.878220</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.842377</td>\n",
       "      <td>0.767059</td>\n",
       "      <td>0.767059</td>\n",
       "      <td>0.855485</td>\n",
       "      <td>0.789925</td>\n",
       "      <td>0.932911</td>\n",
       "      <td>0.932911</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.918930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.771837</td>\n",
       "      <td>0.824650</td>\n",
       "      <td>0.823813</td>\n",
       "      <td>0.820685</td>\n",
       "      <td>0.837331</td>\n",
       "      <td>0.838770</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.922131</td>\n",
       "      <td>0.922131</td>\n",
       "      <td>0.778608</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.841111</td>\n",
       "      <td>0.830955</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>0.814726</td>\n",
       "      <td>0.831699</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>0.862133</td>\n",
       "      <td>0.849938</td>\n",
       "      <td>0.874684</td>\n",
       "      <td>0.874684</td>\n",
       "      <td>0.203351</td>\n",
       "      <td>0.974983</td>\n",
       "      <td>0.920485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.741448</td>\n",
       "      <td>0.838880</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.841604</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.867804</td>\n",
       "      <td>0.834016</td>\n",
       "      <td>0.834016</td>\n",
       "      <td>0.804838</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.843127</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.827809</td>\n",
       "      <td>0.854045</td>\n",
       "      <td>0.803137</td>\n",
       "      <td>0.803137</td>\n",
       "      <td>0.882536</td>\n",
       "      <td>0.866911</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>0.977507</td>\n",
       "      <td>0.926824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.796516</td>\n",
       "      <td>0.826486</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.822422</td>\n",
       "      <td>0.837646</td>\n",
       "      <td>0.835206</td>\n",
       "      <td>0.768966</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>0.765680</td>\n",
       "      <td>0.834839</td>\n",
       "      <td>0.707104</td>\n",
       "      <td>0.707104</td>\n",
       "      <td>0.841142</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.878515</td>\n",
       "      <td>0.878515</td>\n",
       "      <td>0.826070</td>\n",
       "      <td>0.842577</td>\n",
       "      <td>0.810196</td>\n",
       "      <td>0.810196</td>\n",
       "      <td>0.868586</td>\n",
       "      <td>0.858911</td>\n",
       "      <td>0.878481</td>\n",
       "      <td>0.878481</td>\n",
       "      <td>0.197154</td>\n",
       "      <td>0.978196</td>\n",
       "      <td>0.925071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.783218</td>\n",
       "      <td>0.837503</td>\n",
       "      <td>0.836965</td>\n",
       "      <td>0.838120</td>\n",
       "      <td>0.844682</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.848790</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.803132</td>\n",
       "      <td>0.822451</td>\n",
       "      <td>0.784699</td>\n",
       "      <td>0.784699</td>\n",
       "      <td>0.842678</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.824526</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.854067</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.186596</td>\n",
       "      <td>0.977966</td>\n",
       "      <td>0.926856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.826945</td>\n",
       "      <td>0.825622</td>\n",
       "      <td>0.824307</td>\n",
       "      <td>0.840269</td>\n",
       "      <td>0.850288</td>\n",
       "      <td>0.799639</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.781086</td>\n",
       "      <td>0.838346</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.800620</td>\n",
       "      <td>0.871766</td>\n",
       "      <td>0.871766</td>\n",
       "      <td>0.814664</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.869460</td>\n",
       "      <td>0.835473</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.196006</td>\n",
       "      <td>0.978655</td>\n",
       "      <td>0.926140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.836733</td>\n",
       "      <td>0.827175</td>\n",
       "      <td>0.825929</td>\n",
       "      <td>0.825491</td>\n",
       "      <td>0.840342</td>\n",
       "      <td>0.854634</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.789139</td>\n",
       "      <td>0.837010</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.746448</td>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.805411</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.809992</td>\n",
       "      <td>0.847472</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.195777</td>\n",
       "      <td>0.978655</td>\n",
       "      <td>0.926183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.0189, Val F1: 0.0000, QWK: 0.7966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 0.9122, Val F1: 0.0000, QWK: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.7133, Val F1: 0.0000, QWK: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.8079, Val F1: 0.0000, QWK: 0.8897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.7064, Val F1: 0.0000, QWK: 0.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.7357, Val F1: 0.0000, QWK: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.7269, Val F1: 0.0000, QWK: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.7423, Val F1: 0.0000, QWK: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.7718, Val F1: 0.0000, QWK: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.7414, Val F1: 0.0000, QWK: 0.9268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0000, Val Loss: 0.7965, Val F1: 0.0000, QWK: 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0000, Val Loss: 0.7832, Val F1: 0.0000, QWK: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0000, Val Loss: 0.8346, Val F1: 0.0000, QWK: 0.9261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0000, Val Loss: 0.8367, Val F1: 0.0000, QWK: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.4909, Val Loss: 0.8367, Val F1: 0.0000, QWK: 0.9262\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_4/final_epoch_14.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_4\n",
      "üìä Trial 4 score: 0.9262 (Best: 0.9298)\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÑ‚ñà‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_positive</td><td>‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÇ‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÑ‚ñà‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_positive</td><td>‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñÑ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñà‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÑ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñà‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÑ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>Learning_Rate</td><td>5e-05</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.49091</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.82717</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.97866</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.83673</td></tr><tr><td>Validation MAE</td><td>0.19578</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.92618</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.82717</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.89754</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.91139</td></tr><tr><td>eval/accuracy_negative</td><td>0.74645</td></tr><tr><td>eval/accuracy_neutral</td><td>0.87064</td></tr><tr><td>eval/accuracy_positive</td><td>0.77569</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.97866</td></tr><tr><td>eval/f1</td><td>0.82593</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.85463</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.86435</td></tr><tr><td>eval/f1_negative</td><td>0.78914</td></tr><tr><td>eval/f1_neutral</td><td>0.83676</td></tr><tr><td>eval/f1_positive</td><td>0.80999</td></tr><tr><td>eval/loss</td><td>0.83673</td></tr><tr><td>eval/mae</td><td>0.19578</td></tr><tr><td>eval/precision</td><td>0.82549</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.81564</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.82192</td></tr><tr><td>eval/precision_negative</td><td>0.83701</td></tr><tr><td>eval/precision_neutral</td><td>0.80541</td></tr><tr><td>eval/precision_positive</td><td>0.84747</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.92618</td></tr><tr><td>eval/recall</td><td>0.84034</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.89754</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.91139</td></tr><tr><td>eval/recall_negative</td><td>0.74645</td></tr><tr><td>eval/recall_neutral</td><td>0.87064</td></tr><tr><td>eval/recall_positive</td><td>0.77569</td></tr><tr><td>eval/runtime</td><td>5.5842</td></tr><tr><td>eval/samples_per_second</td><td>780.24</td></tr><tr><td>eval/steps_per_second</td><td>3.223</td></tr><tr><td>total_flos</td><td>9834003573603216.0</td></tr><tr><td>train/epoch</td><td>14</td></tr><tr><td>train/global_step</td><td>2744</td></tr><tr><td>train/grad_norm</td><td>2.90025</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2792</td></tr><tr><td>train_loss</td><td>0.49091</td></tr><tr><td>train_runtime</td><td>1093.3629</td></tr><tr><td>train_samples_per_second</td><td>342.979</td></tr><tr><td>train_steps_per_second</td><td>2.689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/likry8g0' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/likry8g0</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_134631-likry8g0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 14:05:13,435] Trial 4 finished with value: 0.9261825007773399 and parameters: {'learning_rate': 4.8907197924823515e-05, 'batch_size': 32, 'label_smoothing': 0.0582946831507724, 'num_epochs': 15, 'warmup_ratio': 0.11185140937752469, 'weight_decay': 0.10507500742800172, 'attention_dropout': 0.33779944126404315, 'hidden_dropout': 0.37190455241829984}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      4.31e-05\n",
      "Epochs:             11\n",
      "Warmup Ratio:       0.145\n",
      "Weight Decay:       0.053\n",
      "Attention Dropout:  0.351\n",
      "Hidden Dropout:     0.302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_140513-5euvzzbi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/5euvzzbi' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/5euvzzbi' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/5euvzzbi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1078' max='1078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1078/1078 13:34, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.164158</td>\n",
       "      <td>0.603626</td>\n",
       "      <td>0.594630</td>\n",
       "      <td>0.611178</td>\n",
       "      <td>0.634909</td>\n",
       "      <td>0.698094</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.555968</td>\n",
       "      <td>0.540206</td>\n",
       "      <td>0.572678</td>\n",
       "      <td>0.572678</td>\n",
       "      <td>0.670020</td>\n",
       "      <td>0.606005</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.471028</td>\n",
       "      <td>0.582659</td>\n",
       "      <td>0.395294</td>\n",
       "      <td>0.395294</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.643326</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>0.903144</td>\n",
       "      <td>0.764208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.423000</td>\n",
       "      <td>0.968847</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.759181</td>\n",
       "      <td>0.739717</td>\n",
       "      <td>0.741339</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.698280</td>\n",
       "      <td>0.667331</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.802152</td>\n",
       "      <td>0.855867</td>\n",
       "      <td>0.754781</td>\n",
       "      <td>0.754781</td>\n",
       "      <td>0.685510</td>\n",
       "      <td>0.696039</td>\n",
       "      <td>0.675294</td>\n",
       "      <td>0.675294</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.727463</td>\n",
       "      <td>0.878481</td>\n",
       "      <td>0.878481</td>\n",
       "      <td>0.333027</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.849560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.038200</td>\n",
       "      <td>0.916609</td>\n",
       "      <td>0.781960</td>\n",
       "      <td>0.781170</td>\n",
       "      <td>0.776590</td>\n",
       "      <td>0.800121</td>\n",
       "      <td>0.779964</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.703064</td>\n",
       "      <td>0.717045</td>\n",
       "      <td>0.689617</td>\n",
       "      <td>0.689617</td>\n",
       "      <td>0.838184</td>\n",
       "      <td>0.868516</td>\n",
       "      <td>0.809899</td>\n",
       "      <td>0.809899</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.841852</td>\n",
       "      <td>0.801833</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.952720</td>\n",
       "      <td>0.888250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.863984</td>\n",
       "      <td>0.818453</td>\n",
       "      <td>0.819094</td>\n",
       "      <td>0.826925</td>\n",
       "      <td>0.820684</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.827515</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.772801</td>\n",
       "      <td>0.763326</td>\n",
       "      <td>0.782514</td>\n",
       "      <td>0.782514</td>\n",
       "      <td>0.856629</td>\n",
       "      <td>0.917738</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.797246</td>\n",
       "      <td>0.778193</td>\n",
       "      <td>0.817255</td>\n",
       "      <td>0.817255</td>\n",
       "      <td>0.861059</td>\n",
       "      <td>0.847853</td>\n",
       "      <td>0.874684</td>\n",
       "      <td>0.874684</td>\n",
       "      <td>0.227909</td>\n",
       "      <td>0.956851</td>\n",
       "      <td>0.900344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.785500</td>\n",
       "      <td>0.887449</td>\n",
       "      <td>0.811109</td>\n",
       "      <td>0.810791</td>\n",
       "      <td>0.814096</td>\n",
       "      <td>0.820875</td>\n",
       "      <td>0.826004</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.760046</td>\n",
       "      <td>0.800484</td>\n",
       "      <td>0.723497</td>\n",
       "      <td>0.723497</td>\n",
       "      <td>0.854935</td>\n",
       "      <td>0.906683</td>\n",
       "      <td>0.808774</td>\n",
       "      <td>0.808774</td>\n",
       "      <td>0.786292</td>\n",
       "      <td>0.772315</td>\n",
       "      <td>0.800784</td>\n",
       "      <td>0.800784</td>\n",
       "      <td>0.850030</td>\n",
       "      <td>0.816803</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.233417</td>\n",
       "      <td>0.958917</td>\n",
       "      <td>0.901759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.895308</td>\n",
       "      <td>0.816387</td>\n",
       "      <td>0.816191</td>\n",
       "      <td>0.813086</td>\n",
       "      <td>0.828971</td>\n",
       "      <td>0.816590</td>\n",
       "      <td>0.742044</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.746252</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.855781</td>\n",
       "      <td>0.910013</td>\n",
       "      <td>0.807649</td>\n",
       "      <td>0.807649</td>\n",
       "      <td>0.808630</td>\n",
       "      <td>0.824104</td>\n",
       "      <td>0.793725</td>\n",
       "      <td>0.793725</td>\n",
       "      <td>0.864602</td>\n",
       "      <td>0.830805</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.224007</td>\n",
       "      <td>0.962589</td>\n",
       "      <td>0.908690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.884183</td>\n",
       "      <td>0.821896</td>\n",
       "      <td>0.821501</td>\n",
       "      <td>0.819183</td>\n",
       "      <td>0.831924</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.775583</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.776271</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.853842</td>\n",
       "      <td>0.877672</td>\n",
       "      <td>0.831271</td>\n",
       "      <td>0.831271</td>\n",
       "      <td>0.809087</td>\n",
       "      <td>0.822528</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0.896203</td>\n",
       "      <td>0.896203</td>\n",
       "      <td>0.215515</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.911581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.815469</td>\n",
       "      <td>0.813985</td>\n",
       "      <td>0.811213</td>\n",
       "      <td>0.831251</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.772487</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.768091</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>0.736612</td>\n",
       "      <td>0.736612</td>\n",
       "      <td>0.846370</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>0.790928</td>\n",
       "      <td>0.833913</td>\n",
       "      <td>0.752157</td>\n",
       "      <td>0.752157</td>\n",
       "      <td>0.857814</td>\n",
       "      <td>0.800439</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.217581</td>\n",
       "      <td>0.969245</td>\n",
       "      <td>0.914801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.877915</td>\n",
       "      <td>0.827634</td>\n",
       "      <td>0.827244</td>\n",
       "      <td>0.832696</td>\n",
       "      <td>0.830999</td>\n",
       "      <td>0.846316</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.786315</td>\n",
       "      <td>0.807604</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.828479</td>\n",
       "      <td>0.795855</td>\n",
       "      <td>0.863892</td>\n",
       "      <td>0.863892</td>\n",
       "      <td>0.816845</td>\n",
       "      <td>0.827697</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.862195</td>\n",
       "      <td>0.894937</td>\n",
       "      <td>0.894937</td>\n",
       "      <td>0.200597</td>\n",
       "      <td>0.973606</td>\n",
       "      <td>0.919048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.916439</td>\n",
       "      <td>0.817305</td>\n",
       "      <td>0.815910</td>\n",
       "      <td>0.814112</td>\n",
       "      <td>0.832534</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.780531</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.776498</td>\n",
       "      <td>0.820950</td>\n",
       "      <td>0.736612</td>\n",
       "      <td>0.736612</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.792330</td>\n",
       "      <td>0.825680</td>\n",
       "      <td>0.761569</td>\n",
       "      <td>0.761569</td>\n",
       "      <td>0.855279</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.214138</td>\n",
       "      <td>0.970622</td>\n",
       "      <td>0.916491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>0.917956</td>\n",
       "      <td>0.816617</td>\n",
       "      <td>0.815148</td>\n",
       "      <td>0.813340</td>\n",
       "      <td>0.831443</td>\n",
       "      <td>0.835878</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.773226</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.841518</td>\n",
       "      <td>0.834994</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.793625</td>\n",
       "      <td>0.828498</td>\n",
       "      <td>0.761569</td>\n",
       "      <td>0.761569</td>\n",
       "      <td>0.855962</td>\n",
       "      <td>0.801991</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>0.971540</td>\n",
       "      <td>0.917069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.1642, Val F1: 0.0000, QWK: 0.7642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 0.9688, Val F1: 0.0000, QWK: 0.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.9166, Val F1: 0.0000, QWK: 0.8882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.8640, Val F1: 0.0000, QWK: 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.8874, Val F1: 0.0000, QWK: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.8953, Val F1: 0.0000, QWK: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.8842, Val F1: 0.0000, QWK: 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.9099, Val F1: 0.0000, QWK: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.8779, Val F1: 0.0000, QWK: 0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.9164, Val F1: 0.0000, QWK: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0000, Val Loss: 0.9180, Val F1: 0.0000, QWK: 0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.7908, Val Loss: 0.9180, Val F1: 0.0000, QWK: 0.9171\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_5/final_epoch_11.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_5\n",
      "üìä Trial 5 score: 0.9171 (Best: 0.9298)\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá</td></tr><tr><td>eval/f1_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/recall_positive</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñÑ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÖ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÖ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>11</td></tr><tr><td>Learning_Rate</td><td>4e-05</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.79084</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.81662</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.97154</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.91796</td></tr><tr><td>Validation MAE</td><td>0.21391</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.91707</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.81662</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.89754</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.91772</td></tr><tr><td>eval/accuracy_negative</td><td>0.73224</td></tr><tr><td>eval/accuracy_neutral</td><td>0.84814</td></tr><tr><td>eval/accuracy_positive</td><td>0.76157</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.97154</td></tr><tr><td>eval/f1</td><td>0.81515</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.83588</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.85596</td></tr><tr><td>eval/f1_negative</td><td>0.77323</td></tr><tr><td>eval/f1_neutral</td><td>0.84152</td></tr><tr><td>eval/f1_positive</td><td>0.79362</td></tr><tr><td>eval/loss</td><td>0.91796</td></tr><tr><td>eval/mae</td><td>0.21391</td></tr><tr><td>eval/precision</td><td>0.81334</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.78214</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.80199</td></tr><tr><td>eval/precision_negative</td><td>0.81907</td></tr><tr><td>eval/precision_neutral</td><td>0.83499</td></tr><tr><td>eval/precision_positive</td><td>0.8285</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.91707</td></tr><tr><td>eval/recall</td><td>0.83144</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.89754</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.91772</td></tr><tr><td>eval/recall_negative</td><td>0.73224</td></tr><tr><td>eval/recall_neutral</td><td>0.84814</td></tr><tr><td>eval/recall_positive</td><td>0.76157</td></tr><tr><td>eval/runtime</td><td>6.3208</td></tr><tr><td>eval/samples_per_second</td><td>689.314</td></tr><tr><td>eval/steps_per_second</td><td>1.424</td></tr><tr><td>total_flos</td><td>7948108398713472.0</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/global_step</td><td>1078</td></tr><tr><td>train/grad_norm</td><td>2.63671</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5996</td></tr><tr><td>train_loss</td><td>0.79084</td></tr><tr><td>train_runtime</td><td>816.5138</td></tr><tr><td>train_samples_per_second</td><td>336.798</td></tr><tr><td>train_steps_per_second</td><td>1.32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/5euvzzbi' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/5euvzzbi</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_140513-5euvzzbi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 14:19:08,303] Trial 5 finished with value: 0.9170690001665863 and parameters: {'learning_rate': 4.310399711368251e-05, 'batch_size': 64, 'label_smoothing': 0.1443310085655225, 'num_epochs': 11, 'warmup_ratio': 0.1447948125423108, 'weight_decay': 0.05311444734390475, 'attention_dropout': 0.35114853217580355, 'hidden_dropout': 0.3018459114267167}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 6 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      4.74e-04\n",
      "Epochs:             14\n",
      "Warmup Ratio:       0.095\n",
      "Weight Decay:       0.116\n",
      "Attention Dropout:  0.364\n",
      "Hidden Dropout:     0.365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_141908-jdidxgc4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/jdidxgc4' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/jdidxgc4' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/jdidxgc4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='588' max='2744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 588/2744 03:53 < 14:20, 2.51 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.213800</td>\n",
       "      <td>1.136578</td>\n",
       "      <td>0.591462</td>\n",
       "      <td>0.569042</td>\n",
       "      <td>0.627535</td>\n",
       "      <td>0.610007</td>\n",
       "      <td>0.576517</td>\n",
       "      <td>0.425097</td>\n",
       "      <td>0.895492</td>\n",
       "      <td>0.895492</td>\n",
       "      <td>0.354009</td>\n",
       "      <td>0.574939</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.759667</td>\n",
       "      <td>0.672444</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.619013</td>\n",
       "      <td>0.583739</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.518320</td>\n",
       "      <td>0.881459</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.527427</td>\n",
       "      <td>0.912325</td>\n",
       "      <td>0.753290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.096900</td>\n",
       "      <td>1.109839</td>\n",
       "      <td>0.596970</td>\n",
       "      <td>0.577825</td>\n",
       "      <td>0.680736</td>\n",
       "      <td>0.579299</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.608456</td>\n",
       "      <td>0.678279</td>\n",
       "      <td>0.678279</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.739742</td>\n",
       "      <td>0.772338</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>0.612443</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>0.507918</td>\n",
       "      <td>0.908653</td>\n",
       "      <td>0.746210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325700</td>\n",
       "      <td>1.649970</td>\n",
       "      <td>0.242598</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>0.130366</td>\n",
       "      <td>0.273474</td>\n",
       "      <td>0.412393</td>\n",
       "      <td>0.430804</td>\n",
       "      <td>0.395492</td>\n",
       "      <td>0.395492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360150</td>\n",
       "      <td>0.221028</td>\n",
       "      <td>0.971879</td>\n",
       "      <td>0.971879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.047510</td>\n",
       "      <td>0.731926</td>\n",
       "      <td>0.228490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.1366, Val F1: 0.0000, QWK: 0.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 1.1098, Val F1: 0.0000, QWK: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 1.6500, Val F1: 0.0000, QWK: 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.2353, Val Loss: 1.6500, Val F1: 0.0000, QWK: 0.2285\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_6/final_epoch_3.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_6\n",
      "üìä Trial 6 score: 0.2285 (Best: 0.9298)\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÖ‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñÅ‚ñÅ‚ñà‚ñà</td></tr><tr><td>Validation MAE</td><td>‚ñÅ‚ñÅ‚ñà‚ñà</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñà‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñà‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÖ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÖ‚ñÅ‚ñà‚ñà</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñá‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÜ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñà‚ñÜ‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1_negative</td><td>‚ñÜ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1_neutral</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/f1_positive</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ‚ñÅ‚ñà‚ñà</td></tr><tr><td>eval/mae</td><td>‚ñÅ‚ñÅ‚ñà‚ñà</td></tr><tr><td>eval/precision</td><td>‚ñá‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÅ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_negative</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_neutral</td><td>‚ñá‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision_positive</td><td>‚ñà‚ñá‚ñÅ‚ñÅ</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall</td><td>‚ñà‚ñá‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñà‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñà‚ñÖ‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_negative</td><td>‚ñÖ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÖ‚ñÅ‚ñà‚ñà</td></tr><tr><td>eval/recall_positive</td><td>‚ñá‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÜ‚ñÜ‚ñà‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÉ‚ñÉ‚ñÅ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÉ‚ñÉ‚ñÅ‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÖ‚ñà‚ñà‚ñà</td></tr><tr><td>train/loss</td><td>‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Learning_Rate</td><td>0.00047</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>1.23531</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.2426</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.73193</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>1.64997</td></tr><tr><td>Validation MAE</td><td>1.04751</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.22849</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.2426</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.39549</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0</td></tr><tr><td>eval/accuracy_negative</td><td>0</td></tr><tr><td>eval/accuracy_neutral</td><td>0.97188</td></tr><tr><td>eval/accuracy_positive</td><td>0</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.73193</td></tr><tr><td>eval/f1</td><td>0.11967</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.41239</td></tr><tr><td>eval/f1_extremely_positive</td><td>0</td></tr><tr><td>eval/f1_negative</td><td>0</td></tr><tr><td>eval/f1_neutral</td><td>0.36015</td></tr><tr><td>eval/f1_positive</td><td>0</td></tr><tr><td>eval/loss</td><td>1.64997</td></tr><tr><td>eval/mae</td><td>1.04751</td></tr><tr><td>eval/precision</td><td>0.13037</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.4308</td></tr><tr><td>eval/precision_extremely_positive</td><td>0</td></tr><tr><td>eval/precision_negative</td><td>0</td></tr><tr><td>eval/precision_neutral</td><td>0.22103</td></tr><tr><td>eval/precision_positive</td><td>0</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.22849</td></tr><tr><td>eval/recall</td><td>0.27347</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.39549</td></tr><tr><td>eval/recall_extremely_positive</td><td>0</td></tr><tr><td>eval/recall_negative</td><td>0</td></tr><tr><td>eval/recall_neutral</td><td>0.97188</td></tr><tr><td>eval/recall_positive</td><td>0</td></tr><tr><td>eval/runtime</td><td>5.2942</td></tr><tr><td>eval/samples_per_second</td><td>822.98</td></tr><tr><td>eval/steps_per_second</td><td>3.4</td></tr><tr><td>total_flos</td><td>2106774633046320.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>588</td></tr><tr><td>train/grad_norm</td><td>3.99772</td></tr><tr><td>train/learning_rate</td><td>0.00046</td></tr><tr><td>train/loss</td><td>1.3257</td></tr><tr><td>train_loss</td><td>1.23531</td></tr><tr><td>train_runtime</td><td>234.9056</td></tr><tr><td>train_samples_per_second</td><td>1489.96</td></tr><tr><td>train_steps_per_second</td><td>11.681</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/jdidxgc4' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/jdidxgc4</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_141908-jdidxgc4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 14:23:35,085] Trial 6 finished with value: 0.22849048342050216 and parameters: {'learning_rate': 0.0004739120765367586, 'batch_size': 32, 'label_smoothing': 0.09736710601504883, 'num_epochs': 14, 'warmup_ratio': 0.09519916627929559, 'weight_decay': 0.11582745742381222, 'attention_dropout': 0.36400909462332215, 'hidden_dropout': 0.36514181786858063}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 7 - TESTING THESE PARAMETERS:\n",
      "Learning Rate:      5.91e-05\n",
      "Epochs:             11\n",
      "Warmup Ratio:       0.135\n",
      "Weight Decay:       0.080\n",
      "Attention Dropout:  0.353\n",
      "Hidden Dropout:     0.325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_142335-x8dhjh3x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/x8dhjh3x' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/x8dhjh3x' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/x8dhjh3x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1950003808.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(  # Uses ordinal loss always\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='980' max='1078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 980/1078 12:20 < 01:14, 1.32 it/s, Epoch 10/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.129369</td>\n",
       "      <td>0.615791</td>\n",
       "      <td>0.604197</td>\n",
       "      <td>0.631996</td>\n",
       "      <td>0.647900</td>\n",
       "      <td>0.724919</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.589920</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.643258</td>\n",
       "      <td>0.772778</td>\n",
       "      <td>0.772778</td>\n",
       "      <td>0.452303</td>\n",
       "      <td>0.556064</td>\n",
       "      <td>0.381176</td>\n",
       "      <td>0.381176</td>\n",
       "      <td>0.681137</td>\n",
       "      <td>0.575546</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.915768</td>\n",
       "      <td>0.789444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.317600</td>\n",
       "      <td>0.991077</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.720939</td>\n",
       "      <td>0.745613</td>\n",
       "      <td>0.727265</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.689802</td>\n",
       "      <td>0.674322</td>\n",
       "      <td>0.706011</td>\n",
       "      <td>0.706011</td>\n",
       "      <td>0.783387</td>\n",
       "      <td>0.906805</td>\n",
       "      <td>0.689539</td>\n",
       "      <td>0.689539</td>\n",
       "      <td>0.663221</td>\n",
       "      <td>0.672581</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.769479</td>\n",
       "      <td>0.668534</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.352077</td>\n",
       "      <td>0.935965</td>\n",
       "      <td>0.846916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.996600</td>\n",
       "      <td>0.878306</td>\n",
       "      <td>0.794124</td>\n",
       "      <td>0.793935</td>\n",
       "      <td>0.791605</td>\n",
       "      <td>0.808704</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.702229</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.903689</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.735805</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.846523</td>\n",
       "      <td>0.906290</td>\n",
       "      <td>0.794151</td>\n",
       "      <td>0.794151</td>\n",
       "      <td>0.780430</td>\n",
       "      <td>0.791768</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.851038</td>\n",
       "      <td>0.821934</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.257976</td>\n",
       "      <td>0.952720</td>\n",
       "      <td>0.891349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>0.840612</td>\n",
       "      <td>0.825109</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>0.837022</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.831557</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.787783</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.817486</td>\n",
       "      <td>0.817486</td>\n",
       "      <td>0.856814</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>0.810997</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>0.832941</td>\n",
       "      <td>0.832941</td>\n",
       "      <td>0.855826</td>\n",
       "      <td>0.891632</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.211613</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.909468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.746500</td>\n",
       "      <td>0.869154</td>\n",
       "      <td>0.816158</td>\n",
       "      <td>0.815879</td>\n",
       "      <td>0.820301</td>\n",
       "      <td>0.824423</td>\n",
       "      <td>0.841901</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.771870</td>\n",
       "      <td>0.809353</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.886839</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.849010</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.225155</td>\n",
       "      <td>0.962359</td>\n",
       "      <td>0.905030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.683400</td>\n",
       "      <td>0.867117</td>\n",
       "      <td>0.827404</td>\n",
       "      <td>0.827024</td>\n",
       "      <td>0.826466</td>\n",
       "      <td>0.837683</td>\n",
       "      <td>0.831418</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.774554</td>\n",
       "      <td>0.791334</td>\n",
       "      <td>0.758470</td>\n",
       "      <td>0.758470</td>\n",
       "      <td>0.862605</td>\n",
       "      <td>0.919745</td>\n",
       "      <td>0.812148</td>\n",
       "      <td>0.812148</td>\n",
       "      <td>0.812054</td>\n",
       "      <td>0.821171</td>\n",
       "      <td>0.803137</td>\n",
       "      <td>0.803137</td>\n",
       "      <td>0.869203</td>\n",
       "      <td>0.819507</td>\n",
       "      <td>0.925316</td>\n",
       "      <td>0.925316</td>\n",
       "      <td>0.210695</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.912990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.635500</td>\n",
       "      <td>0.841963</td>\n",
       "      <td>0.837732</td>\n",
       "      <td>0.837375</td>\n",
       "      <td>0.842103</td>\n",
       "      <td>0.841086</td>\n",
       "      <td>0.852910</td>\n",
       "      <td>0.881838</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.803954</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.855388</td>\n",
       "      <td>0.849224</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.822355</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.870460</td>\n",
       "      <td>0.834107</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.190498</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.922602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.869107</td>\n",
       "      <td>0.835437</td>\n",
       "      <td>0.834571</td>\n",
       "      <td>0.833042</td>\n",
       "      <td>0.846687</td>\n",
       "      <td>0.856589</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.905738</td>\n",
       "      <td>0.905738</td>\n",
       "      <td>0.792260</td>\n",
       "      <td>0.826603</td>\n",
       "      <td>0.760656</td>\n",
       "      <td>0.760656</td>\n",
       "      <td>0.851811</td>\n",
       "      <td>0.831726</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.821774</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.871226</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.894937</td>\n",
       "      <td>0.894937</td>\n",
       "      <td>0.192564</td>\n",
       "      <td>0.974524</td>\n",
       "      <td>0.923341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.875462</td>\n",
       "      <td>0.832683</td>\n",
       "      <td>0.832048</td>\n",
       "      <td>0.831174</td>\n",
       "      <td>0.841831</td>\n",
       "      <td>0.850643</td>\n",
       "      <td>0.822180</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.787913</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.769399</td>\n",
       "      <td>0.769399</td>\n",
       "      <td>0.842802</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.821443</td>\n",
       "      <td>0.844942</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.876695</td>\n",
       "      <td>0.854567</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.195547</td>\n",
       "      <td>0.974065</td>\n",
       "      <td>0.922107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.898477</td>\n",
       "      <td>0.826945</td>\n",
       "      <td>0.825724</td>\n",
       "      <td>0.822717</td>\n",
       "      <td>0.840680</td>\n",
       "      <td>0.845420</td>\n",
       "      <td>0.791071</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.779370</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.844199</td>\n",
       "      <td>0.829533</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.813573</td>\n",
       "      <td>0.849701</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.912658</td>\n",
       "      <td>0.201744</td>\n",
       "      <td>0.973835</td>\n",
       "      <td>0.921099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0000, Val Loss: 1.1294, Val F1: 0.0000, QWK: 0.7894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0000, Val Loss: 0.9911, Val F1: 0.0000, QWK: 0.8469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0000, Val Loss: 0.8783, Val F1: 0.0000, QWK: 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0000, Val Loss: 0.8406, Val F1: 0.0000, QWK: 0.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0000, Val Loss: 0.8692, Val F1: 0.0000, QWK: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0000, Val Loss: 0.8671, Val F1: 0.0000, QWK: 0.9130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0000, Val Loss: 0.8420, Val F1: 0.0000, QWK: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0000, Val Loss: 0.8691, Val F1: 0.0000, QWK: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0000, Val Loss: 0.8755, Val F1: 0.0000, QWK: 0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0000, Val Loss: 0.8985, Val F1: 0.0000, QWK: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.7548, Val Loss: 0.8985, Val F1: 0.0000, QWK: 0.9211\n",
      "‚úÖ Trial checkpoint saved: ./checkpoints_roberta/trial_7/final_epoch_10.ckpt\n",
      "‚úÖ Model files saved in: ./checkpoints_roberta/trial_7\n",
      "üìä Trial 7 score: 0.9211 (Best: 0.9298)\n",
      "GPU Memory Used: 4.02 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>Learning_Rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Stage</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Train Loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>Unfrozen_Layers</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Adjacent Accuracy</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation F1</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Loss</td><td>‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>Validation MAE</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation Precision</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Validation QWK</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>Validation Recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/accuracy</td><td>‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>‚ñÇ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/accuracy_negative</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ</td></tr><tr><td>eval/accuracy_neutral</td><td>‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/accuracy_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/adjacent_accuracy</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_extremely_negative</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá</td></tr><tr><td>eval/f1_extremely_positive</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1_negative</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_neutral</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/f1_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá</td></tr><tr><td>eval/precision_extremely_negative</td><td>‚ñÉ‚ñÖ‚ñÅ‚ñá‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ</td></tr><tr><td>eval/precision_extremely_positive</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/precision_negative</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/precision_neutral</td><td>‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/precision_positive</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_negative</td><td>‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>eval/recall_extremely_positive</td><td>‚ñÇ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá</td></tr><tr><td>eval/recall_negative</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ</td></tr><tr><td>eval/recall_neutral</td><td>‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/recall_positive</td><td>‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÇ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñá‚ñÉ‚ñá‚ñÖ‚ñá</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñá‚ñÉ‚ñá‚ñÖ‚ñá</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Learning_Rate</td><td>6e-05</td></tr><tr><td>Stage</td><td>1</td></tr><tr><td>Train Accuracy</td><td>0</td></tr><tr><td>Train Loss</td><td>0.75478</td></tr><tr><td>Unfrozen_Layers</td><td>12</td></tr><tr><td>Validation Accuracy</td><td>0.82695</td></tr><tr><td>Validation Adjacent Accuracy</td><td>0.97384</td></tr><tr><td>Validation F1</td><td>0</td></tr><tr><td>Validation Loss</td><td>0.89848</td></tr><tr><td>Validation MAE</td><td>0.20174</td></tr><tr><td>Validation Precision</td><td>0</td></tr><tr><td>Validation QWK</td><td>0.9211</td></tr><tr><td>Validation Recall</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.82695</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.90779</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.91266</td></tr><tr><td>eval/accuracy_negative</td><td>0.74317</td></tr><tr><td>eval/accuracy_neutral</td><td>0.85939</td></tr><tr><td>eval/accuracy_positive</td><td>0.78039</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.97384</td></tr><tr><td>eval/f1</td><td>0.82572</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.84542</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.86607</td></tr><tr><td>eval/f1_negative</td><td>0.77937</td></tr><tr><td>eval/f1_neutral</td><td>0.8442</td></tr><tr><td>eval/f1_positive</td><td>0.81357</td></tr><tr><td>eval/loss</td><td>0.89848</td></tr><tr><td>eval/mae</td><td>0.20174</td></tr><tr><td>eval/precision</td><td>0.82272</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.79107</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.824</td></tr><tr><td>eval/precision_negative</td><td>0.81928</td></tr><tr><td>eval/precision_neutral</td><td>0.82953</td></tr><tr><td>eval/precision_positive</td><td>0.8497</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.9211</td></tr><tr><td>eval/recall</td><td>0.84068</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.90779</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.91266</td></tr><tr><td>eval/recall_negative</td><td>0.74317</td></tr><tr><td>eval/recall_neutral</td><td>0.85939</td></tr><tr><td>eval/recall_positive</td><td>0.78039</td></tr><tr><td>eval/runtime</td><td>6.2187</td></tr><tr><td>eval/samples_per_second</td><td>700.63</td></tr><tr><td>eval/steps_per_second</td><td>1.447</td></tr><tr><td>total_flos</td><td>7225039187117520.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>980</td></tr><tr><td>train/grad_norm</td><td>2.88362</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.5602</td></tr><tr><td>train_loss</td><td>0.75478</td></tr><tr><td>train_runtime</td><td>742.5615</td></tr><tr><td>train_samples_per_second</td><td>370.34</td></tr><tr><td>train_steps_per_second</td><td>1.452</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/x8dhjh3x' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss/runs/x8dhjh3x</a><br> View project at: <a href='https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/covid-tweet-sentiment-hf-roberta-regularloss</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_142335-x8dhjh3x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 14:36:47,626] Trial 7 finished with value: 0.9210994149655075 and parameters: {'learning_rate': 5.912385786218203e-05, 'batch_size': 64, 'label_smoothing': 0.1340152351552511, 'num_epochs': 11, 'warmup_ratio': 0.13457532845956638, 'weight_decay': 0.07983415554786308, 'attention_dropout': 0.3533393048077859, 'hidden_dropout': 0.32510017157630366}. Best is trial 2 with value: 0.9297840127669785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters saved to best_params_roberta.json\n",
      "Best score: 0.9298\n",
      "Best params: {'learning_rate': 0.0002410038500292598, 'batch_size': 32, 'label_smoothing': 0.09079127901743848, 'num_epochs': 11, 'warmup_ratio': 0.14435680747215307, 'weight_decay': 0.0849441280799004, 'attention_dropout': 0.3758622805072069, 'hidden_dropout': 0.3533269312284606}\n",
      "Completed 8/8 trials\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=8)\n",
    "\n",
    "roberta_results = save_best_hyperparameters(study, \"roberta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f0dbd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "34f88efe5ab24d20927ca21b02e0d3c7",
      "34a6c0eab2874625875d555af6257658",
      "d7106754a3eb4faebb4ecae05eed6a98",
      "8654010d0cf04f1ba6f36488926d9aac",
      "9653ca717ce14a24af0e9605e5dc2a05",
      "99a13abcad48455b8f523a45b1ff66b3",
      "b87688fba2b3415986af6912be41c2a9",
      "ae545347ec974505b1cb4d4810464603",
      "6a1b9253869545b8b2d0b1367e821681",
      "c258b2a1031645f6b51c620bdd18aac2",
      "249836f74234443eb30345c59cd2e400",
      "08e8b15126904a2dbeac6f7ce1eb4b01",
      "831009f3c36c49f7af511a306e93dda8",
      "3f5f87537b8e41bd9deb7d0c327d5390",
      "e0e702198f2f41508944a36c1f64dbd8",
      "5358d8170a4c4df9a5c8f7cd1bf7b555",
      "3552eb0b0f96403ebdcbe4c991a6e09f",
      "092aaea92e9747bba5cede2ad7e9a069",
      "c66de1585d494d1bb423dcf9f7a1ab8b",
      "edeb85340544484f9a9b52285e74aee5",
      "c8a22b6ebc424367a6d2db9cfadbb503",
      "3fc12d9667bd495b8daa05b28d8cd147",
      "a3d004c4ffbb441c8bfef104b5ab0ea0",
      "e11f0de0b51a4874a1270d974327469b",
      "820ea70c3fcf40009677b634270da9cd",
      "e5c5be624af04f1eb41c24585b7dd7f8",
      "9ad4d2a6f7b44f03a04cf9ef7147d27e",
      "196213f7d97d43c0aec1562386c73ce3",
      "0546381a7411418f9ef400bdfc67fb31",
      "0d4ed17009fc4235ab9b63c86a1bfe3f",
      "3f0774392d6c4cf6bc6b4f9ff81096b2",
      "b9fec429dd2440ae87d58295dc13b98d",
      "05c69249c3564bb2a72f53bfd007826d"
     ]
    },
    "id": "f8f0dbd0",
    "outputId": "6ca9fb62-c924-482d-c2a3-e6923e521289"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3255646991.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  test_trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [214/214 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/deep-learning-project/wandb/run-20250801_143656-vzuqnfc9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mayachn3-maya-bondar/huggingface/runs/vzuqnfc9' target=\"_blank\">./temp</a></strong> to <a href='https://wandb.ai/mayachn3-maya-bondar/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mayachn3-maya-bondar/huggingface' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mayachn3-maya-bondar/huggingface/runs/vzuqnfc9' target=\"_blank\">https://wandb.ai/mayachn3-maya-bondar/huggingface/runs/vzuqnfc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f88efe5ab24d20927ca21b02e0d3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e8b15126904a2dbeac6f7ce1eb4b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d004c4ffbb441c8bfef104b5ab0ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST SET EVALUATION - COMPREHENSIVE ANALYSIS\n",
      "{'eval_loss': 0.5976839065551758, 'eval_model_preparation_time': 0.0031, 'eval_accuracy': 0.833820093457944, 'eval_f1': 0.8329810902269634, 'eval_precision': 0.8310268173965134, 'eval_recall': 0.8477128360447125, 'eval_f1_extremely_negative': 0.8459770114942529, 'eval_precision_extremely_negative': 0.8, 'eval_recall_extremely_negative': 0.8975609756097561, 'eval_accuracy_extremely_negative': 0.8975609756097561, 'eval_f1_negative': 0.8036410923276983, 'eval_precision_negative': 0.8524137931034482, 'eval_recall_negative': 0.7601476014760148, 'eval_accuracy_negative': 0.7601476014760148, 'eval_f1_neutral': 0.8392101551480959, 'eval_precision_neutral': 0.7839262187088274, 'eval_recall_neutral': 0.9028831562974203, 'eval_accuracy_neutral': 0.9028831562974203, 'eval_f1_positive': 0.8244358833241607, 'eval_precision_positive': 0.8679026651216686, 'eval_recall_positive': 0.7851153039832285, 'eval_accuracy_positive': 0.7851153039832285, 'eval_f1_extremely_positive': 0.8713692946058091, 'eval_precision_extremely_positive': 0.8508914100486223, 'eval_recall_extremely_positive': 0.8928571428571429, 'eval_accuracy_extremely_positive': 0.8928571428571429, 'eval_mae': 0.19304906542056074, 'eval_adjacent_accuracy': 0.9760514018691588, 'eval_quadratic_weighted_kappa': 0.9247642877519247, 'eval_runtime': 6.0791, 'eval_samples_per_second': 563.237, 'eval_steps_per_second': 35.202}\n",
      "\n",
      "OVERALL CLASSIFICATION METRICS:\n",
      "Accuracy:           0.8338\n",
      "Validation QWK:     0.9248\n",
      "F1:                 0.8330\n",
      "Precision-Macro:    0.8310\n",
      "Recall-Macro:       0.8477\n",
      "\n",
      "ORDINAL-AWARE METRICS:\n",
      "Mean Absolute Error:        0.1930\n",
      "Adjacent Accuracy:          0.9761\n",
      "Quadratic Weighted Kappa:   0.9248\n",
      "\n",
      "PERFORMANCE METRICS:\n",
      "Inference Time:             0.0114 sec\n",
      "Model Size:                 1906.9 MB\n",
      "\n",
      "PER-CLASS PERFORMANCE ANALYSIS:\n",
      "\n",
      "Extremely Negative:\n",
      "  F1-Score:   0.8460\n",
      "  Precision:  0.8000\n",
      "  Recall:     0.8976\n",
      "  Accuracy:   0.8976\n",
      "\n",
      "Negative:\n",
      "  F1-Score:   0.8036\n",
      "  Precision:  0.8524\n",
      "  Recall:     0.7601\n",
      "  Accuracy:   0.7601\n",
      "\n",
      "Neutral:\n",
      "  F1-Score:   0.8392\n",
      "  Precision:  0.7839\n",
      "  Recall:     0.9029\n",
      "  Accuracy:   0.9029\n",
      "\n",
      "Positive:\n",
      "  F1-Score:   0.8244\n",
      "  Precision:  0.8679\n",
      "  Recall:     0.7851\n",
      "  Accuracy:   0.7851\n",
      "\n",
      "Extremely Positive:\n",
      "  F1-Score:   0.8714\n",
      "  Precision:  0.8509\n",
      "  Recall:     0.8929\n",
      "  Accuracy:   0.8929\n",
      "\n",
      "PERFORMANCE INSIGHTS:\n",
      "‚Ä¢ MAE 0.19: On average off by 0.19 sentiment levels\n",
      "‚Ä¢ Adjacent Accuracy 97.6%: Predictions within 1 sentiment level\n",
      "‚Ä¢ QWK 0.925: Excellent ordinal agreement\n",
      "‚Ä¢ Inference Speed: 88.1 predictions per second\n",
      "‚Ä¢ Model Efficiency: 1906.9 MB storage required\n",
      "\n",
      "CLASS-SPECIFIC INSIGHTS:\n",
      "‚Ä¢ Best performing class: Extremely Positive (F1: 0.8714)\n",
      "‚Ä¢ Most challenging class: Negative (F1: 0.8036)\n",
      "\n",
      "COVID SENTIMENT INSIGHTS:\n",
      "‚Ä¢ Extreme emotions (avg F1: 0.859): Well-handled\n",
      "‚Ä¢ Moderate emotions (avg F1: 0.814): Good performance\n",
      "‚Ä¢ Neutral sentiment (F1: 0.839): Well-identified\n",
      "\n",
      "üìä FINAL SUMMARY:\n",
      "F1: 0.8330 | QWK: 0.9248 | Inference: 0.0114s | Size: 1906.9MB\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def calculate_model_metrics(model_path=\"./best_model_so_far\"):\n",
    "    \"\"\"Calculate inference time and model size\"\"\"\n",
    "\n",
    "    # 1. Calculate Model Size\n",
    "    def get_model_size_mb(path):\n",
    "        total_size = 0\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                total_size += os.path.getsize(filepath)\n",
    "        return total_size / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    model_size_mb = get_model_size_mb(model_path)\n",
    "\n",
    "    # 2. Calculate Inference Time\n",
    "    def measure_inference_time():\n",
    "        # Load model for timing\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer_for_timing = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base\")\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Sample text for timing\n",
    "        sample_text = \"COVID vaccines are helping to reduce hospitalizations significantly.\"\n",
    "\n",
    "        # Warm-up runs (don't count these)\n",
    "        for _ in range(3):\n",
    "            inputs = tokenizer_for_timing(sample_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            if device.type == \"cuda\":\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                _ = model(**inputs)\n",
    "\n",
    "        # Actual timing runs\n",
    "        times = []\n",
    "        num_runs = 10\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            inputs = tokenizer_for_timing(sample_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            if device.type == \"cuda\":\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                _ = model(**inputs)\n",
    "            end_time = time.time()\n",
    "\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "        # Return average inference time\n",
    "        avg_inference_time = sum(times) / len(times)\n",
    "        return avg_inference_time\n",
    "\n",
    "    inference_time = measure_inference_time()\n",
    "\n",
    "    return model_size_mb, inference_time\n",
    "\n",
    "# Load the best model\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(best_model_path)\n",
    "\n",
    "# Create trainer for test evaluation\n",
    "test_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./temp\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        remove_unused_columns=False,\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_detailed_metrics,  # Use the enhanced function!\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = test_trainer.evaluate(test_dataset)\n",
    "\n",
    "# Calculate performance metrics\n",
    "model_size_mb, inference_time_sec = calculate_model_metrics(best_model_path)\n",
    "\n",
    "print(\"FINAL TEST SET EVALUATION - COMPREHENSIVE ANALYSIS\")\n",
    "\n",
    "# Standard Classification Metrics\n",
    "print(test_results)\n",
    "print(\"\\nOVERALL CLASSIFICATION METRICS:\")\n",
    "print(f\"Accuracy:           {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation QWK:     {test_results['eval_quadratic_weighted_kappa']:.4f}\")\n",
    "print(f\"F1:                 {test_results['eval_f1']:.4f}\")\n",
    "print(f\"Precision-Macro:    {test_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall-Macro:       {test_results['eval_recall']:.4f}\")\n",
    "\n",
    "# Ordinal-Aware Metrics\n",
    "print(\"\\nORDINAL-AWARE METRICS:\")\n",
    "print(f\"Mean Absolute Error:        {test_results['eval_mae']:.4f}\")\n",
    "print(f\"Adjacent Accuracy:          {test_results['eval_adjacent_accuracy']:.4f}\")\n",
    "print(f\"Quadratic Weighted Kappa:   {test_results['eval_quadratic_weighted_kappa']:.4f}\")\n",
    "\n",
    "# Performance Metrics\n",
    "print(\"\\nPERFORMANCE METRICS:\")\n",
    "print(f\"Inference Time:             {inference_time_sec:.4f} sec\")\n",
    "print(f\"Model Size:                 {model_size_mb:.1f} MB\")\n",
    "\n",
    "# Per-Class Detailed Analysis (PRESERVED)\n",
    "print(\"\\nPER-CLASS PERFORMANCE ANALYSIS:\")\n",
    "sentiment_classes = [\"extremely_negative\", \"negative\", \"neutral\", \"positive\", \"extremely_positive\"]\n",
    "class_display_names = [\"Extremely Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Extremely Positive\"]\n",
    "\n",
    "for i, (class_key, class_name) in enumerate(zip(sentiment_classes, class_display_names)):\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  F1-Score:   {test_results.get(f'eval_f1_{class_key}', 0):.4f}\")\n",
    "    print(f\"  Precision:  {test_results.get(f'eval_precision_{class_key}', 0):.4f}\")\n",
    "    print(f\"  Recall:     {test_results.get(f'eval_accuracy_{class_key}', 0):.4f}\")\n",
    "    print(f\"  Accuracy:   {test_results.get(f'eval_accuracy_{class_key}', 0):.4f}\")\n",
    "\n",
    "# Performance Analysis (PRESERVED + ENHANCED)\n",
    "print(\"\\nPERFORMANCE INSIGHTS:\")\n",
    "print(f\"‚Ä¢ MAE {test_results['eval_mae']:.2f}: On average off by {test_results['eval_mae']:.2f} sentiment levels\")\n",
    "print(f\"‚Ä¢ Adjacent Accuracy {test_results['eval_adjacent_accuracy']:.1%}: Predictions within 1 sentiment level\")\n",
    "print(f\"‚Ä¢ QWK {test_results['eval_quadratic_weighted_kappa']:.3f}: {'Excellent' if test_results['eval_quadratic_weighted_kappa'] > 0.8 else 'Good' if test_results['eval_quadratic_weighted_kappa'] > 0.6 else 'Moderate'} ordinal agreement\")\n",
    "# Added inference speed and efficiency insights\n",
    "print(f\"‚Ä¢ Inference Speed: {1/inference_time_sec:.1f} predictions per second\")\n",
    "print(f\"‚Ä¢ Model Efficiency: {model_size_mb:.1f} MB storage required\")\n",
    "\n",
    "# Class Performance Analysis (PRESERVED)\n",
    "f1_scores = [test_results.get(f'eval_f1_{class_key}', 0) for class_key in sentiment_classes]\n",
    "best_class_idx = f1_scores.index(max(f1_scores))\n",
    "worst_class_idx = f1_scores.index(min(f1_scores))\n",
    "\n",
    "print(f\"\\nCLASS-SPECIFIC INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Best performing class: {class_display_names[best_class_idx]} (F1: {f1_scores[best_class_idx]:.4f})\")\n",
    "print(f\"‚Ä¢ Most challenging class: {class_display_names[worst_class_idx]} (F1: {f1_scores[worst_class_idx]:.4f})\")\n",
    "\n",
    "# COVID-specific insights (PRESERVED)\n",
    "extreme_avg = (f1_scores[0] + f1_scores[4]) / 2  # extremely negative + extremely positive\n",
    "moderate_avg = (f1_scores[1] + f1_scores[3]) / 2  # negative + positive\n",
    "neutral_score = f1_scores[2]\n",
    "\n",
    "print(f\"\\nCOVID SENTIMENT INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Extreme emotions (avg F1: {extreme_avg:.3f}): {'Challenging' if extreme_avg < 0.7 else 'Well-handled'}\")\n",
    "print(f\"‚Ä¢ Moderate emotions (avg F1: {moderate_avg:.3f}): {'Needs work' if moderate_avg < 0.75 else 'Good performance'}\")\n",
    "print(f\"‚Ä¢ Neutral sentiment (F1: {neutral_score:.3f}): {'Difficult to detect' if neutral_score < 0.8 else 'Well-identified'}\")\n",
    "\n",
    "# Final Summary with Key Metrics\n",
    "print(f\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"F1: {test_results['eval_f1']:.4f} | QWK: {test_results['eval_quadratic_weighted_kappa']:.4f} | Inference: {inference_time_sec:.4f}s | Size: {model_size_mb:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbqy2-UTV0q-",
   "metadata": {
    "id": "dbqy2-UTV0q-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "t8HZfeEkRm5q",
   "metadata": {
    "id": "t8HZfeEkRm5q"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qfFcAYK09243",
   "metadata": {
    "id": "qfFcAYK09243"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qfzxxnZlUwni",
   "metadata": {
    "id": "qfzxxnZlUwni"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8kbmFvP7ZE6X",
   "metadata": {
    "id": "8kbmFvP7ZE6X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ff52cc87324652be2f158cfacc004b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb34f6d268447d3858e6ebb2c7728c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6bca1a0c241452eae8c1a4665272946",
      "value": 1
     }
    },
    "03832a4062994496ba436f4f559d4d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "05295c9735714280a7855522b6f347a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0546381a7411418f9ef400bdfc67fb31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05c69249c3564bb2a72f53bfd007826d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0706eec76d844c37942e2fc347490eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0781a380a5be4acebbc43de221648bb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08e8b15126904a2dbeac6f7ce1eb4b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_831009f3c36c49f7af511a306e93dda8",
       "IPY_MODEL_3f5f87537b8e41bd9deb7d0c327d5390",
       "IPY_MODEL_e0e702198f2f41508944a36c1f64dbd8"
      ],
      "layout": "IPY_MODEL_5358d8170a4c4df9a5c8f7cd1bf7b555"
     }
    },
    "092aaea92e9747bba5cede2ad7e9a069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d4ed17009fc4235ab9b63c86a1bfe3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "119ff29627ed46a6a22c3223766f5a3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "139a3cba0e574f188793625a48afcc62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1693c3864eb9435bb7e9e2d0275f4c13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2dbe648ddf445c0af90dcb9447a7def",
       "IPY_MODEL_919bac8386494e3eb31e182de571d210",
       "IPY_MODEL_1d384f5082514794b5d833e0a7f2e5f3"
      ],
      "layout": "IPY_MODEL_139a3cba0e574f188793625a48afcc62"
     }
    },
    "18f5e54594e64c298235412d99528578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "196213f7d97d43c0aec1562386c73ce3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d384f5082514794b5d833e0a7f2e5f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6554aa02e14b400ca2996f7852e0d482",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2d62eac39daa4adfbb64180c364e1ac9",
      "value": "‚Äá456k/?‚Äá[00:00&lt;00:00,‚Äá19.4MB/s]"
     }
    },
    "1d50de1f582d402a85a270c785506d08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "1f4a6a68928b426eb852e26587bc4a9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ff92333757f40068a3a54a7feff9c34",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_781ff2d42cbd47fbabed94779de35cd2",
      "value": "‚Äá499M/499M‚Äá[00:08&lt;00:00,‚Äá91.8MB/s]"
     }
    },
    "22f9cb7994fd4a67bf81f02a73afab21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6272cfb9525484ba89ad2958fc2e116",
      "max": 498679497,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36082894cdff4b4ea2fbcbd95cde35e8",
      "value": 498679497
     }
    },
    "249836f74234443eb30345c59cd2e400": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2821ed6da4b84696a6fdbada949ef7fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92a2046435b4414da1de707e5616647e",
       "IPY_MODEL_22f9cb7994fd4a67bf81f02a73afab21",
       "IPY_MODEL_62ee1d3b01304d83b470219247537848"
      ],
      "layout": "IPY_MODEL_baedcade0ee746e49e6ee6dfb29b8ef5"
     }
    },
    "29f362b8857642bda4b45cd2a33cb2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d62eac39daa4adfbb64180c364e1ac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34a6c0eab2874625875d555af6257658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a13abcad48455b8f523a45b1ff66b3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b87688fba2b3415986af6912be41c2a9",
      "value": "config.json:‚Äá100%"
     }
    },
    "34f88efe5ab24d20927ca21b02e0d3c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34a6c0eab2874625875d555af6257658",
       "IPY_MODEL_d7106754a3eb4faebb4ecae05eed6a98",
       "IPY_MODEL_8654010d0cf04f1ba6f36488926d9aac"
      ],
      "layout": "IPY_MODEL_9653ca717ce14a24af0e9605e5dc2a05"
     }
    },
    "3552eb0b0f96403ebdcbe4c991a6e09f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36082894cdff4b4ea2fbcbd95cde35e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "366df97bcd9943f7859b83ce0d7c19e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bb33970e76b4cc9bdeffa3a3f4945bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63af3dda74e84864aacbc55316a8181f",
      "max": 150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7853784bf0c94d7c837ede06fb117f71",
      "value": 150
     }
    },
    "3d35c6a74ee545318fbeeb96e68b3341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e12c09bd97e41d1af906dd434212875": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3e4d1a29fb2b4ae2b74b426e570dfe72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1daa66e3e3a4c5e86de6166c5904579",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e5f47b812904aa2aa7e18fedaad3f20",
      "value": 1
     }
    },
    "3f0774392d6c4cf6bc6b4f9ff81096b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f5f87537b8e41bd9deb7d0c327d5390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c66de1585d494d1bb423dcf9f7a1ab8b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edeb85340544484f9a9b52285e74aee5",
      "value": 1
     }
    },
    "3fc12d9667bd495b8daa05b28d8cd147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44403ef97ae14190bd4d3c1df03cb02e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c56d8af61d8b4aa99569d8c7b864fa21",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_af99290f2db64c73b026f8b1b1543cfd",
      "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
     }
    },
    "451e74328fb4440e9c925511f623d5e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bd2360a82234615b975a1d90935fb81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff7f131a5c0441d0922627949e2f27e1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c048d48ec3534b568880586209dbf443",
      "value": "‚Äá747/747‚Äá[00:00&lt;00:00,‚Äá14.4kB/s]"
     }
    },
    "4f985d2d1be246139246672f5281482a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5358d8170a4c4df9a5c8f7cd1bf7b555": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "544a4f01e08844cabb222d3e8e35daf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "549166b7ad4f4c098128bd4c80f3104e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79075c00e23a4f1cb046fab73223bd6c",
      "max": 498620100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b890d8f88b894d5a8912d510439fa5d3",
      "value": 498620100
     }
    },
    "586833fbf74d4665af37aa034257280b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb34f6d268447d3858e6ebb2c7728c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5d3f9b35f09a470697b1ad3924e09acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab68ed1830c3423bbc27904f21aaf5f6",
       "IPY_MODEL_dbd4b9f62a894b7ca84d8d508e1d107b",
       "IPY_MODEL_4bd2360a82234615b975a1d90935fb81"
      ],
      "layout": "IPY_MODEL_9ef4d19fdf434d3eabccc36313d5fb60"
     }
    },
    "5d425cece12c447e9d959e23b2914c53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61e10086534c44f7b5a0b605a6be8494": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62ee1d3b01304d83b470219247537848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_544a4f01e08844cabb222d3e8e35daf2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_29f362b8857642bda4b45cd2a33cb2c6",
      "value": "‚Äá499M/499M‚Äá[00:16&lt;00:00,‚Äá36.4MB/s]"
     }
    },
    "6324976e748541179692883c6df2368a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6386d04666f94b1ab415b0a7f71265e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5ea925ab7fe4761a574eb71075267f9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_75947f57bc2d4dfbb59b9e4d9fa5afac",
      "value": "vocab.json:‚Äá"
     }
    },
    "63af3dda74e84864aacbc55316a8181f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "653cbc00b5ef478191ef34bcbd3c844e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a575e347df3644edb6afa2cf2dd33c19",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_af9030671d9344e9a2c01f2b3c686d37",
      "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
     }
    },
    "6554aa02e14b400ca2996f7852e0d482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68d5b5164e354f5089b32ff301ff161c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_586833fbf74d4665af37aa034257280b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_823197ef947e4531ae82b6225ebee846",
      "value": "‚Äá150/150‚Äá[00:00&lt;00:00,‚Äá4.50kB/s]"
     }
    },
    "6a1b9253869545b8b2d0b1367e821681": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d6a82b115454ca29a0d63c4a4b08b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f03f31cb1ccc48a7b191b68a35b977a0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_76cd9bc65ce04f60809ece0d944c4c52",
      "value": "special_tokens_map.json:‚Äá100%"
     }
    },
    "6e1aea27009e4292b5e34f9d5c609f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "73a99b615b424d4298f68bb45fcc1ee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7435ba26857c40f4ac99844c23d15ad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb9faf150f4d4b2f99c2fd9c398901b0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_935ba084b35444cdb033bd63e0840749",
      "value": "‚Äá4.20k/?‚Äá[00:00&lt;00:00,‚Äá45.3kB/s]"
     }
    },
    "75947f57bc2d4dfbb59b9e4d9fa5afac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76cd9bc65ce04f60809ece0d944c4c52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77ca4eeb992045da830bcf0a8d68f5ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6386d04666f94b1ab415b0a7f71265e5",
       "IPY_MODEL_dded6da6bb994d82a2910ef788d1b2d8",
       "IPY_MODEL_856bbebcf1334c03858875a9508792d4"
      ],
      "layout": "IPY_MODEL_3d35c6a74ee545318fbeeb96e68b3341"
     }
    },
    "781ff2d42cbd47fbabed94779de35cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7853784bf0c94d7c837ede06fb117f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79075c00e23a4f1cb046fab73223bd6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ff92333757f40068a3a54a7feff9c34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "820ea70c3fcf40009677b634270da9cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d4ed17009fc4235ab9b63c86a1bfe3f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f0774392d6c4cf6bc6b4f9ff81096b2",
      "value": 1
     }
    },
    "823197ef947e4531ae82b6225ebee846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83027707f4be4bf1b4f09c3a7a16151d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eab65e368fc0400087dbefa4625fca54",
       "IPY_MODEL_549166b7ad4f4c098128bd4c80f3104e",
       "IPY_MODEL_1f4a6a68928b426eb852e26587bc4a9c"
      ],
      "layout": "IPY_MODEL_451e74328fb4440e9c925511f623d5e3"
     }
    },
    "831009f3c36c49f7af511a306e93dda8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3552eb0b0f96403ebdcbe4c991a6e09f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_092aaea92e9747bba5cede2ad7e9a069",
      "value": "vocab.json:‚Äá"
     }
    },
    "85282a4c1f734d7f940bf33b92a52014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18f5e54594e64c298235412d99528578",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_901eaa5011d84dc7925a926657f441aa",
      "value": "‚Äá6.79k/?‚Äá[00:00&lt;00:00,‚Äá74.5kB/s]"
     }
    },
    "856bbebcf1334c03858875a9508792d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73a99b615b424d4298f68bb45fcc1ee8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_61e10086534c44f7b5a0b605a6be8494",
      "value": "‚Äá899k/?‚Äá[00:00&lt;00:00,‚Äá15.2MB/s]"
     }
    },
    "8654010d0cf04f1ba6f36488926d9aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c258b2a1031645f6b51c620bdd18aac2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_249836f74234443eb30345c59cd2e400",
      "value": "‚Äá565/565‚Äá[00:00&lt;00:00,‚Äá30.9kB/s]"
     }
    },
    "892cfbfc2c8b47e0816409eeed192f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d6a82b115454ca29a0d63c4a4b08b54",
       "IPY_MODEL_3bb33970e76b4cc9bdeffa3a3f4945bc",
       "IPY_MODEL_68d5b5164e354f5089b32ff301ff161c"
      ],
      "layout": "IPY_MODEL_cd3e2a1317ea4bfb859d017dc2275b50"
     }
    },
    "8ae05f528d4747d68a2d4616761ff0b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e5f47b812904aa2aa7e18fedaad3f20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "901eaa5011d84dc7925a926657f441aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "919bac8386494e3eb31e182de571d210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e1aea27009e4292b5e34f9d5c609f61",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03832a4062994496ba436f4f559d4d69",
      "value": 1
     }
    },
    "9288a74ba9f74b33afa22836d34b9efb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92a2046435b4414da1de707e5616647e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec5a153e1c734de6972a052ec481ff18",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_df1c6ae7b76641718191d6235ba93470",
      "value": "pytorch_model.bin:‚Äá100%"
     }
    },
    "935ba084b35444cdb033bd63e0840749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9653ca717ce14a24af0e9605e5dc2a05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98fb681487a74d208327de07460fa650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99a13abcad48455b8f523a45b1ff66b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ad4d2a6f7b44f03a04cf9ef7147d27e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef4d19fdf434d3eabccc36313d5fb60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3d004c4ffbb441c8bfef104b5ab0ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e11f0de0b51a4874a1270d974327469b",
       "IPY_MODEL_820ea70c3fcf40009677b634270da9cd",
       "IPY_MODEL_e5c5be624af04f1eb41c24585b7dd7f8"
      ],
      "layout": "IPY_MODEL_9ad4d2a6f7b44f03a04cf9ef7147d27e"
     }
    },
    "a426be591eb346339ad701b51f3c6213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a50e7258639a4462a71f17f4b00e4c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbd5b1dec6fb4cd0870f195bcaa7a0fc",
       "IPY_MODEL_3e4d1a29fb2b4ae2b74b426e570dfe72",
       "IPY_MODEL_d3ccbf67d1164279ace2ec381d76e826"
      ],
      "layout": "IPY_MODEL_4f985d2d1be246139246672f5281482a"
     }
    },
    "a575e347df3644edb6afa2cf2dd33c19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6482dbb156d412b82d3888e907921ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e12c09bd97e41d1af906dd434212875",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c536190a57d747f28a2912abffba2b53",
      "value": 1
     }
    },
    "a7b2163761554730a1645eba2d24cf7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab68ed1830c3423bbc27904f21aaf5f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ae05f528d4747d68a2d4616761ff0b2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a426be591eb346339ad701b51f3c6213",
      "value": "config.json:‚Äá100%"
     }
    },
    "ae545347ec974505b1cb4d4810464603": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9030671d9344e9a2c01f2b3c686d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af99290f2db64c73b026f8b1b1543cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1daa66e3e3a4c5e86de6166c5904579": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b23837ee38f94ea1bfa0b1009469c96b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b35a4cdc72ec465e97161702ae0df8f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d50c99c8a02047f59ef5b259b9cfd2c1",
       "IPY_MODEL_a6482dbb156d412b82d3888e907921ab",
       "IPY_MODEL_7435ba26857c40f4ac99844c23d15ad3"
      ],
      "layout": "IPY_MODEL_0781a380a5be4acebbc43de221648bb2"
     }
    },
    "b3617441486d402eba3e7a49aa523e58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b56bce7626144e22ba1bdb0fe935fcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b87688fba2b3415986af6912be41c2a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b890d8f88b894d5a8912d510439fa5d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9fec429dd2440ae87d58295dc13b98d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba695eb30f6048039d4f1da395800e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd18d098e9f341fdb60fc716bafd618f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9288a74ba9f74b33afa22836d34b9efb",
      "value": "‚Äá7.38k/?‚Äá[00:00&lt;00:00,‚Äá111kB/s]"
     }
    },
    "baedcade0ee746e49e6ee6dfb29b8ef5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd18d098e9f341fdb60fc716bafd618f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c048d48ec3534b568880586209dbf443": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c258b2a1031645f6b51c620bdd18aac2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c497a3c2a5864d138d5e9d14e2bb4ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c536190a57d747f28a2912abffba2b53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c56d8af61d8b4aa99569d8c7b864fa21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5ba775605404c879fe18cf9cea6741c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d50de1f582d402a85a270c785506d08",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b56bce7626144e22ba1bdb0fe935fcbe",
      "value": 1
     }
    },
    "c66de1585d494d1bb423dcf9f7a1ab8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c8a22b6ebc424367a6d2db9cfadbb503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd3e2a1317ea4bfb859d017dc2275b50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3ccbf67d1164279ace2ec381d76e826": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe83c962074f4cc9a21b937a06417f04",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_98fb681487a74d208327de07460fa650",
      "value": "‚Äá7.56k/?‚Äá[00:00&lt;00:00,‚Äá99.5kB/s]"
     }
    },
    "d50c99c8a02047f59ef5b259b9cfd2c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d425cece12c447e9d959e23b2914c53",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0706eec76d844c37942e2fc347490eb5",
      "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
     }
    },
    "d5ea925ab7fe4761a574eb71075267f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6bca1a0c241452eae8c1a4665272946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7106754a3eb4faebb4ecae05eed6a98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae545347ec974505b1cb4d4810464603",
      "max": 565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a1b9253869545b8b2d0b1367e821681",
      "value": 565
     }
    },
    "dbd4b9f62a894b7ca84d8d508e1d107b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7b2163761554730a1645eba2d24cf7f",
      "max": 747,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6324976e748541179692883c6df2368a",
      "value": 747
     }
    },
    "dcab8c5c2f924a2fb146b708f562d5a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dded6da6bb994d82a2910ef788d1b2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f877cf15f99545969739c8e7290e6e58",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c497a3c2a5864d138d5e9d14e2bb4ca7",
      "value": 1
     }
    },
    "df1c6ae7b76641718191d6235ba93470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0a0ab20fc254c6e8511d3c81c7284dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0e702198f2f41508944a36c1f64dbd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8a22b6ebc424367a6d2db9cfadbb503",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3fc12d9667bd495b8daa05b28d8cd147",
      "value": "‚Äá899k/?‚Äá[00:00&lt;00:00,‚Äá11.5MB/s]"
     }
    },
    "e11f0de0b51a4874a1270d974327469b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_196213f7d97d43c0aec1562386c73ce3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0546381a7411418f9ef400bdfc67fb31",
      "value": "merges.txt:‚Äá"
     }
    },
    "e2dbe648ddf445c0af90dcb9447a7def": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3868097d7444927826afbbe2c95fa7b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_366df97bcd9943f7859b83ce0d7c19e7",
      "value": "merges.txt:‚Äá"
     }
    },
    "e3868097d7444927826afbbe2c95fa7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3bb2621f09d4e1695d296891f86b98b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_653cbc00b5ef478191ef34bcbd3c844e",
       "IPY_MODEL_00ff52cc87324652be2f158cfacc004b",
       "IPY_MODEL_ba695eb30f6048039d4f1da395800e26"
      ],
      "layout": "IPY_MODEL_dcab8c5c2f924a2fb146b708f562d5a8"
     }
    },
    "e5c5be624af04f1eb41c24585b7dd7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9fec429dd2440ae87d58295dc13b98d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_05c69249c3564bb2a72f53bfd007826d",
      "value": "‚Äá456k/?‚Äá[00:00&lt;00:00,‚Äá9.75MB/s]"
     }
    },
    "e821e71550634d4ba1c1d5b165bf82f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44403ef97ae14190bd4d3c1df03cb02e",
       "IPY_MODEL_c5ba775605404c879fe18cf9cea6741c",
       "IPY_MODEL_85282a4c1f734d7f940bf33b92a52014"
      ],
      "layout": "IPY_MODEL_b23837ee38f94ea1bfa0b1009469c96b"
     }
    },
    "eab65e368fc0400087dbefa4625fca54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119ff29627ed46a6a22c3223766f5a3a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b3617441486d402eba3e7a49aa523e58",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "ec5a153e1c734de6972a052ec481ff18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edeb85340544484f9a9b52285e74aee5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f03f31cb1ccc48a7b191b68a35b977a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6272cfb9525484ba89ad2958fc2e116": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f877cf15f99545969739c8e7290e6e58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "fb9faf150f4d4b2f99c2fd9c398901b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbd5b1dec6fb4cd0870f195bcaa7a0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05295c9735714280a7855522b6f347a6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e0a0ab20fc254c6e8511d3c81c7284dd",
      "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
     }
    },
    "fe83c962074f4cc9a21b937a06417f04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7f131a5c0441d0922627949e2f27e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
