{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation for COVID Tweet Sentiment Analysis\n",
    "\n",
    "This notebook implements knowledge distillation to compress a BERTweet sentiment analysis model into a smaller DistilRoBERTa student model.\n",
    "\n",
    "## Distillation Setup:\n",
    "- **Teacher Model**: `finiteautomata/bertweet-base-sentiment-analysis` (frozen)\n",
    "- **Student Model**: `distilroberta-base` with classification head\n",
    "- **Loss Function**: Combined hard target (CrossEntropy) + soft target (KL Divergence) loss\n",
    "- **Temperature**: T ≈ 2.0 for soft target computation\n",
    "- **Alpha**: α ≈ 0.5 for loss weighting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured for CPU-only execution\n",
      "Please restart the kernel and run all cells from the beginning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables to force CPU usage and disable MPS\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"Environment configured for CPU-only execution\")\n",
    "print(\"Please restart the kernel and run all cells from the beginning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q evaluate\n",
    "%pip install -q emoji==0.6.0\n",
    "%pip install -q torch\n",
    "%pip install -q transformers\n",
    "%pip install -q accelerate\n",
    "%pip install -q wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, cohen_kappa_score\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import evaluate\n",
    "import wandb\n",
    "import time\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon MPS\n"
     ]
    }
   ],
   "source": [
    "# Smart device selection for cross-platform GPU support\n",
    "def get_optimal_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "        return device\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple Silicon MPS\")\n",
    "        return device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "        return device\n",
    "\n",
    "device = get_optimal_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/taltzafrir/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to wandb.ai account\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W&B login\n",
    "print('Logging to wandb.ai account')\n",
    "wandb.login(key=\"6dd13a6018f089606e418d323dd8b502f31bca4e\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "train = pd.read_csv(\"OOT_train.csv\", encoding='latin-1')\n",
    "val = pd.read_csv(\"OOT_val.csv\", encoding='latin-1')\n",
    "test = pd.read_csv(\"OOT_test.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the labels numerically from Sentiment\n",
    "ordinal_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "# Map to ordinal labels\n",
    "train[\"ordinal_label_id\"] = train[\"Sentiment\"].map(ordinal_mapping)\n",
    "val[\"ordinal_label_id\"] = val[\"Sentiment\"].map(ordinal_mapping)\n",
    "test[\"ordinal_label_id\"] = test[\"Sentiment\"].map(ordinal_mapping)\n",
    "\n",
    "# Define mapping between label id and sentiment for later use\n",
    "ordinal_label2id = ordinal_mapping\n",
    "ordinal_id2label = {v: k for k, v in ordinal_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Input Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the input string from multiple columns\n",
    "def build_augmented_input(row):\n",
    "    parts = []\n",
    "\n",
    "    if pd.notna(row.get('clean_tweet')):\n",
    "        parts.append(f\"{row['clean_tweet']}\")\n",
    "\n",
    "    if pd.notna(row.get('Location_standardized')) and row['Location_standardized'].lower() != 'unknown':\n",
    "        parts.append(f\"{row['Location_standardized']}\")\n",
    "\n",
    "    if pd.notna(row.get('TweetAt')):\n",
    "        parts.append(f\"{row['TweetAt']}\")\n",
    "\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# Apply to the DataFrames\n",
    "train['model_input'] = train.apply(build_augmented_input, axis=1)\n",
    "val['model_input'] = val.apply(build_augmented_input, axis=1)\n",
    "test['model_input'] = test.apply(build_augmented_input, axis=1)\n",
    "\n",
    "# Create new DataFrames with only what's needed for modeling\n",
    "formatted_train = train[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_val = val[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_test = test[['model_input', 'ordinal_label_id']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "ordinal_label_id\n",
      "0     5175\n",
      "1     9230\n",
      "2     6784\n",
      "3    10140\n",
      "4     5845\n",
      "Name: count, dtype: int64\n",
      "Class 0: 5000 samples (undersampled)\n",
      "Class 1: 5000 samples (undersampled)\n",
      "Class 2: 5000 samples (undersampled)\n",
      "Class 3: 5000 samples (undersampled)\n",
      "Class 4: 5000 samples (undersampled)\n",
      "Balanced dataset: 25000 total samples\n",
      "New distribution:\n",
      "ordinal_label_id\n",
      "0    5000\n",
      "1    5000\n",
      "2    5000\n",
      "3    5000\n",
      "4    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(df, target_samples_per_class=5000):\n",
    "    \"\"\"Balance dataset by undersampling\"\"\"\n",
    "    balanced_dfs = []\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    print(df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    for class_id in range(5):\n",
    "        class_data = df[df['ordinal_label_id'] == class_id]\n",
    "\n",
    "        if len(class_data) > target_samples_per_class:\n",
    "            class_data = class_data.sample(n=target_samples_per_class, random_state=42)\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (undersampled)\")\n",
    "        else:\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (kept all)\")\n",
    "\n",
    "        balanced_dfs.append(class_data)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "    print(f\"Balanced dataset: {len(balanced_df)} total samples\")\n",
    "    print(\"New distribution:\")\n",
    "    print(balanced_df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing to training data\n",
    "formatted_train = balance_dataset(formatted_train, target_samples_per_class=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "### Teacher Model (BERTweet) - Frozen\n",
    "### Student Model (DistilRoBERTa) - Trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: finiteautomata/bertweet-base-sentiment-analysis\n",
      "Student Model: distilroberta-base\n"
     ]
    }
   ],
   "source": [
    "# Teacher model configuration\n",
    "MODEL_TYPE = 'bert'\n",
    "teacher_model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "teacher_model_path = \"./Full model/bert/best_bert_model_so_far\"\n",
    "teacher_model_file = \"model_bert.pt\"\n",
    "\n",
    "# Student model configuration\n",
    "student_model_name = \"distilroberta-base\"\n",
    "\n",
    "print(f\"Teacher Model: {teacher_model_name}\")\n",
    "print(f\"Student Model: {student_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Teacher Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading teacher model from best checkpoint...\n",
      "Teacher model loaded and frozen!\n"
     ]
    }
   ],
   "source": [
    "# Load the best teacher model from hyperparameter tuning\n",
    "print(\"Loading teacher model from best checkpoint...\")\n",
    "teacher_model = torch.load(os.path.join(teacher_model_path, teacher_model_file), map_location=device)\n",
    "teacher_model.eval()  # Set to evaluation mode\n",
    "teacher_model.to(device)\n",
    "\n",
    "# Freeze teacher model parameters\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"Teacher model loaded and frozen!\")\n",
    "\n",
    "# Load teacher tokenizer\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Student Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model initialized with 82,122,245 trainable parameters\n",
      "Teacher model has 134,903,813 total parameters (frozen)\n"
     ]
    }
   ],
   "source": [
    "# Initialize student model with classification head\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student_model_name,\n",
    "    num_labels=5,\n",
    "    id2label=ordinal_id2label,\n",
    "    label2id=ordinal_label2id\n",
    ")\n",
    "student_model.to(device)\n",
    "\n",
    "# Load student tokenizer\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
    "\n",
    "print(f\"Student model initialized with {sum(p.numel() for p in student_model.parameters() if p.requires_grad):,} trainable parameters\")\n",
    "print(f\"Teacher model has {sum(p.numel() for p in teacher_model.parameters()):,} total parameters (frozen)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset for Knowledge Distillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationDataset(Dataset):\n",
    "    \"\"\"Custom dataset for knowledge distillation that stores raw text\"\"\"\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return raw text and label - tokenization will happen in the collate function\n",
    "        return {\n",
    "            'text': self.texts[idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def create_distillation_collate_fn(student_tokenizer, teacher_tokenizer, device, max_length=128):\n",
    "    \"\"\"Create a collate function that tokenizes for both student and teacher\"\"\"\n",
    "    def collate_fn(batch):\n",
    "        texts = [item['text'] for item in batch]\n",
    "        labels = torch.stack([item['labels'] for item in batch])\n",
    "        \n",
    "        # Tokenize for student\n",
    "        student_encodings = student_tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize for teacher\n",
    "        teacher_encodings = teacher_tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move all tensors to the correct device\n",
    "        return {\n",
    "            'student_input_ids': student_encodings['input_ids'].to(device),\n",
    "            'student_attention_mask': student_encodings['attention_mask'].to(device),\n",
    "            'teacher_input_ids': teacher_encodings['input_ids'].to(device),\n",
    "            'teacher_attention_mask': teacher_encodings['attention_mask'].to(device),\n",
    "            'labels': labels.to(device)\n",
    "        }\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 25000\n",
      "Validation dataset size: 4357\n",
      "Test dataset size: 3424\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to lists\n",
    "train_texts = formatted_train['model_input'].tolist()\n",
    "val_texts = formatted_val['model_input'].tolist()\n",
    "test_texts = formatted_test['model_input'].tolist()\n",
    "\n",
    "train_labels = formatted_train['ordinal_label_id'].tolist()\n",
    "val_labels = formatted_val['ordinal_label_id'].tolist()\n",
    "test_labels = formatted_test['ordinal_label_id'].tolist()\n",
    "\n",
    "# Create distillation datasets\n",
    "train_dataset = DistillationDataset(train_texts, train_labels)\n",
    "val_dataset = DistillationDataset(val_texts, val_labels)\n",
    "test_dataset = DistillationDataset(test_texts, test_labels)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_detailed_metrics(eval_pred):\n",
    "    \"\"\"Enhanced metrics using HuggingFace Evaluate library\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Load HuggingFace metrics (cached after first load)\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "    # Compute standard classification metrics\n",
    "    results = {}\n",
    "\n",
    "    # Basic metrics\n",
    "    results.update(accuracy_metric.compute(predictions=predictions, references=labels))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
    "    results.update(precision_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(recall_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "\n",
    "    # Per-class F1 scores\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "    for i, class_name in enumerate(['extremely_negative', 'negative', 'neutral', 'positive', 'extremely_positive']):\n",
    "        results[f'f1_{class_name}'] = f1_per_class[i]\n",
    "\n",
    "        # Per-class precision and recall\n",
    "        precision_per_class = precision_score(labels, predictions, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, predictions, average=None, zero_division=0)\n",
    "        results[f'precision_{class_name}'] = precision_per_class[i]\n",
    "        results[f'recall_{class_name}'] = recall_per_class[i]\n",
    "\n",
    "        # Per-class accuracy\n",
    "        class_mask = (labels == i)\n",
    "        if class_mask.sum() > 0:\n",
    "            results[f'accuracy_{class_name}'] = accuracy_score(labels[class_mask], predictions[class_mask])\n",
    "        else:\n",
    "            results[f'accuracy_{class_name}'] = 0.0\n",
    "\n",
    "    # Custom ordinal metrics\n",
    "    results['mae'] = np.mean(np.abs(predictions - labels))\n",
    "    results['adjacent_accuracy'] = np.sum(np.abs(predictions - labels) <= 1) / len(labels)\n",
    "\n",
    "    # Quadratic Weighted Kappa\n",
    "    try:\n",
    "        qwk = cohen_kappa_score(labels, predictions, weights='quadratic')\n",
    "        results['quadratic_weighted_kappa'] = qwk\n",
    "    except:\n",
    "        results['quadratic_weighted_kappa'] = 0.0\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distillation Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation Temperature: 2.0\n",
      "Alpha (hard loss weight): 0.5\n",
      "Soft loss weight: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Knowledge distillation hyperparameters\n",
    "TEMPERATURE = 2.0  # Temperature for soft targets\n",
    "ALPHA = 0.5  # Weight for hard target loss (1-alpha for soft target loss)\n",
    "\n",
    "print(f\"Distillation Temperature: {TEMPERATURE}\")\n",
    "print(f\"Alpha (hard loss weight): {ALPHA}\")\n",
    "print(f\"Soft loss weight: {1-ALPHA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Distillation Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    \"\"\"Custom trainer for knowledge distillation\"\"\"\n",
    "    \n",
    "    def __init__(self, teacher_model, temperature, alpha, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Compute combined knowledge distillation loss\n",
    "        \"\"\"\n",
    "        # Check if we're in distillation mode (training) or regular mode (evaluation)\n",
    "        if 'student_input_ids' in inputs and inputs['student_input_ids'] is not None:\n",
    "            # Distillation mode - use both teacher and student\n",
    "            # Get student predictions\n",
    "            student_outputs = model(\n",
    "                input_ids=inputs.get('student_input_ids'),\n",
    "                attention_mask=inputs.get('student_attention_mask')\n",
    "            )\n",
    "            student_logits = student_outputs.logits\n",
    "            \n",
    "            # Get teacher predictions (no gradient)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = self.teacher_model(\n",
    "                    input_ids=inputs.get('teacher_input_ids'),\n",
    "                    attention_mask=inputs.get('teacher_attention_mask')\n",
    "                )\n",
    "                teacher_logits = teacher_outputs.logits\n",
    "            \n",
    "            # Get labels\n",
    "            labels = inputs.get('labels')\n",
    "            \n",
    "            # Hard target loss (CrossEntropy)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            hard_loss = loss_fct(student_logits, labels)\n",
    "            \n",
    "            # Soft target loss (KL Divergence)\n",
    "            student_log_probs = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "            teacher_probs = F.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "            \n",
    "            # KL Divergence loss\n",
    "            soft_loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean')\n",
    "            soft_loss = soft_loss * (self.temperature ** 2)\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = self.alpha * hard_loss + (1 - self.alpha) * soft_loss\n",
    "            \n",
    "            return (loss, student_outputs) if return_outputs else loss\n",
    "        \n",
    "        else:\n",
    "            # Regular mode - use standard loss computation for evaluation\n",
    "            student_outputs = model(\n",
    "                input_ids=inputs.get('input_ids'),\n",
    "                attention_mask=inputs.get('attention_mask'),\n",
    "                labels=inputs.get('labels')\n",
    "            )\n",
    "            \n",
    "            return (student_outputs.loss, student_outputs) if return_outputs else student_outputs.loss\n",
    "        \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        Override prediction step to use student inputs only\n",
    "        \"\"\"\n",
    "        # Check if we have the expected distillation inputs\n",
    "        if 'student_input_ids' in inputs and inputs['student_input_ids'] is not None:\n",
    "            # During training/evaluation with distillation data\n",
    "            student_inputs = {\n",
    "                'input_ids': inputs.get('student_input_ids'),\n",
    "                'attention_mask': inputs.get('student_attention_mask'),\n",
    "                'labels': inputs.get('labels')\n",
    "            }\n",
    "        else:\n",
    "            # Fallback for regular evaluation (when using SimpleDataset)\n",
    "            student_inputs = {\n",
    "                'input_ids': inputs.get('input_ids'),\n",
    "                'attention_mask': inputs.get('attention_mask'),\n",
    "                'labels': inputs.get('labels')\n",
    "            }\n",
    "        \n",
    "        # Call parent's prediction_step with student inputs\n",
    "        return super().prediction_step(model, student_inputs, prediction_loss_only, ignore_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Logger Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationMetricsLogger(TrainerCallback):\n",
    "    \"\"\"Callback to log detailed metrics during distillation\"\"\"\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None or not wandb.run:\n",
    "            return\n",
    "        \n",
    "        # Only log when we have evaluation metrics\n",
    "        if 'eval_loss' in logs:\n",
    "            current_epoch = int(state.epoch) if state.epoch else 0\n",
    "            \n",
    "            # Get training loss from state history\n",
    "            train_loss = 0\n",
    "            if state.log_history:\n",
    "                for log_entry in reversed(state.log_history):\n",
    "                    if 'loss' in log_entry:\n",
    "                        train_loss = log_entry['loss']\n",
    "                        break\n",
    "            \n",
    "            # Detailed metrics\n",
    "            detailed_metrics = {\n",
    "                \"Epoch\": current_epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Validation Loss\": logs.get('eval_loss', 0),\n",
    "                \"Validation Accuracy\": logs.get('eval_accuracy', 0),\n",
    "                \"Validation F1\": logs.get('eval_f1', 0),\n",
    "                \"Validation MAE\": logs.get('eval_mae', 0),\n",
    "                \"Validation QWK\": logs.get('eval_quadratic_weighted_kappa', 0),\n",
    "                \"Learning_Rate\": logs.get('learning_rate', args.learning_rate),\n",
    "            }\n",
    "            \n",
    "            # Log to WandB\n",
    "            wandb.log(detailed_metrics)\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"Epoch {current_epoch}: \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {logs.get('eval_loss', 0):.4f}, \"\n",
    "                  f\"Val F1: {logs.get('eval_f1', 0):.4f}, \"\n",
    "                  f\"QWK: {logs.get('eval_quadratic_weighted_kappa', 0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/taltzafrir/At_Bay/paz/deep/deep_learning_sentiment/wandb/run-20250820_073935-ctzr5ddi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi' target=\"_blank\">bert-to-distilroberta</a></strong> to <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2fda80790>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize W&B for tracking\n",
    "wandb.init(\n",
    "    project=\"covid-tweet-sentiment-distillation\",\n",
    "    name=f\"{MODEL_TYPE}-to-distilroberta\",\n",
    "    config={\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"teacher_model\": teacher_model_name,\n",
    "        \"student_model\": student_model_name,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"num_epochs\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments with GPU optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilled_model\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16 if device.type == \"cpu\" else 32,  # Smaller batch for CPU\n",
    "    per_device_eval_batch_size=32 if device.type == \"cpu\" else 64,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_quadratic_weighted_kappa\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"wandb\",\n",
    "    fp16=device.type == \"cuda\",  # Enable FP16 only for CUDA\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=device.type != \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Distillation Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation trainer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create custom collate function\n",
    "collate_fn = collate_fn = create_distillation_collate_fn(student_tokenizer, teacher_tokenizer, device)\n",
    "\n",
    "# Create distillation trainer\n",
    "trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA,\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_detailed_metrics,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=2),\n",
    "        DistillationMetricsLogger(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# GPU memory optimization\n",
    "if device.type in [\"cuda\", \"mps\"]:\n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    student_model.gradient_checkpointing_enable()\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        # CUDA-specific optimizations\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"Distillation trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Knowledge Distillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting knowledge distillation training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 1:04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>0.753833</td>\n",
       "      <td>0.718614</td>\n",
       "      <td>0.718342</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>0.714441</td>\n",
       "      <td>0.683215</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.592213</td>\n",
       "      <td>0.592213</td>\n",
       "      <td>0.675609</td>\n",
       "      <td>0.619308</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.783738</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.678035</td>\n",
       "      <td>0.702862</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.780999</td>\n",
       "      <td>0.761733</td>\n",
       "      <td>0.801266</td>\n",
       "      <td>0.801266</td>\n",
       "      <td>0.356667</td>\n",
       "      <td>0.934129</td>\n",
       "      <td>0.834216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580400</td>\n",
       "      <td>0.775524</td>\n",
       "      <td>0.721597</td>\n",
       "      <td>0.714726</td>\n",
       "      <td>0.732524</td>\n",
       "      <td>0.757951</td>\n",
       "      <td>0.769091</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.866803</td>\n",
       "      <td>0.866803</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>0.767409</td>\n",
       "      <td>0.602186</td>\n",
       "      <td>0.602186</td>\n",
       "      <td>0.854866</td>\n",
       "      <td>0.865207</td>\n",
       "      <td>0.844769</td>\n",
       "      <td>0.844769</td>\n",
       "      <td>0.612339</td>\n",
       "      <td>0.741360</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.597464</td>\n",
       "      <td>0.954430</td>\n",
       "      <td>0.954430</td>\n",
       "      <td>0.339454</td>\n",
       "      <td>0.948359</td>\n",
       "      <td>0.866675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.541632</td>\n",
       "      <td>0.817305</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.828780</td>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.807091</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.793033</td>\n",
       "      <td>0.793033</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>0.770742</td>\n",
       "      <td>0.771585</td>\n",
       "      <td>0.771585</td>\n",
       "      <td>0.862927</td>\n",
       "      <td>0.888095</td>\n",
       "      <td>0.839145</td>\n",
       "      <td>0.839145</td>\n",
       "      <td>0.803412</td>\n",
       "      <td>0.762139</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.852568</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.808861</td>\n",
       "      <td>0.808861</td>\n",
       "      <td>0.231122</td>\n",
       "      <td>0.956392</td>\n",
       "      <td>0.893931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.607764</td>\n",
       "      <td>0.803076</td>\n",
       "      <td>0.801692</td>\n",
       "      <td>0.794178</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.772294</td>\n",
       "      <td>0.668666</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>0.707620</td>\n",
       "      <td>0.769923</td>\n",
       "      <td>0.654645</td>\n",
       "      <td>0.654645</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>0.889277</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.795399</td>\n",
       "      <td>0.835203</td>\n",
       "      <td>0.759216</td>\n",
       "      <td>0.759216</td>\n",
       "      <td>0.858160</td>\n",
       "      <td>0.807821</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>0.238467</td>\n",
       "      <td>0.962130</td>\n",
       "      <td>0.904807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.311800</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.784026</td>\n",
       "      <td>0.781800</td>\n",
       "      <td>0.781652</td>\n",
       "      <td>0.805671</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.725256</td>\n",
       "      <td>0.870902</td>\n",
       "      <td>0.870902</td>\n",
       "      <td>0.734250</td>\n",
       "      <td>0.771360</td>\n",
       "      <td>0.700546</td>\n",
       "      <td>0.700546</td>\n",
       "      <td>0.863507</td>\n",
       "      <td>0.877030</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.825121</td>\n",
       "      <td>0.669804</td>\n",
       "      <td>0.669804</td>\n",
       "      <td>0.807420</td>\n",
       "      <td>0.709492</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.258894</td>\n",
       "      <td>0.962359</td>\n",
       "      <td>0.897559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.627535</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.807740</td>\n",
       "      <td>0.808417</td>\n",
       "      <td>0.820407</td>\n",
       "      <td>0.813861</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.842213</td>\n",
       "      <td>0.842213</td>\n",
       "      <td>0.771733</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>0.751913</td>\n",
       "      <td>0.751913</td>\n",
       "      <td>0.861127</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.833521</td>\n",
       "      <td>0.833521</td>\n",
       "      <td>0.776866</td>\n",
       "      <td>0.814273</td>\n",
       "      <td>0.742745</td>\n",
       "      <td>0.742745</td>\n",
       "      <td>0.835414</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>0.228827</td>\n",
       "      <td>0.966720</td>\n",
       "      <td>0.907647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.718361</td>\n",
       "      <td>0.792288</td>\n",
       "      <td>0.789662</td>\n",
       "      <td>0.791133</td>\n",
       "      <td>0.814804</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.746528</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.757417</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>0.855543</td>\n",
       "      <td>0.851728</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.745969</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.671373</td>\n",
       "      <td>0.671373</td>\n",
       "      <td>0.811892</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>0.243287</td>\n",
       "      <td>0.969015</td>\n",
       "      <td>0.906510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>0.690931</td>\n",
       "      <td>0.804682</td>\n",
       "      <td>0.802871</td>\n",
       "      <td>0.804160</td>\n",
       "      <td>0.819135</td>\n",
       "      <td>0.820614</td>\n",
       "      <td>0.794626</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.816953</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.855721</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.768395</td>\n",
       "      <td>0.822739</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.745178</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.232958</td>\n",
       "      <td>0.967409</td>\n",
       "      <td>0.905317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>0.805600</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.798935</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.802525</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.911885</td>\n",
       "      <td>0.911885</td>\n",
       "      <td>0.744431</td>\n",
       "      <td>0.802781</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.862302</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.785534</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.732549</td>\n",
       "      <td>0.732549</td>\n",
       "      <td>0.837050</td>\n",
       "      <td>0.763295</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>0.228139</td>\n",
       "      <td>0.970163</td>\n",
       "      <td>0.911929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.708193</td>\n",
       "      <td>0.805830</td>\n",
       "      <td>0.803935</td>\n",
       "      <td>0.799346</td>\n",
       "      <td>0.822445</td>\n",
       "      <td>0.806361</td>\n",
       "      <td>0.741824</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.797048</td>\n",
       "      <td>0.708197</td>\n",
       "      <td>0.708197</td>\n",
       "      <td>0.848318</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>0.785684</td>\n",
       "      <td>0.848182</td>\n",
       "      <td>0.731765</td>\n",
       "      <td>0.731765</td>\n",
       "      <td>0.844419</td>\n",
       "      <td>0.777423</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.911993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.8347, Val Loss: 0.7538, Val F1: 0.7183, QWK: 0.8342\n",
      "Epoch 2: Train Loss: 0.5804, Val Loss: 0.7755, Val F1: 0.7147, QWK: 0.8667\n",
      "Epoch 3: Train Loss: 0.4613, Val Loss: 0.5416, Val F1: 0.8181, QWK: 0.8939\n",
      "Epoch 4: Train Loss: 0.3605, Val Loss: 0.6078, Val F1: 0.8017, QWK: 0.9048\n",
      "Epoch 5: Train Loss: 0.3118, Val Loss: 0.6624, Val F1: 0.7818, QWK: 0.8976\n",
      "Epoch 6: Train Loss: 0.2591, Val Loss: 0.6275, Val F1: 0.8077, QWK: 0.9076\n",
      "Epoch 7: Train Loss: 0.2286, Val Loss: 0.7184, Val F1: 0.7897, QWK: 0.9065\n",
      "Epoch 8: Train Loss: 0.2063, Val Loss: 0.6909, Val F1: 0.8029, QWK: 0.9053\n",
      "Epoch 9: Train Loss: 0.1472, Val Loss: 0.7108, Val F1: 0.8038, QWK: 0.9119\n",
      "Epoch 10: Train Loss: 0.1388, Val Loss: 0.7082, Val F1: 0.8039, QWK: 0.9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7820, training_loss=0.3834667370447417, metrics={'train_runtime': 3895.0233, 'train_samples_per_second': 64.184, 'train_steps_per_second': 2.008, 'total_flos': 0.0, 'train_loss': 0.3834667370447417, 'epoch': 10.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the student model with knowledge distillation\n",
    "print(\"Starting knowledge distillation training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Size Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Size Comparison:\n",
      "Teacher Model Size: 514.62 MB\n",
      "Student Model Size: 313.28 MB\n",
      "Compression Ratio: 1.64x\n",
      "Size Reduction: 39.1%\n"
     ]
    }
   ],
   "source": [
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / (1024 * 1024)\n",
    "    return size_mb\n",
    "\n",
    "# Compare model sizes\n",
    "teacher_size = get_model_size(teacher_model)\n",
    "student_size = get_model_size(student_model)\n",
    "compression_ratio = teacher_size / student_size\n",
    "\n",
    "print(f\"\\nModel Size Comparison:\")\n",
    "print(f\"Teacher Model Size: {teacher_size:.2f} MB\")\n",
    "print(f\"Student Model Size: {student_size:.2f} MB\")\n",
    "print(f\"Compression Ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Speed Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference speed...\n",
      "\n",
      "Inference Speed Comparison:\n",
      "Teacher Model: 15.73 ± 0.91 ms\n",
      "Student Model: 8.59 ± 0.07 ms\n",
      "Speedup: 1.83x\n"
     ]
    }
   ],
   "source": [
    "def measure_inference_time(model, tokenizer, sample_text, num_runs=50):\n",
    "    \"\"\"Measure average inference time for a model\"\"\"\n",
    "    model.eval()\n",
    "    times = []\n",
    "    \n",
    "    # Warm-up runs\n",
    "    for _ in range(5):\n",
    "        inputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "    \n",
    "    # Actual timing runs\n",
    "    for _ in range(num_runs):\n",
    "        inputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# Test inference speed\n",
    "sample_tweet = \"COVID-19 vaccines have been crucial in reducing hospitalizations and saving lives worldwide.\"\n",
    "\n",
    "print(\"Measuring inference speed...\")\n",
    "teacher_time, teacher_std = measure_inference_time(teacher_model, teacher_tokenizer, sample_tweet)\n",
    "student_time, student_std = measure_inference_time(student_model, student_tokenizer, sample_tweet)\n",
    "\n",
    "speedup = teacher_time / student_time\n",
    "\n",
    "print(f\"\\nInference Speed Comparison:\")\n",
    "print(f\"Teacher Model: {teacher_time*1000:.2f} ± {teacher_std*1000:.2f} ms\")\n",
    "print(f\"Student Model: {student_time*1000:.2f} ± {student_std*1000:.2f} ms\")\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Teacher Model on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_24478/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Student Model on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_24478/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Teacher Model on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_24478/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Student Model on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_24478/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, tokenizer, dataset, model_name):\n",
    "    \"\"\"Evaluate a model on a given dataset\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create regular dataset for single-model evaluation\n",
    "    eval_encodings = tokenizer(\n",
    "        [dataset[i]['text'] for i in range(len(dataset))],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=128,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "    \n",
    "    class SimpleDataset(Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "    \n",
    "    eval_dataset = SimpleDataset(eval_encodings, [dataset[i]['labels'].item() for i in range(len(dataset))])\n",
    "    \n",
    "    # Create trainer for evaluation\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=\"./temp\",\n",
    "            per_device_eval_batch_size=64,\n",
    "            remove_unused_columns=False,\n",
    "            dataloader_num_workers=0,\n",
    "        ),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_detailed_metrics,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    results = eval_trainer.evaluate(eval_dataset)\n",
    "    \n",
    "    # Format results with model name prefix\n",
    "    formatted_results = {}\n",
    "    for key, value in results.items():\n",
    "        new_key = f\"{model_name}_{key}\"\n",
    "        formatted_results[new_key] = value\n",
    "    \n",
    "    return results, formatted_results\n",
    "\n",
    "# Evaluate both models on validation set\n",
    "print(\"Evaluating Teacher Model on Validation Set...\")\n",
    "val_results_teacher, val_formatted_teacher = evaluate_model(teacher_model, teacher_tokenizer, val_dataset, \"teacher\")\n",
    "\n",
    "print(\"\\nEvaluating Student Model on Validation Set...\")\n",
    "val_results_student, val_formatted_student = evaluate_model(student_model, student_tokenizer, val_dataset, \"student\")\n",
    "\n",
    "# Evaluate both models on test set\n",
    "print(\"\\nEvaluating Teacher Model on Test Set...\")\n",
    "test_results_teacher, test_formatted_teacher = evaluate_model(teacher_model, teacher_tokenizer, test_dataset, \"teacher\")\n",
    "\n",
    "print(\"\\nEvaluating Student Model on Test Set...\")\n",
    "test_results_student, test_formatted_student = evaluate_model(student_model, student_tokenizer, test_dataset, \"student\")\n",
    "\n",
    "# Log to wandb\n",
    "wandb.log({\n",
    "    **val_formatted_teacher,\n",
    "    **val_formatted_student,\n",
    "    **test_formatted_teacher,\n",
    "    **test_formatted_student\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Results Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KNOWLEDGE DISTILLATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 MODEL COMPRESSION:\n",
      "Teacher Model Size: 514.62 MB\n",
      "Student Model Size: 313.28 MB\n",
      "Compression Ratio: 1.64x\n",
      "Size Reduction: 39.1%\n",
      "\n",
      "⚡ INFERENCE SPEED:\n",
      "Teacher Model: 15.73 ms\n",
      "Student Model: 8.59 ms\n",
      "Speedup: 1.83x\n",
      "\n",
      "🎯 VALIDATION SET PERFORMANCE:\n",
      "                      Teacher     Student     Difference\n",
      "Accuracy:             0.8442      0.8058      -0.0383\n",
      "F1-Score:             0.8433      0.8039      -0.0394\n",
      "QWK:                  0.9374      0.9120      -0.0254\n",
      "MAE:                  0.1714      0.2265      +0.0551\n",
      "\n",
      "🧪 TEST SET PERFORMANCE:\n",
      "                      Teacher     Student     Difference\n",
      "Accuracy:             0.8423      0.8067      -0.0356\n",
      "F1-Score:             0.8414      0.8045      -0.0368\n",
      "QWK:                  0.9330      0.9127      -0.0203\n",
      "MAE:                  0.1790      0.2281      +0.0491\n",
      "\n",
      "🎯 PERFORMANCE RETENTION:\n",
      "Accuracy Retention: 95.8%\n",
      "F1-Score Retention: 95.6%\n",
      "QWK Retention: 97.8%\n",
      "\n",
      "💡 DISTILLATION SUMMARY:\n",
      "• Temperature: 2.0\n",
      "• Alpha (hard loss weight): 0.5\n",
      "• Achieved 1.6x model compression with 1.8x inference speedup\n",
      "• Performance drop: 0.0368 F1-score points\n",
      "• Knowledge retention: 95.6% of teacher's performance\n",
      "\n",
      "✅ Knowledge distillation complete! Results logged to W&B.\n",
      "✅ Distilled model saved to ./distilled_model_final\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Learning_Rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁█▇▆▇▆▇▇▇</td></tr><tr><td>Validation F1</td><td>▁▁█▇▆▇▆▇▇▇</td></tr><tr><td>Validation Loss</td><td>▇█▁▃▅▄▆▅▆▆</td></tr><tr><td>Validation MAE</td><td>█▇▁▂▃▁▂▁▁▁</td></tr><tr><td>Validation QWK</td><td>▁▄▆▇▇██▇██</td></tr><tr><td>alpha</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▁▇▆▅▆▅▆▆▆█▆█▆</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>▁▇▅█▇▆▇▆█▇▇▇██</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>▁█▁▆▇▇█▇▇▇▇▇▆▆</td></tr><tr><td>eval/accuracy_negative</td><td>▇▁█▃▅▇▆▆▅▅█▅█▆</td></tr><tr><td>eval/accuracy_neutral</td><td>▁▄▄▅▅▄▅▆▅▆▇▆█▅</td></tr><tr><td>eval/accuracy_positive</td><td>▄▁█▆▄▆▄▅▆▅▇▅▇▅</td></tr><tr><td>eval/adjacent_accuracy</td><td>▁▃▄▅▅▅▆▆▆▆█▆▇▆</td></tr><tr><td>eval/f1</td><td>▁▁▇▆▅▆▅▆▆▆█▆█▆</td></tr><tr><td>eval/f1_extremely_negative</td><td>▁▄▆▄▅▆▆▆▅▆█▆▇▆</td></tr><tr><td>eval/f1_extremely_positive</td><td>▃▁▇▇▄▆▅▅▆▆█▆█▆</td></tr><tr><td>eval/f1_negative</td><td>▁▁▆▃▄▆▅▆▄▅█▅█▅</td></tr><tr><td>eval/f1_neutral</td><td>▁▇▇█▇▇▇▇▇▆▅▆▆▅</td></tr><tr><td>eval/f1_positive</td><td>▃▁▇▇▅▆▅▆▆▆█▆█▆</td></tr><tr><td>eval/loss</td><td>▇█▁▃▅▄▆▅▆▆▃▆▃▆</td></tr><tr><td>eval/mae</td><td>█▇▃▄▄▃▄▃▃▃▁▃▁▃</td></tr><tr><td>eval/model_preparation_time</td><td>█▁▇▂</td></tr><tr><td>eval/precision</td><td>▁▁▇▅▄▆▅▅▅▅█▅█▅</td></tr><tr><td>eval/precision_extremely_negative</td><td>▆▂▇▁▃▆▄▆▃▄█▄▆▄</td></tr><tr><td>eval/precision_extremely_positive</td><td>▅▁█▆▄▅▄▄▅▅▇▅▇▅</td></tr><tr><td>eval/precision_negative</td><td>▁▅▅▅▅▆▆▆▆▆█▆█▇</td></tr><tr><td>eval/precision_neutral</td><td>▁▆██▇█▅▅▆▄▁▄▁▃</td></tr><tr><td>eval/precision_positive</td><td>▁▃▃▆▆▅▆▆▇▇█▇█▇</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>▁▃▅▆▅▆▆▆▆▆█▆█▆</td></tr><tr><td>eval/recall</td><td>▁▃▆▆▅▆▆▆▆▆█▆█▇</td></tr><tr><td>eval/recall_extremely_negative</td><td>▁▇▅█▇▆▇▆█▇▇▇██</td></tr><tr><td>eval/recall_extremely_positive</td><td>▁█▁▆▇▇█▇▇▇▇▇▆▆</td></tr><tr><td>eval/recall_negative</td><td>▇▁█▃▅▇▆▆▅▅█▅█▆</td></tr><tr><td>eval/recall_neutral</td><td>▁▄▄▅▅▄▅▆▅▆▇▆█▅</td></tr><tr><td>eval/recall_positive</td><td>▄▁█▆▄▆▄▅▆▅▇▅▇▅</td></tr><tr><td>eval/runtime</td><td>▅▄▄▄▄▄▄▄▄▄█▃▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▆▆▆▆▆▆▆▆▆▁█▁▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▆▆▆▆▆▆▆▆▆▂█▁▇</td></tr><tr><td>final_accuracy_retention</td><td>▁</td></tr><tr><td>final_compression_ratio</td><td>▁</td></tr><tr><td>final_f1_retention</td><td>▁</td></tr><tr><td>final_qwk_retention</td><td>▁</td></tr><tr><td>final_speedup</td><td>▁</td></tr><tr><td>student_eval_accuracy</td><td>▁</td></tr><tr><td>student_eval_accuracy_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_accuracy_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_accuracy_negative</td><td>▁</td></tr><tr><td>student_eval_accuracy_neutral</td><td>▁</td></tr><tr><td>student_eval_accuracy_positive</td><td>▁</td></tr><tr><td>student_eval_adjacent_accuracy</td><td>▁</td></tr><tr><td>student_eval_f1</td><td>▁</td></tr><tr><td>student_eval_f1_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_f1_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_f1_negative</td><td>▁</td></tr><tr><td>student_eval_f1_neutral</td><td>▁</td></tr><tr><td>student_eval_f1_positive</td><td>▁</td></tr><tr><td>student_eval_loss</td><td>▁</td></tr><tr><td>student_eval_mae</td><td>▁</td></tr><tr><td>student_eval_model_preparation_time</td><td>▁</td></tr><tr><td>student_eval_precision</td><td>▁</td></tr><tr><td>student_eval_precision_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_precision_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_precision_negative</td><td>▁</td></tr><tr><td>student_eval_precision_neutral</td><td>▁</td></tr><tr><td>student_eval_precision_positive</td><td>▁</td></tr><tr><td>student_eval_quadratic_weighted_kappa</td><td>▁</td></tr><tr><td>student_eval_recall</td><td>▁</td></tr><tr><td>student_eval_recall_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_recall_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_recall_negative</td><td>▁</td></tr><tr><td>student_eval_recall_neutral</td><td>▁</td></tr><tr><td>student_eval_recall_positive</td><td>▁</td></tr><tr><td>student_eval_runtime</td><td>▁</td></tr><tr><td>student_eval_samples_per_second</td><td>▁</td></tr><tr><td>student_eval_steps_per_second</td><td>▁</td></tr><tr><td>teacher_eval_accuracy</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_negative</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_neutral</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_positive</td><td>▁</td></tr><tr><td>teacher_eval_adjacent_accuracy</td><td>▁</td></tr><tr><td>teacher_eval_f1</td><td>▁</td></tr><tr><td>teacher_eval_f1_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_f1_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_f1_negative</td><td>▁</td></tr><tr><td>teacher_eval_f1_neutral</td><td>▁</td></tr><tr><td>teacher_eval_f1_positive</td><td>▁</td></tr><tr><td>teacher_eval_loss</td><td>▁</td></tr><tr><td>teacher_eval_mae</td><td>▁</td></tr><tr><td>teacher_eval_model_preparation_time</td><td>▁</td></tr><tr><td>teacher_eval_precision</td><td>▁</td></tr><tr><td>teacher_eval_precision_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_precision_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_precision_negative</td><td>▁</td></tr><tr><td>teacher_eval_precision_neutral</td><td>▁</td></tr><tr><td>teacher_eval_precision_positive</td><td>▁</td></tr><tr><td>teacher_eval_quadratic_weighted_kappa</td><td>▁</td></tr><tr><td>teacher_eval_recall</td><td>▁</td></tr><tr><td>teacher_eval_recall_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_recall_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_recall_negative</td><td>▁</td></tr><tr><td>teacher_eval_recall_neutral</td><td>▁</td></tr><tr><td>teacher_eval_recall_positive</td><td>▁</td></tr><tr><td>teacher_eval_runtime</td><td>▁</td></tr><tr><td>teacher_eval_samples_per_second</td><td>▁</td></tr><tr><td>teacher_eval_steps_per_second</td><td>▁</td></tr><tr><td>temperature</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████▁</td></tr><tr><td>train/grad_norm</td><td>▂▅▄▇▅▃▄▃▆▆▄▆▇▅▅▆▃▄▄▆▃▅▅▅▄█▇▄▃▅▅▂▂▃▁▅█▄▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Learning_Rate</td><td>5e-05</td></tr><tr><td>Train Loss</td><td>0.1388</td></tr><tr><td>Validation Accuracy</td><td>0.80583</td></tr><tr><td>Validation F1</td><td>0.80394</td></tr><tr><td>Validation Loss</td><td>0.70819</td></tr><tr><td>Validation MAE</td><td>0.22653</td></tr><tr><td>Validation QWK</td><td>0.91199</td></tr><tr><td>alpha</td><td>0.5</td></tr><tr><td>eval/accuracy</td><td>0.80666</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.92683</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.92007</td></tr><tr><td>eval/accuracy_negative</td><td>0.71341</td></tr><tr><td>eval/accuracy_neutral</td><td>0.86039</td></tr><tr><td>eval/accuracy_positive</td><td>0.72746</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.96904</td></tr><tr><td>eval/f1</td><td>0.80455</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.82073</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.84664</td></tr><tr><td>eval/f1_negative</td><td>0.76517</td></tr><tr><td>eval/f1_neutral</td><td>0.8369</td></tr><tr><td>eval/f1_positive</td><td>0.78285</td></tr><tr><td>eval/loss</td><td>0.71113</td></tr><tr><td>eval/mae</td><td>0.2281</td></tr><tr><td>eval/model_preparation_time</td><td>0.0014</td></tr><tr><td>eval/precision</td><td>0.80151</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.73643</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.78406</td></tr><tr><td>eval/precision_negative</td><td>0.82504</td></tr><tr><td>eval/precision_neutral</td><td>0.81466</td></tr><tr><td>eval/precision_positive</td><td>0.84737</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.9127</td></tr><tr><td>eval/recall</td><td>0.82963</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.92683</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.92007</td></tr><tr><td>eval/recall_negative</td><td>0.71341</td></tr><tr><td>eval/recall_neutral</td><td>0.86039</td></tr><tr><td>eval/recall_positive</td><td>0.72746</td></tr><tr><td>eval/runtime</td><td>12.1725</td></tr><tr><td>eval/samples_per_second</td><td>281.29</td></tr><tr><td>eval/steps_per_second</td><td>4.436</td></tr><tr><td>final_accuracy_retention</td><td>95.76976</td></tr><tr><td>final_compression_ratio</td><td>1.64268</td></tr><tr><td>final_f1_retention</td><td>95.62057</td></tr><tr><td>final_qwk_retention</td><td>97.82814</td></tr><tr><td>final_speedup</td><td>1.83054</td></tr><tr><td>student_eval_accuracy</td><td>0.80666</td></tr><tr><td>student_eval_accuracy_extremely_negative</td><td>0.92683</td></tr><tr><td>student_eval_accuracy_extremely_positive</td><td>0.92007</td></tr><tr><td>student_eval_accuracy_negative</td><td>0.71341</td></tr><tr><td>student_eval_accuracy_neutral</td><td>0.86039</td></tr><tr><td>student_eval_accuracy_positive</td><td>0.72746</td></tr><tr><td>student_eval_adjacent_accuracy</td><td>0.96904</td></tr><tr><td>student_eval_f1</td><td>0.80455</td></tr><tr><td>student_eval_f1_extremely_negative</td><td>0.82073</td></tr><tr><td>student_eval_f1_extremely_positive</td><td>0.84664</td></tr><tr><td>student_eval_f1_negative</td><td>0.76517</td></tr><tr><td>student_eval_f1_neutral</td><td>0.8369</td></tr><tr><td>student_eval_f1_positive</td><td>0.78285</td></tr><tr><td>student_eval_loss</td><td>0.71113</td></tr><tr><td>student_eval_mae</td><td>0.2281</td></tr><tr><td>student_eval_model_preparation_time</td><td>0.0014</td></tr><tr><td>student_eval_precision</td><td>0.80151</td></tr><tr><td>student_eval_precision_extremely_negative</td><td>0.73643</td></tr><tr><td>student_eval_precision_extremely_positive</td><td>0.78406</td></tr><tr><td>student_eval_precision_negative</td><td>0.82504</td></tr><tr><td>student_eval_precision_neutral</td><td>0.81466</td></tr><tr><td>student_eval_precision_positive</td><td>0.84737</td></tr><tr><td>student_eval_quadratic_weighted_kappa</td><td>0.9127</td></tr><tr><td>student_eval_recall</td><td>0.82963</td></tr><tr><td>student_eval_recall_extremely_negative</td><td>0.92683</td></tr><tr><td>student_eval_recall_extremely_positive</td><td>0.92007</td></tr><tr><td>student_eval_recall_negative</td><td>0.71341</td></tr><tr><td>student_eval_recall_neutral</td><td>0.86039</td></tr><tr><td>student_eval_recall_positive</td><td>0.72746</td></tr><tr><td>student_eval_runtime</td><td>12.1725</td></tr><tr><td>student_eval_samples_per_second</td><td>281.29</td></tr><tr><td>student_eval_steps_per_second</td><td>4.436</td></tr><tr><td>teacher_eval_accuracy</td><td>0.84229</td></tr><tr><td>teacher_eval_accuracy_extremely_negative</td><td>0.9122</td></tr><tr><td>teacher_eval_accuracy_extremely_positive</td><td>0.90816</td></tr><tr><td>teacher_eval_accuracy_negative</td><td>0.76507</td></tr><tr><td>teacher_eval_accuracy_neutral</td><td>0.91047</td></tr><tr><td>teacher_eval_accuracy_positive</td><td>0.79036</td></tr><tr><td>teacher_eval_adjacent_accuracy</td><td>0.98102</td></tr><tr><td>teacher_eval_f1</td><td>0.84139</td></tr><tr><td>teacher_eval_f1_extremely_negative</td><td>0.85388</td></tr><tr><td>teacher_eval_f1_extremely_positive</td><td>0.87974</td></tr><tr><td>teacher_eval_f1_negative</td><td>0.81788</td></tr><tr><td>teacher_eval_f1_neutral</td><td>0.84567</td></tr><tr><td>teacher_eval_f1_positive</td><td>0.82948</td></tr><tr><td>teacher_eval_loss</td><td>0.61302</td></tr><tr><td>teacher_eval_mae</td><td>0.17903</td></tr><tr><td>teacher_eval_model_preparation_time</td><td>0.002</td></tr><tr><td>teacher_eval_precision</td><td>0.83926</td></tr><tr><td>teacher_eval_precision_extremely_negative</td><td>0.80258</td></tr><tr><td>teacher_eval_precision_extremely_positive</td><td>0.85304</td></tr><tr><td>teacher_eval_precision_negative</td><td>0.87853</td></tr><tr><td>teacher_eval_precision_neutral</td><td>0.78947</td></tr><tr><td>teacher_eval_precision_positive</td><td>0.87269</td></tr><tr><td>teacher_eval_quadratic_weighted_kappa</td><td>0.93296</td></tr><tr><td>teacher_eval_recall</td><td>0.85725</td></tr><tr><td>teacher_eval_recall_extremely_negative</td><td>0.9122</td></tr><tr><td>teacher_eval_recall_extremely_positive</td><td>0.90816</td></tr><tr><td>teacher_eval_recall_negative</td><td>0.76507</td></tr><tr><td>teacher_eval_recall_neutral</td><td>0.91047</td></tr><tr><td>teacher_eval_recall_positive</td><td>0.79036</td></tr><tr><td>teacher_eval_runtime</td><td>17.7504</td></tr><tr><td>teacher_eval_samples_per_second</td><td>192.897</td></tr><tr><td>teacher_eval_steps_per_second</td><td>3.042</td></tr><tr><td>temperature</td><td>2</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>0</td></tr><tr><td>train/grad_norm</td><td>0.22717</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1388</td></tr><tr><td>train_loss</td><td>0.38347</td></tr><tr><td>train_runtime</td><td>3895.0233</td></tr><tr><td>train_samples_per_second</td><td>64.184</td></tr><tr><td>train_steps_per_second</td><td>2.008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-to-distilroberta</strong> at: <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/ctzr5ddi</a><br> View project at: <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250820_073935-ctzr5ddi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KNOWLEDGE DISTILLATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 MODEL COMPRESSION:\")\n",
    "print(f\"Teacher Model Size: {teacher_size:.2f} MB\")\n",
    "print(f\"Student Model Size: {student_size:.2f} MB\")\n",
    "print(f\"Compression Ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n⚡ INFERENCE SPEED:\")\n",
    "print(f\"Teacher Model: {teacher_time*1000:.2f} ms\")\n",
    "print(f\"Student Model: {student_time*1000:.2f} ms\")\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n",
    "\n",
    "print(f\"\\n🎯 VALIDATION SET PERFORMANCE:\")\n",
    "print(f\"                      Teacher     Student     Difference\")\n",
    "print(f\"Accuracy:             {val_results_teacher['eval_accuracy']:.4f}      {val_results_student['eval_accuracy']:.4f}      {val_results_student['eval_accuracy'] - val_results_teacher['eval_accuracy']:+.4f}\")\n",
    "print(f\"F1-Score:             {val_results_teacher['eval_f1']:.4f}      {val_results_student['eval_f1']:.4f}      {val_results_student['eval_f1'] - val_results_teacher['eval_f1']:+.4f}\")\n",
    "print(f\"QWK:                  {val_results_teacher['eval_quadratic_weighted_kappa']:.4f}      {val_results_student['eval_quadratic_weighted_kappa']:.4f}      {val_results_student['eval_quadratic_weighted_kappa'] - val_results_teacher['eval_quadratic_weighted_kappa']:+.4f}\")\n",
    "print(f\"MAE:                  {val_results_teacher['eval_mae']:.4f}      {val_results_student['eval_mae']:.4f}      {val_results_student['eval_mae'] - val_results_teacher['eval_mae']:+.4f}\")\n",
    "\n",
    "print(f\"\\n🧪 TEST SET PERFORMANCE:\")\n",
    "print(f\"                      Teacher     Student     Difference\")\n",
    "print(f\"Accuracy:             {test_results_teacher['eval_accuracy']:.4f}      {test_results_student['eval_accuracy']:.4f}      {test_results_student['eval_accuracy'] - test_results_teacher['eval_accuracy']:+.4f}\")\n",
    "print(f\"F1-Score:             {test_results_teacher['eval_f1']:.4f}      {test_results_student['eval_f1']:.4f}      {test_results_student['eval_f1'] - test_results_teacher['eval_f1']:+.4f}\")\n",
    "print(f\"QWK:                  {test_results_teacher['eval_quadratic_weighted_kappa']:.4f}      {test_results_student['eval_quadratic_weighted_kappa']:.4f}      {test_results_student['eval_quadratic_weighted_kappa'] - test_results_teacher['eval_quadratic_weighted_kappa']:+.4f}\")\n",
    "print(f\"MAE:                  {test_results_teacher['eval_mae']:.4f}      {test_results_student['eval_mae']:.4f}      {test_results_student['eval_mae'] - test_results_teacher['eval_mae']:+.4f}\")\n",
    "\n",
    "# Calculate performance retention\n",
    "acc_retention = (test_results_student['eval_accuracy'] / test_results_teacher['eval_accuracy']) * 100\n",
    "f1_retention = (test_results_student['eval_f1'] / test_results_teacher['eval_f1']) * 100\n",
    "qwk_retention = (test_results_student['eval_quadratic_weighted_kappa'] / test_results_teacher['eval_quadratic_weighted_kappa']) * 100\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE RETENTION:\")\n",
    "print(f\"Accuracy Retention: {acc_retention:.1f}%\")\n",
    "print(f\"F1-Score Retention: {f1_retention:.1f}%\")\n",
    "print(f\"QWK Retention: {qwk_retention:.1f}%\")\n",
    "\n",
    "print(f\"\\n💡 DISTILLATION SUMMARY:\")\n",
    "print(f\"• Temperature: {TEMPERATURE}\")\n",
    "print(f\"• Alpha (hard loss weight): {ALPHA}\")\n",
    "print(f\"• Achieved {compression_ratio:.1f}x model compression with {speedup:.1f}x inference speedup\")\n",
    "print(f\"• Performance drop: {abs(test_results_student['eval_f1'] - test_results_teacher['eval_f1']):.4f} F1-score points\")\n",
    "print(f\"• Knowledge retention: {f1_retention:.1f}% of teacher's performance\")\n",
    "\n",
    "# Final wandb log with summary metrics\n",
    "wandb.log({\n",
    "    \"final_compression_ratio\": compression_ratio,\n",
    "    \"final_speedup\": speedup,\n",
    "    \"final_f1_retention\": f1_retention,\n",
    "    \"final_accuracy_retention\": acc_retention,\n",
    "    \"final_qwk_retention\": qwk_retention,\n",
    "    \"temperature\": TEMPERATURE,\n",
    "    \"alpha\": ALPHA\n",
    "})\n",
    "\n",
    "print(f\"\\n✅ Knowledge distillation complete! Results logged to W&B.\")\n",
    "\n",
    "# Save the distilled model\n",
    "trainer.save_model(\"./distilled_model_final\")\n",
    "print(f\"✅ Distilled model saved to ./distilled_model_final\")\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
