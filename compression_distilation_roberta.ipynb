{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation for COVID Tweet Sentiment Analysis\n",
    "\n",
    "This notebook implements knowledge distillation to compress a BERTweet sentiment analysis model into a smaller DistilRoBERTa student model.\n",
    "\n",
    "## Distillation Setup:\n",
    "- **Teacher Model**: `finiteautomata/bertweet-base-sentiment-analysis` (frozen)\n",
    "- **Student Model**: `distilroberta-base` with classification head\n",
    "- **Loss Function**: Combined hard target (CrossEntropy) + soft target (KL Divergence) loss\n",
    "- **Temperature**: T ≈ 2.0 for soft target computation\n",
    "- **Alpha**: α ≈ 0.5 for loss weighting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured for CPU-only execution\n",
      "Please restart the kernel and run all cells from the beginning\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Run this cell first to set up CPU-only environment\n",
    "import os\n",
    "\n",
    "# Set environment variables to force CPU usage and disable MPS\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"Environment configured for CPU-only execution\")\n",
    "print(\"Please restart the kernel and run all cells from the beginning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q evaluate\n",
    "%pip install -q emoji==0.6.0\n",
    "%pip install -q torch\n",
    "%pip install -q transformers\n",
    "%pip install -q accelerate\n",
    "%pip install -q wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taltzafrir/At_Bay/paz/deep/deep_learning_sentiment/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, cohen_kappa_score\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import evaluate\n",
    "import wandb\n",
    "import time\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon MPS\n"
     ]
    }
   ],
   "source": [
    "# Smart device selection for cross-platform GPU support\n",
    "def get_optimal_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "        return device\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple Silicon MPS\")\n",
    "        return device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "        return device\n",
    "\n",
    "device = get_optimal_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to wandb.ai account\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/taltzafrir/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mttzafrir\u001b[0m (\u001b[33mat-bay-data-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W&B login\n",
    "print('Logging to wandb.ai account')\n",
    "wandb.login(key=\"6dd13a6018f089606e418d323dd8b502f31bca4e\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "train = pd.read_csv(\"OOT_train.csv\", encoding='latin-1')\n",
    "val = pd.read_csv(\"OOT_val.csv\", encoding='latin-1')\n",
    "test = pd.read_csv(\"OOT_test.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the labels numerically from Sentiment\n",
    "ordinal_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "# Map to ordinal labels\n",
    "train[\"ordinal_label_id\"] = train[\"Sentiment\"].map(ordinal_mapping)\n",
    "val[\"ordinal_label_id\"] = val[\"Sentiment\"].map(ordinal_mapping)\n",
    "test[\"ordinal_label_id\"] = test[\"Sentiment\"].map(ordinal_mapping)\n",
    "\n",
    "# Define mapping between label id and sentiment for later use\n",
    "ordinal_label2id = ordinal_mapping\n",
    "ordinal_id2label = {v: k for k, v in ordinal_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Input Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the input string from multiple columns\n",
    "def build_augmented_input(row):\n",
    "    parts = []\n",
    "\n",
    "    if pd.notna(row.get('clean_tweet')):\n",
    "        parts.append(f\"{row['clean_tweet']}\")\n",
    "\n",
    "    if pd.notna(row.get('Location_standardized')) and row['Location_standardized'].lower() != 'unknown':\n",
    "        parts.append(f\"{row['Location_standardized']}\")\n",
    "\n",
    "    if pd.notna(row.get('TweetAt')):\n",
    "        parts.append(f\"{row['TweetAt']}\")\n",
    "\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# Apply to the DataFrames\n",
    "train['model_input'] = train.apply(build_augmented_input, axis=1)\n",
    "val['model_input'] = val.apply(build_augmented_input, axis=1)\n",
    "test['model_input'] = test.apply(build_augmented_input, axis=1)\n",
    "\n",
    "# Create new DataFrames with only what's needed for modeling\n",
    "formatted_train = train[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_val = val[['model_input', 'ordinal_label_id']].copy()\n",
    "formatted_test = test[['model_input', 'ordinal_label_id']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "ordinal_label_id\n",
      "0     5175\n",
      "1     9230\n",
      "2     6784\n",
      "3    10140\n",
      "4     5845\n",
      "Name: count, dtype: int64\n",
      "Class 0: 5000 samples (undersampled)\n",
      "Class 1: 5000 samples (undersampled)\n",
      "Class 2: 5000 samples (undersampled)\n",
      "Class 3: 5000 samples (undersampled)\n",
      "Class 4: 5000 samples (undersampled)\n",
      "Balanced dataset: 25000 total samples\n",
      "New distribution:\n",
      "ordinal_label_id\n",
      "0    5000\n",
      "1    5000\n",
      "2    5000\n",
      "3    5000\n",
      "4    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def balance_dataset(df, target_samples_per_class=5000):\n",
    "    \"\"\"Balance dataset by undersampling\"\"\"\n",
    "    balanced_dfs = []\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    print(df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    for class_id in range(5):\n",
    "        class_data = df[df['ordinal_label_id'] == class_id]\n",
    "\n",
    "        if len(class_data) > target_samples_per_class:\n",
    "            class_data = class_data.sample(n=target_samples_per_class, random_state=42)\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (undersampled)\")\n",
    "        else:\n",
    "            print(f\"Class {class_id}: {len(class_data)} samples (kept all)\")\n",
    "\n",
    "        balanced_dfs.append(class_data)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "    print(f\"Balanced dataset: {len(balanced_df)} total samples\")\n",
    "    print(\"New distribution:\")\n",
    "    print(balanced_df['ordinal_label_id'].value_counts().sort_index())\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing to training data\n",
    "formatted_train = balance_dataset(formatted_train, target_samples_per_class=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "### Teacher Model (BERTweet) - Frozen\n",
    "### Student Model (DistilRoBERTa) - Trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: cardiffnlp/twitter-roberta-base-sentiment\n",
      "Student Model: distilroberta-base\n"
     ]
    }
   ],
   "source": [
    "# Teacher model configuration\n",
    "MODEL_TYPE = 'roberta'\n",
    "teacher_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "teacher_model_path = \"./HuggingFace/roberta/best_roberta_model_so_far\"\n",
    "teacher_model_file = \"model_roberta.pt\"\n",
    "\n",
    "# Student model configuration\n",
    "student_model_name = \"distilroberta-base\"\n",
    "\n",
    "print(f\"Teacher Model: {teacher_model_name}\")\n",
    "print(f\"Student Model: {student_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Teacher Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading teacher model from best checkpoint...\n",
      "Teacher model loaded and frozen!\n"
     ]
    }
   ],
   "source": [
    "# Load the best teacher model from hyperparameter tuning\n",
    "print(\"Loading teacher model from best checkpoint...\")\n",
    "teacher_model = torch.load(os.path.join(teacher_model_path, teacher_model_file), map_location=device, weights_only=False)\n",
    "teacher_model.eval()  # Set to evaluation mode\n",
    "teacher_model.to(device)\n",
    "\n",
    "# Freeze teacher model parameters\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"Teacher model loaded and frozen!\")\n",
    "\n",
    "# Load teacher tokenizer\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Student Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model initialized with 82,122,245 trainable parameters\n",
      "Teacher model has 124,649,477 total parameters (frozen)\n"
     ]
    }
   ],
   "source": [
    "# Initialize student model with classification head\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student_model_name,\n",
    "    num_labels=5,\n",
    "    id2label=ordinal_id2label,\n",
    "    label2id=ordinal_label2id\n",
    ")\n",
    "student_model.to(device)\n",
    "\n",
    "# Load student tokenizer\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
    "\n",
    "print(f\"Student model initialized with {sum(p.numel() for p in student_model.parameters() if p.requires_grad):,} trainable parameters\")\n",
    "print(f\"Teacher model has {sum(p.numel() for p in teacher_model.parameters()):,} total parameters (frozen)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset for Knowledge Distillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationDataset(Dataset):\n",
    "    \"\"\"Custom dataset for knowledge distillation that stores raw text\"\"\"\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return raw text and label - tokenization will happen in the collate function\n",
    "        return {\n",
    "            'text': self.texts[idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def create_distillation_collate_fn(student_tokenizer, teacher_tokenizer, device, max_length=128):\n",
    "    \"\"\"Create a collate function that tokenizes for both student and teacher\"\"\"\n",
    "    def collate_fn(batch):\n",
    "        texts = [item['text'] for item in batch]\n",
    "        labels = torch.stack([item['labels'] for item in batch])\n",
    "        \n",
    "        # Tokenize for student\n",
    "        student_encodings = student_tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize for teacher\n",
    "        teacher_encodings = teacher_tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move all tensors to the correct device\n",
    "        return {\n",
    "            'student_input_ids': student_encodings['input_ids'].to(device),\n",
    "            'student_attention_mask': student_encodings['attention_mask'].to(device),\n",
    "            'teacher_input_ids': teacher_encodings['input_ids'].to(device),\n",
    "            'teacher_attention_mask': teacher_encodings['attention_mask'].to(device),\n",
    "            'labels': labels.to(device)\n",
    "        }\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 25000\n",
      "Validation dataset size: 4357\n",
      "Test dataset size: 3424\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to lists\n",
    "train_texts = formatted_train['model_input'].tolist()\n",
    "val_texts = formatted_val['model_input'].tolist()\n",
    "test_texts = formatted_test['model_input'].tolist()\n",
    "\n",
    "train_labels = formatted_train['ordinal_label_id'].tolist()\n",
    "val_labels = formatted_val['ordinal_label_id'].tolist()\n",
    "test_labels = formatted_test['ordinal_label_id'].tolist()\n",
    "\n",
    "# Create distillation datasets\n",
    "train_dataset = DistillationDataset(train_texts, train_labels)\n",
    "val_dataset = DistillationDataset(val_texts, val_labels)\n",
    "test_dataset = DistillationDataset(test_texts, test_labels)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_detailed_metrics(eval_pred):\n",
    "    \"\"\"Enhanced metrics using HuggingFace Evaluate library\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Load HuggingFace metrics (cached after first load)\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "    # Compute standard classification metrics\n",
    "    results = {}\n",
    "\n",
    "    # Basic metrics\n",
    "    results.update(accuracy_metric.compute(predictions=predictions, references=labels))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
    "    results.update(precision_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "    results.update(recall_metric.compute(predictions=predictions, references=labels, average='macro'))\n",
    "\n",
    "    # Per-class F1 scores\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "    for i, class_name in enumerate(['extremely_negative', 'negative', 'neutral', 'positive', 'extremely_positive']):\n",
    "        results[f'f1_{class_name}'] = f1_per_class[i]\n",
    "\n",
    "        # Per-class precision and recall\n",
    "        precision_per_class = precision_score(labels, predictions, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, predictions, average=None, zero_division=0)\n",
    "        results[f'precision_{class_name}'] = precision_per_class[i]\n",
    "        results[f'recall_{class_name}'] = recall_per_class[i]\n",
    "\n",
    "        # Per-class accuracy\n",
    "        class_mask = (labels == i)\n",
    "        if class_mask.sum() > 0:\n",
    "            results[f'accuracy_{class_name}'] = accuracy_score(labels[class_mask], predictions[class_mask])\n",
    "        else:\n",
    "            results[f'accuracy_{class_name}'] = 0.0\n",
    "\n",
    "    # Custom ordinal metrics\n",
    "    results['mae'] = np.mean(np.abs(predictions - labels))\n",
    "    results['adjacent_accuracy'] = np.sum(np.abs(predictions - labels) <= 1) / len(labels)\n",
    "\n",
    "    # Quadratic Weighted Kappa\n",
    "    try:\n",
    "        qwk = cohen_kappa_score(labels, predictions, weights='quadratic')\n",
    "        results['quadratic_weighted_kappa'] = qwk\n",
    "    except:\n",
    "        results['quadratic_weighted_kappa'] = 0.0\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distillation Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation Temperature: 2.0\n",
      "Alpha (hard loss weight): 0.5\n",
      "Soft loss weight: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Knowledge distillation hyperparameters\n",
    "TEMPERATURE = 2.0  # Temperature for soft targets\n",
    "ALPHA = 0.5  # Weight for hard target loss (1-alpha for soft target loss)\n",
    "\n",
    "print(f\"Distillation Temperature: {TEMPERATURE}\")\n",
    "print(f\"Alpha (hard loss weight): {ALPHA}\")\n",
    "print(f\"Soft loss weight: {1-ALPHA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Distillation Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    \"\"\"Custom trainer for knowledge distillation\"\"\"\n",
    "    \n",
    "    def __init__(self, teacher_model, temperature, alpha, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Compute combined knowledge distillation loss\n",
    "        \"\"\"\n",
    "        # Check if we're in distillation mode (training) or regular mode (evaluation)\n",
    "        if 'student_input_ids' in inputs and inputs['student_input_ids'] is not None:\n",
    "            # Distillation mode - use both teacher and student\n",
    "            # Get student predictions\n",
    "            student_outputs = model(\n",
    "                input_ids=inputs.get('student_input_ids'),\n",
    "                attention_mask=inputs.get('student_attention_mask')\n",
    "            )\n",
    "            student_logits = student_outputs.logits\n",
    "            \n",
    "            # Get teacher predictions (no gradient)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = self.teacher_model(\n",
    "                    input_ids=inputs.get('teacher_input_ids'),\n",
    "                    attention_mask=inputs.get('teacher_attention_mask')\n",
    "                )\n",
    "                teacher_logits = teacher_outputs.logits\n",
    "            \n",
    "            # Get labels\n",
    "            labels = inputs.get('labels')\n",
    "            \n",
    "            # Hard target loss (CrossEntropy)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            hard_loss = loss_fct(student_logits, labels)\n",
    "            \n",
    "            # Soft target loss (KL Divergence)\n",
    "            student_log_probs = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "            teacher_probs = F.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "            \n",
    "            # KL Divergence loss\n",
    "            soft_loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean')\n",
    "            soft_loss = soft_loss * (self.temperature ** 2)\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = self.alpha * hard_loss + (1 - self.alpha) * soft_loss\n",
    "            \n",
    "            return (loss, student_outputs) if return_outputs else loss\n",
    "        \n",
    "        else:\n",
    "            # Regular mode - use standard loss computation for evaluation\n",
    "            student_outputs = model(\n",
    "                input_ids=inputs.get('input_ids'),\n",
    "                attention_mask=inputs.get('attention_mask'),\n",
    "                labels=inputs.get('labels')\n",
    "            )\n",
    "            \n",
    "            return (student_outputs.loss, student_outputs) if return_outputs else student_outputs.loss\n",
    "        \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        Override prediction step to use student inputs only\n",
    "        \"\"\"\n",
    "        # Check if we have the expected distillation inputs\n",
    "        if 'student_input_ids' in inputs and inputs['student_input_ids'] is not None:\n",
    "            # During training/evaluation with distillation data\n",
    "            student_inputs = {\n",
    "                'input_ids': inputs.get('student_input_ids'),\n",
    "                'attention_mask': inputs.get('student_attention_mask'),\n",
    "                'labels': inputs.get('labels')\n",
    "            }\n",
    "        else:\n",
    "            # Fallback for regular evaluation (when using SimpleDataset)\n",
    "            student_inputs = {\n",
    "                'input_ids': inputs.get('input_ids'),\n",
    "                'attention_mask': inputs.get('attention_mask'),\n",
    "                'labels': inputs.get('labels')\n",
    "            }\n",
    "        \n",
    "        # Call parent's prediction_step with student inputs\n",
    "        return super().prediction_step(model, student_inputs, prediction_loss_only, ignore_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Logger Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationMetricsLogger(TrainerCallback):\n",
    "    \"\"\"Callback to log detailed metrics during distillation\"\"\"\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None or not wandb.run:\n",
    "            return\n",
    "        \n",
    "        # Only log when we have evaluation metrics\n",
    "        if 'eval_loss' in logs:\n",
    "            current_epoch = int(state.epoch) if state.epoch else 0\n",
    "            \n",
    "            # Get training loss from state history\n",
    "            train_loss = 0\n",
    "            if state.log_history:\n",
    "                for log_entry in reversed(state.log_history):\n",
    "                    if 'loss' in log_entry:\n",
    "                        train_loss = log_entry['loss']\n",
    "                        break\n",
    "            \n",
    "            # Detailed metrics\n",
    "            detailed_metrics = {\n",
    "                \"Epoch\": current_epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Validation Loss\": logs.get('eval_loss', 0),\n",
    "                \"Validation Accuracy\": logs.get('eval_accuracy', 0),\n",
    "                \"Validation F1\": logs.get('eval_f1', 0),\n",
    "                \"Validation MAE\": logs.get('eval_mae', 0),\n",
    "                \"Validation QWK\": logs.get('eval_quadratic_weighted_kappa', 0),\n",
    "                \"Learning_Rate\": logs.get('learning_rate', args.learning_rate),\n",
    "            }\n",
    "            \n",
    "            # Log to WandB\n",
    "            wandb.log(detailed_metrics)\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"Epoch {current_epoch}: \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {logs.get('eval_loss', 0):.4f}, \"\n",
    "                  f\"Val F1: {logs.get('eval_f1', 0):.4f}, \"\n",
    "                  f\"QWK: {logs.get('eval_quadratic_weighted_kappa', 0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/taltzafrir/At_Bay/paz/deep/deep_learning_sentiment/wandb/run-20250820_004201-e407tgiz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz' target=\"_blank\">bertweet-to-distilroberta</a></strong> to <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1fdaed970>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize W&B for tracking\n",
    "wandb.init(\n",
    "    project=\"covid-tweet-sentiment-distillation\",\n",
    "    name=f\"{MODEL_TYPE}-to-distilroberta\",\n",
    "    config={\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"teacher_model\": teacher_model_name,\n",
    "        \"student_model\": student_model_name,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"num_epochs\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments with GPU optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilled_model\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16 if device.type == \"cpu\" else 32,  # Smaller batch for CPU\n",
    "    per_device_eval_batch_size=32 if device.type == \"cpu\" else 64,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_quadratic_weighted_kappa\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"wandb\",\n",
    "    fp16=device.type == \"cuda\",  # Enable FP16 only for CUDA\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=device.type != \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Distillation Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation trainer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create custom collate function\n",
    "collate_fn = collate_fn = create_distillation_collate_fn(student_tokenizer, teacher_tokenizer, device)\n",
    "\n",
    "# Create distillation trainer\n",
    "trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA,\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_detailed_metrics,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=2),\n",
    "        DistillationMetricsLogger(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# GPU memory optimization\n",
    "if device.type in [\"cuda\", \"mps\"]:\n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    student_model.gradient_checkpointing_enable()\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        # CUDA-specific optimizations\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"Distillation trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Knowledge Distillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting knowledge distillation training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 1:11:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Extremely Negative</th>\n",
       "      <th>Precision Extremely Negative</th>\n",
       "      <th>Recall Extremely Negative</th>\n",
       "      <th>Accuracy Extremely Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Accuracy Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>Accuracy Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Accuracy Positive</th>\n",
       "      <th>F1 Extremely Positive</th>\n",
       "      <th>Precision Extremely Positive</th>\n",
       "      <th>Recall Extremely Positive</th>\n",
       "      <th>Accuracy Extremely Positive</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Adjacent Accuracy</th>\n",
       "      <th>Quadratic Weighted Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.704384</td>\n",
       "      <td>0.701395</td>\n",
       "      <td>0.724734</td>\n",
       "      <td>0.706781</td>\n",
       "      <td>0.669082</td>\n",
       "      <td>0.814706</td>\n",
       "      <td>0.567623</td>\n",
       "      <td>0.567623</td>\n",
       "      <td>0.677950</td>\n",
       "      <td>0.607979</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.783908</td>\n",
       "      <td>0.801410</td>\n",
       "      <td>0.767154</td>\n",
       "      <td>0.767154</td>\n",
       "      <td>0.631670</td>\n",
       "      <td>0.706796</td>\n",
       "      <td>0.570980</td>\n",
       "      <td>0.570980</td>\n",
       "      <td>0.768190</td>\n",
       "      <td>0.692777</td>\n",
       "      <td>0.862025</td>\n",
       "      <td>0.862025</td>\n",
       "      <td>0.373881</td>\n",
       "      <td>0.931834</td>\n",
       "      <td>0.830954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.743583</td>\n",
       "      <td>0.729401</td>\n",
       "      <td>0.722631</td>\n",
       "      <td>0.729979</td>\n",
       "      <td>0.758834</td>\n",
       "      <td>0.725766</td>\n",
       "      <td>0.609179</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.605541</td>\n",
       "      <td>0.763727</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.850114</td>\n",
       "      <td>0.864959</td>\n",
       "      <td>0.835771</td>\n",
       "      <td>0.835771</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.735832</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.782284</td>\n",
       "      <td>0.676199</td>\n",
       "      <td>0.927848</td>\n",
       "      <td>0.927848</td>\n",
       "      <td>0.338536</td>\n",
       "      <td>0.941244</td>\n",
       "      <td>0.862074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.564406</td>\n",
       "      <td>0.811797</td>\n",
       "      <td>0.812561</td>\n",
       "      <td>0.815623</td>\n",
       "      <td>0.814478</td>\n",
       "      <td>0.801164</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.846311</td>\n",
       "      <td>0.846311</td>\n",
       "      <td>0.753904</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.864560</td>\n",
       "      <td>0.867497</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.802011</td>\n",
       "      <td>0.790999</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.846049</td>\n",
       "      <td>0.915929</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>0.238008</td>\n",
       "      <td>0.954556</td>\n",
       "      <td>0.892980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.816534</td>\n",
       "      <td>0.826372</td>\n",
       "      <td>0.819939</td>\n",
       "      <td>0.814141</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.825820</td>\n",
       "      <td>0.771320</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.784152</td>\n",
       "      <td>0.827526</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.855457</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.226762</td>\n",
       "      <td>0.959376</td>\n",
       "      <td>0.903685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.765664</td>\n",
       "      <td>0.762996</td>\n",
       "      <td>0.759187</td>\n",
       "      <td>0.793921</td>\n",
       "      <td>0.746732</td>\n",
       "      <td>0.620924</td>\n",
       "      <td>0.936475</td>\n",
       "      <td>0.936475</td>\n",
       "      <td>0.676593</td>\n",
       "      <td>0.743455</td>\n",
       "      <td>0.620765</td>\n",
       "      <td>0.620765</td>\n",
       "      <td>0.838968</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.741612</td>\n",
       "      <td>0.834314</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.822134</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.921519</td>\n",
       "      <td>0.284599</td>\n",
       "      <td>0.957769</td>\n",
       "      <td>0.887736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.587084</td>\n",
       "      <td>0.827863</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.827812</td>\n",
       "      <td>0.834648</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.864754</td>\n",
       "      <td>0.864754</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>0.859099</td>\n",
       "      <td>0.871528</td>\n",
       "      <td>0.847019</td>\n",
       "      <td>0.847019</td>\n",
       "      <td>0.810597</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>0.877215</td>\n",
       "      <td>0.877215</td>\n",
       "      <td>0.210466</td>\n",
       "      <td>0.966261</td>\n",
       "      <td>0.909745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.730180</td>\n",
       "      <td>0.794354</td>\n",
       "      <td>0.791570</td>\n",
       "      <td>0.790945</td>\n",
       "      <td>0.815442</td>\n",
       "      <td>0.807116</td>\n",
       "      <td>0.743103</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.806084</td>\n",
       "      <td>0.695082</td>\n",
       "      <td>0.695082</td>\n",
       "      <td>0.848652</td>\n",
       "      <td>0.830819</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.867267</td>\n",
       "      <td>0.758859</td>\n",
       "      <td>0.845043</td>\n",
       "      <td>0.688627</td>\n",
       "      <td>0.688627</td>\n",
       "      <td>0.822750</td>\n",
       "      <td>0.729677</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.238237</td>\n",
       "      <td>0.971081</td>\n",
       "      <td>0.909533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.701074</td>\n",
       "      <td>0.808813</td>\n",
       "      <td>0.806980</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.836435</td>\n",
       "      <td>0.801126</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.779176</td>\n",
       "      <td>0.817527</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.849833</td>\n",
       "      <td>0.840484</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.859393</td>\n",
       "      <td>0.769684</td>\n",
       "      <td>0.830909</td>\n",
       "      <td>0.716863</td>\n",
       "      <td>0.716863</td>\n",
       "      <td>0.832957</td>\n",
       "      <td>0.751527</td>\n",
       "      <td>0.934177</td>\n",
       "      <td>0.934177</td>\n",
       "      <td>0.223319</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.913190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.745446</td>\n",
       "      <td>0.799403</td>\n",
       "      <td>0.797358</td>\n",
       "      <td>0.793488</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.811439</td>\n",
       "      <td>0.719493</td>\n",
       "      <td>0.930328</td>\n",
       "      <td>0.930328</td>\n",
       "      <td>0.741599</td>\n",
       "      <td>0.789149</td>\n",
       "      <td>0.699454</td>\n",
       "      <td>0.699454</td>\n",
       "      <td>0.849858</td>\n",
       "      <td>0.856164</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.772554</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.834194</td>\n",
       "      <td>0.762854</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.237549</td>\n",
       "      <td>0.967868</td>\n",
       "      <td>0.907128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.805848</td>\n",
       "      <td>0.804034</td>\n",
       "      <td>0.826150</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.764912</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.852260</td>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.869516</td>\n",
       "      <td>0.869516</td>\n",
       "      <td>0.779232</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>0.723922</td>\n",
       "      <td>0.723922</td>\n",
       "      <td>0.833617</td>\n",
       "      <td>0.755922</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.222860</td>\n",
       "      <td>0.973147</td>\n",
       "      <td>0.914032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.9558, Val Loss: 0.7747, Val F1: 0.7014, QWK: 0.8310\n",
      "Epoch 2: Train Loss: 0.6603, Val Loss: 0.7436, Val F1: 0.7226, QWK: 0.8621\n",
      "Epoch 3: Train Loss: 0.5008, Val Loss: 0.5644, Val F1: 0.8126, QWK: 0.8930\n",
      "Epoch 4: Train Loss: 0.3917, Val Loss: 0.5729, Val F1: 0.8160, QWK: 0.9037\n",
      "Epoch 5: Train Loss: 0.3209, Val Loss: 0.7524, Val F1: 0.7630, QWK: 0.8877\n",
      "Epoch 6: Train Loss: 0.2630, Val Loss: 0.5871, Val F1: 0.8277, QWK: 0.9097\n",
      "Epoch 7: Train Loss: 0.2306, Val Loss: 0.7302, Val F1: 0.7916, QWK: 0.9095\n",
      "Epoch 8: Train Loss: 0.1952, Val Loss: 0.7011, Val F1: 0.8070, QWK: 0.9132\n",
      "Epoch 9: Train Loss: 0.1461, Val Loss: 0.7454, Val F1: 0.7974, QWK: 0.9071\n",
      "Epoch 10: Train Loss: 0.1400, Val Loss: 0.7295, Val F1: 0.8058, QWK: 0.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7820, training_loss=0.4122857236496323, metrics={'train_runtime': 4311.2458, 'train_samples_per_second': 57.988, 'train_steps_per_second': 1.814, 'total_flos': 0.0, 'train_loss': 0.4122857236496323, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the student model with knowledge distillation\n",
    "print(\"Starting knowledge distillation training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Size Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Size Comparison:\n",
      "Teacher Model Size: 475.51 MB\n",
      "Student Model Size: 313.28 MB\n",
      "Compression Ratio: 1.52x\n",
      "Size Reduction: 34.1%\n"
     ]
    }
   ],
   "source": [
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / (1024 * 1024)\n",
    "    return size_mb\n",
    "\n",
    "# Compare model sizes\n",
    "teacher_size = get_model_size(teacher_model)\n",
    "student_size = get_model_size(student_model)\n",
    "compression_ratio = teacher_size / student_size\n",
    "\n",
    "print(f\"\\nModel Size Comparison:\")\n",
    "print(f\"Teacher Model Size: {teacher_size:.2f} MB\")\n",
    "print(f\"Student Model Size: {student_size:.2f} MB\")\n",
    "print(f\"Compression Ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Speed Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference speed...\n",
      "\n",
      "Inference Speed Comparison:\n",
      "Teacher Model: 15.36 ± 0.27 ms\n",
      "Student Model: 8.66 ± 0.16 ms\n",
      "Speedup: 1.77x\n"
     ]
    }
   ],
   "source": [
    "def measure_inference_time(model, tokenizer, sample_text, num_runs=50):\n",
    "    \"\"\"Measure average inference time for a model\"\"\"\n",
    "    model.eval()\n",
    "    times = []\n",
    "    \n",
    "    # Warm-up runs\n",
    "    for _ in range(5):\n",
    "        inputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "    \n",
    "    # Actual timing runs\n",
    "    for _ in range(num_runs):\n",
    "        inputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# Test inference speed\n",
    "sample_tweet = \"COVID-19 vaccines have been crucial in reducing hospitalizations and saving lives worldwide.\"\n",
    "\n",
    "print(\"Measuring inference speed...\")\n",
    "teacher_time, teacher_std = measure_inference_time(teacher_model, teacher_tokenizer, sample_tweet)\n",
    "student_time, student_std = measure_inference_time(student_model, student_tokenizer, sample_tweet)\n",
    "\n",
    "speedup = teacher_time / student_time\n",
    "\n",
    "print(f\"\\nInference Speed Comparison:\")\n",
    "print(f\"Teacher Model: {teacher_time*1000:.2f} ± {teacher_std*1000:.2f} ms\")\n",
    "print(f\"Student Model: {student_time*1000:.2f} ± {student_std*1000:.2f} ms\")\n",
    "print(f\"Speedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Teacher Model on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_35732/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Student Model on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_35732/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Teacher Model on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_35732/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Student Model on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/7c5v880d4_lg0yc07pfjklsh0000gn/T/ipykernel_35732/41261118.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, tokenizer, dataset, model_name):\n",
    "    \"\"\"Evaluate a model on a given dataset\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create regular dataset for single-model evaluation\n",
    "    eval_encodings = tokenizer(\n",
    "        [dataset[i]['text'] for i in range(len(dataset))],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=128,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "    \n",
    "    class SimpleDataset(Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "    \n",
    "    eval_dataset = SimpleDataset(eval_encodings, [dataset[i]['labels'].item() for i in range(len(dataset))])\n",
    "    \n",
    "    # Create trainer for evaluation\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=\"./temp\",\n",
    "            per_device_eval_batch_size=64,\n",
    "            remove_unused_columns=False,\n",
    "            dataloader_num_workers=0,\n",
    "        ),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_detailed_metrics,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    results = eval_trainer.evaluate(eval_dataset)\n",
    "    \n",
    "    # Format results with model name prefix\n",
    "    formatted_results = {}\n",
    "    for key, value in results.items():\n",
    "        new_key = f\"{model_name}_{key}\"\n",
    "        formatted_results[new_key] = value\n",
    "    \n",
    "    return results, formatted_results\n",
    "\n",
    "# Evaluate both models on validation set\n",
    "print(\"Evaluating Teacher Model on Validation Set...\")\n",
    "val_results_teacher, val_formatted_teacher = evaluate_model(teacher_model, teacher_tokenizer, val_dataset, \"teacher\")\n",
    "\n",
    "print(\"\\nEvaluating Student Model on Validation Set...\")\n",
    "val_results_student, val_formatted_student = evaluate_model(student_model, student_tokenizer, val_dataset, \"student\")\n",
    "\n",
    "# Evaluate both models on test set\n",
    "print(\"\\nEvaluating Teacher Model on Test Set...\")\n",
    "test_results_teacher, test_formatted_teacher = evaluate_model(teacher_model, teacher_tokenizer, test_dataset, \"teacher\")\n",
    "\n",
    "print(\"\\nEvaluating Student Model on Test Set...\")\n",
    "test_results_student, test_formatted_student = evaluate_model(student_model, student_tokenizer, test_dataset, \"student\")\n",
    "\n",
    "# Log to wandb\n",
    "wandb.log({\n",
    "    **val_formatted_teacher,\n",
    "    **val_formatted_student,\n",
    "    **test_formatted_teacher,\n",
    "    **test_formatted_student\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Results Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KNOWLEDGE DISTILLATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 MODEL COMPRESSION:\n",
      "Teacher Model Size: 475.51 MB\n",
      "Student Model Size: 313.28 MB\n",
      "Compression Ratio: 1.52x\n",
      "Size Reduction: 34.1%\n",
      "\n",
      "⚡ INFERENCE SPEED:\n",
      "Teacher Model: 15.36 ms\n",
      "Student Model: 8.66 ms\n",
      "Speedup: 1.77x\n",
      "\n",
      "🎯 VALIDATION SET PERFORMANCE:\n",
      "                      Teacher     Student     Difference\n",
      "Accuracy:             0.8393      0.8079      -0.0314\n",
      "F1-Score:             0.8388      0.8058      -0.0330\n",
      "QWK:                  0.9297      0.9140      -0.0157\n",
      "MAE:                  0.1820      0.2229      +0.0409\n",
      "\n",
      "🧪 TEST SET PERFORMANCE:\n",
      "                      Teacher     Student     Difference\n",
      "Accuracy:             0.8338      0.8119      -0.0219\n",
      "F1-Score:             0.8330      0.8098      -0.0232\n",
      "QWK:                  0.9248      0.9158      -0.0090\n",
      "MAE:                  0.1930      0.2208      +0.0277\n",
      "\n",
      "🎯 PERFORMANCE RETENTION:\n",
      "Accuracy Retention: 97.4%\n",
      "F1-Score Retention: 97.2%\n",
      "QWK Retention: 99.0%\n",
      "\n",
      "💡 DISTILLATION SUMMARY:\n",
      "• Temperature: 2.0\n",
      "• Alpha (hard loss weight): 0.5\n",
      "• Achieved 1.5x model compression with 1.8x inference speedup\n",
      "• Performance drop: 0.0232 F1-score points\n",
      "• Knowledge retention: 97.2% of teacher's performance\n",
      "\n",
      "✅ Knowledge distillation complete! Results logged to W&B.\n",
      "✅ Distilled model saved to ./distilled_model_final\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Learning_Rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▇▇▄█▆▇▆▇</td></tr><tr><td>Validation F1</td><td>▁▂▇▇▄█▆▇▆▇</td></tr><tr><td>Validation Loss</td><td>█▇▁▁▇▂▇▆▇▆</td></tr><tr><td>Validation MAE</td><td>█▆▂▂▄▁▂▂▂▂</td></tr><tr><td>Validation QWK</td><td>▁▄▆▇▆███▇█</td></tr><tr><td>alpha</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▂▇▇▄▇▆▆▆▆█▆█▇</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>▁▇▆▆█▇▇▇█▇▇▇▇▇</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>▄▇▁▇▇▅██▇▇▆▇▆█</td></tr><tr><td>eval/accuracy_negative</td><td>█▁██▄█▆▇▆▆█▆▇▆</td></tr><tr><td>eval/accuracy_neutral</td><td>▁▅▆▆▄▅▆▆▅▆▇▆█▇</td></tr><tr><td>eval/accuracy_positive</td><td>▁▃█▆▄█▄▅▅▅█▅▇▆</td></tr><tr><td>eval/adjacent_accuracy</td><td>▁▂▄▅▅▆▇▇▆▇█▇▇▇</td></tr><tr><td>eval/f1</td><td>▁▂▇▇▄▇▆▆▆▆█▆█▇</td></tr><tr><td>eval/f1_extremely_negative</td><td>▁▃▆▇▄▇▆▇▇▇█▇█▇</td></tr><tr><td>eval/f1_extremely_positive</td><td>▁▂▅▆▄▆▄▅▅▅█▅▇▆</td></tr><tr><td>eval/f1_negative</td><td>▄▁▆▇▄▇▆▇▆▇█▇█▇</td></tr><tr><td>eval/f1_neutral</td><td>▁▆██▅▇▆▆▆▇▅▇▅▆</td></tr><tr><td>eval/f1_positive</td><td>▁▃▇▆▅▇▅▆▆▆█▆█▆</td></tr><tr><td>eval/loss</td><td>█▇▁▁▇▂▇▆▇▆▂▆▂▆</td></tr><tr><td>eval/mae</td><td>█▇▃▃▅▂▃▃▃▂▁▂▁▂</td></tr><tr><td>eval/model_preparation_time</td><td>▆▁█▁</td></tr><tr><td>eval/precision</td><td>▁▁▇▇▃▇▅▆▅▆█▆█▆</td></tr><tr><td>eval/precision_extremely_negative</td><td>▇▁▆▇▁▇▅▇▄▆█▆▇▅</td></tr><tr><td>eval/precision_extremely_positive</td><td>▁▁█▅▃▆▃▃▄▃▇▃▆▄</td></tr><tr><td>eval/precision_negative</td><td>▁▅▅▆▅▆▇▇▆▇▇▇█▇</td></tr><tr><td>eval/precision_neutral</td><td>▂▇██▇█▅▅▇▅▁▅▁▄</td></tr><tr><td>eval/precision_positive</td><td>▁▂▅▆▆▆▇▆▇▇█▇██</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>▁▃▅▆▅▇▇▇▆▇█▇█▇</td></tr><tr><td>eval/recall</td><td>▁▄▆▇▅▇▆▇▇▇█▇█▇</td></tr><tr><td>eval/recall_extremely_negative</td><td>▁▇▆▆█▇▇▇█▇▇▇▇▇</td></tr><tr><td>eval/recall_extremely_positive</td><td>▄▇▁▇▇▅██▇▇▆▇▆█</td></tr><tr><td>eval/recall_negative</td><td>█▁██▄█▆▇▆▆█▆▇▆</td></tr><tr><td>eval/recall_neutral</td><td>▁▅▆▆▄▅▆▆▅▆▇▆█▇</td></tr><tr><td>eval/recall_positive</td><td>▁▃█▆▄█▄▅▅▅█▅▇▆</td></tr><tr><td>eval/runtime</td><td>█▃▄▃▄▅▅▅▃▃█▂▆▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▆▆▆▆▄▄▄▇▇▂█▁▇</td></tr><tr><td>eval/steps_per_second</td><td>▂▆▆▆▆▄▄▄▇▇▂█▁▇</td></tr><tr><td>final_accuracy_retention</td><td>▁</td></tr><tr><td>final_compression_ratio</td><td>▁</td></tr><tr><td>final_f1_retention</td><td>▁</td></tr><tr><td>final_qwk_retention</td><td>▁</td></tr><tr><td>final_speedup</td><td>▁</td></tr><tr><td>student_eval_accuracy</td><td>▁</td></tr><tr><td>student_eval_accuracy_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_accuracy_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_accuracy_negative</td><td>▁</td></tr><tr><td>student_eval_accuracy_neutral</td><td>▁</td></tr><tr><td>student_eval_accuracy_positive</td><td>▁</td></tr><tr><td>student_eval_adjacent_accuracy</td><td>▁</td></tr><tr><td>student_eval_f1</td><td>▁</td></tr><tr><td>student_eval_f1_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_f1_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_f1_negative</td><td>▁</td></tr><tr><td>student_eval_f1_neutral</td><td>▁</td></tr><tr><td>student_eval_f1_positive</td><td>▁</td></tr><tr><td>student_eval_loss</td><td>▁</td></tr><tr><td>student_eval_mae</td><td>▁</td></tr><tr><td>student_eval_model_preparation_time</td><td>▁</td></tr><tr><td>student_eval_precision</td><td>▁</td></tr><tr><td>student_eval_precision_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_precision_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_precision_negative</td><td>▁</td></tr><tr><td>student_eval_precision_neutral</td><td>▁</td></tr><tr><td>student_eval_precision_positive</td><td>▁</td></tr><tr><td>student_eval_quadratic_weighted_kappa</td><td>▁</td></tr><tr><td>student_eval_recall</td><td>▁</td></tr><tr><td>student_eval_recall_extremely_negative</td><td>▁</td></tr><tr><td>student_eval_recall_extremely_positive</td><td>▁</td></tr><tr><td>student_eval_recall_negative</td><td>▁</td></tr><tr><td>student_eval_recall_neutral</td><td>▁</td></tr><tr><td>student_eval_recall_positive</td><td>▁</td></tr><tr><td>student_eval_runtime</td><td>▁</td></tr><tr><td>student_eval_samples_per_second</td><td>▁</td></tr><tr><td>student_eval_steps_per_second</td><td>▁</td></tr><tr><td>teacher_eval_accuracy</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_negative</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_neutral</td><td>▁</td></tr><tr><td>teacher_eval_accuracy_positive</td><td>▁</td></tr><tr><td>teacher_eval_adjacent_accuracy</td><td>▁</td></tr><tr><td>teacher_eval_f1</td><td>▁</td></tr><tr><td>teacher_eval_f1_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_f1_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_f1_negative</td><td>▁</td></tr><tr><td>teacher_eval_f1_neutral</td><td>▁</td></tr><tr><td>teacher_eval_f1_positive</td><td>▁</td></tr><tr><td>teacher_eval_loss</td><td>▁</td></tr><tr><td>teacher_eval_mae</td><td>▁</td></tr><tr><td>teacher_eval_model_preparation_time</td><td>▁</td></tr><tr><td>teacher_eval_precision</td><td>▁</td></tr><tr><td>teacher_eval_precision_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_precision_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_precision_negative</td><td>▁</td></tr><tr><td>teacher_eval_precision_neutral</td><td>▁</td></tr><tr><td>teacher_eval_precision_positive</td><td>▁</td></tr><tr><td>teacher_eval_quadratic_weighted_kappa</td><td>▁</td></tr><tr><td>teacher_eval_recall</td><td>▁</td></tr><tr><td>teacher_eval_recall_extremely_negative</td><td>▁</td></tr><tr><td>teacher_eval_recall_extremely_positive</td><td>▁</td></tr><tr><td>teacher_eval_recall_negative</td><td>▁</td></tr><tr><td>teacher_eval_recall_neutral</td><td>▁</td></tr><tr><td>teacher_eval_recall_positive</td><td>▁</td></tr><tr><td>teacher_eval_runtime</td><td>▁</td></tr><tr><td>teacher_eval_samples_per_second</td><td>▁</td></tr><tr><td>teacher_eval_steps_per_second</td><td>▁</td></tr><tr><td>temperature</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████▁</td></tr><tr><td>train/grad_norm</td><td>▄▆▅▃▄▄▄▃▅▄▄▄▄▃▃▅▄▅▆▄▂▃▃▃▃▂▁█▅▃▃▁▅▄▅▂▃▂▁▃</td></tr><tr><td>train/learning_rate</td><td>▂▃▄▄▅▇███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▆▅▅▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Learning_Rate</td><td>5e-05</td></tr><tr><td>Train Loss</td><td>0.14</td></tr><tr><td>Validation Accuracy</td><td>0.8079</td></tr><tr><td>Validation F1</td><td>0.80585</td></tr><tr><td>Validation Loss</td><td>0.72954</td></tr><tr><td>Validation MAE</td><td>0.22286</td></tr><tr><td>Validation QWK</td><td>0.91403</td></tr><tr><td>alpha</td><td>0.5</td></tr><tr><td>eval/accuracy</td><td>0.81192</td></tr><tr><td>eval/accuracy_extremely_negative</td><td>0.90976</td></tr><tr><td>eval/accuracy_extremely_positive</td><td>0.93878</td></tr><tr><td>eval/accuracy_negative</td><td>0.71341</td></tr><tr><td>eval/accuracy_neutral</td><td>0.87709</td></tr><tr><td>eval/accuracy_positive</td><td>0.73061</td></tr><tr><td>eval/adjacent_accuracy</td><td>0.97109</td></tr><tr><td>eval/f1</td><td>0.80976</td></tr><tr><td>eval/f1_extremely_negative</td><td>0.81352</td></tr><tr><td>eval/f1_extremely_positive</td><td>0.85251</td></tr><tr><td>eval/f1_negative</td><td>0.76821</td></tr><tr><td>eval/f1_neutral</td><td>0.84875</td></tr><tr><td>eval/f1_positive</td><td>0.79025</td></tr><tr><td>eval/loss</td><td>0.71425</td></tr><tr><td>eval/mae</td><td>0.22079</td></tr><tr><td>eval/model_preparation_time</td><td>0.0013</td></tr><tr><td>eval/precision</td><td>0.80626</td></tr><tr><td>eval/precision_extremely_negative</td><td>0.7357</td></tr><tr><td>eval/precision_extremely_positive</td><td>0.78076</td></tr><tr><td>eval/precision_negative</td><td>0.83214</td></tr><tr><td>eval/precision_neutral</td><td>0.82219</td></tr><tr><td>eval/precision_positive</td><td>0.86049</td></tr><tr><td>eval/quadratic_weighted_kappa</td><td>0.91581</td></tr><tr><td>eval/recall</td><td>0.83393</td></tr><tr><td>eval/recall_extremely_negative</td><td>0.90976</td></tr><tr><td>eval/recall_extremely_positive</td><td>0.93878</td></tr><tr><td>eval/recall_negative</td><td>0.71341</td></tr><tr><td>eval/recall_neutral</td><td>0.87709</td></tr><tr><td>eval/recall_positive</td><td>0.73061</td></tr><tr><td>eval/runtime</td><td>12.0524</td></tr><tr><td>eval/samples_per_second</td><td>284.094</td></tr><tr><td>eval/steps_per_second</td><td>4.48</td></tr><tr><td>final_accuracy_retention</td><td>97.37303</td></tr><tr><td>final_compression_ratio</td><td>1.51784</td></tr><tr><td>final_f1_retention</td><td>97.21141</td></tr><tr><td>final_qwk_retention</td><td>99.03143</td></tr><tr><td>final_speedup</td><td>1.77416</td></tr><tr><td>student_eval_accuracy</td><td>0.81192</td></tr><tr><td>student_eval_accuracy_extremely_negative</td><td>0.90976</td></tr><tr><td>student_eval_accuracy_extremely_positive</td><td>0.93878</td></tr><tr><td>student_eval_accuracy_negative</td><td>0.71341</td></tr><tr><td>student_eval_accuracy_neutral</td><td>0.87709</td></tr><tr><td>student_eval_accuracy_positive</td><td>0.73061</td></tr><tr><td>student_eval_adjacent_accuracy</td><td>0.97109</td></tr><tr><td>student_eval_f1</td><td>0.80976</td></tr><tr><td>student_eval_f1_extremely_negative</td><td>0.81352</td></tr><tr><td>student_eval_f1_extremely_positive</td><td>0.85251</td></tr><tr><td>student_eval_f1_negative</td><td>0.76821</td></tr><tr><td>student_eval_f1_neutral</td><td>0.84875</td></tr><tr><td>student_eval_f1_positive</td><td>0.79025</td></tr><tr><td>student_eval_loss</td><td>0.71425</td></tr><tr><td>student_eval_mae</td><td>0.22079</td></tr><tr><td>student_eval_model_preparation_time</td><td>0.0013</td></tr><tr><td>student_eval_precision</td><td>0.80626</td></tr><tr><td>student_eval_precision_extremely_negative</td><td>0.7357</td></tr><tr><td>student_eval_precision_extremely_positive</td><td>0.78076</td></tr><tr><td>student_eval_precision_negative</td><td>0.83214</td></tr><tr><td>student_eval_precision_neutral</td><td>0.82219</td></tr><tr><td>student_eval_precision_positive</td><td>0.86049</td></tr><tr><td>student_eval_quadratic_weighted_kappa</td><td>0.91581</td></tr><tr><td>student_eval_recall</td><td>0.83393</td></tr><tr><td>student_eval_recall_extremely_negative</td><td>0.90976</td></tr><tr><td>student_eval_recall_extremely_positive</td><td>0.93878</td></tr><tr><td>student_eval_recall_negative</td><td>0.71341</td></tr><tr><td>student_eval_recall_neutral</td><td>0.87709</td></tr><tr><td>student_eval_recall_positive</td><td>0.73061</td></tr><tr><td>student_eval_runtime</td><td>12.0524</td></tr><tr><td>student_eval_samples_per_second</td><td>284.094</td></tr><tr><td>student_eval_steps_per_second</td><td>4.48</td></tr><tr><td>teacher_eval_accuracy</td><td>0.83382</td></tr><tr><td>teacher_eval_accuracy_extremely_negative</td><td>0.89756</td></tr><tr><td>teacher_eval_accuracy_extremely_positive</td><td>0.89286</td></tr><tr><td>teacher_eval_accuracy_negative</td><td>0.76015</td></tr><tr><td>teacher_eval_accuracy_neutral</td><td>0.90288</td></tr><tr><td>teacher_eval_accuracy_positive</td><td>0.78512</td></tr><tr><td>teacher_eval_adjacent_accuracy</td><td>0.97605</td></tr><tr><td>teacher_eval_f1</td><td>0.83298</td></tr><tr><td>teacher_eval_f1_extremely_negative</td><td>0.84598</td></tr><tr><td>teacher_eval_f1_extremely_positive</td><td>0.87137</td></tr><tr><td>teacher_eval_f1_negative</td><td>0.80312</td></tr><tr><td>teacher_eval_f1_neutral</td><td>0.83921</td></tr><tr><td>teacher_eval_f1_positive</td><td>0.82489</td></tr><tr><td>teacher_eval_loss</td><td>0.59774</td></tr><tr><td>teacher_eval_mae</td><td>0.19305</td></tr><tr><td>teacher_eval_model_preparation_time</td><td>0.0021</td></tr><tr><td>teacher_eval_precision</td><td>0.83099</td></tr><tr><td>teacher_eval_precision_extremely_negative</td><td>0.8</td></tr><tr><td>teacher_eval_precision_extremely_positive</td><td>0.85089</td></tr><tr><td>teacher_eval_precision_negative</td><td>0.85124</td></tr><tr><td>teacher_eval_precision_neutral</td><td>0.78393</td></tr><tr><td>teacher_eval_precision_positive</td><td>0.86891</td></tr><tr><td>teacher_eval_quadratic_weighted_kappa</td><td>0.92477</td></tr><tr><td>teacher_eval_recall</td><td>0.84771</td></tr><tr><td>teacher_eval_recall_extremely_negative</td><td>0.89756</td></tr><tr><td>teacher_eval_recall_extremely_positive</td><td>0.89286</td></tr><tr><td>teacher_eval_recall_negative</td><td>0.76015</td></tr><tr><td>teacher_eval_recall_neutral</td><td>0.90288</td></tr><tr><td>teacher_eval_recall_positive</td><td>0.78512</td></tr><tr><td>teacher_eval_runtime</td><td>20.0098</td></tr><tr><td>teacher_eval_samples_per_second</td><td>171.116</td></tr><tr><td>teacher_eval_steps_per_second</td><td>2.699</td></tr><tr><td>temperature</td><td>2</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>0</td></tr><tr><td>train/grad_norm</td><td>10.37957</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.14</td></tr><tr><td>train_loss</td><td>0.41229</td></tr><tr><td>train_runtime</td><td>4311.2458</td></tr><tr><td>train_samples_per_second</td><td>57.988</td></tr><tr><td>train_steps_per_second</td><td>1.814</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bertweet-to-distilroberta</strong> at: <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation/runs/e407tgiz</a><br> View project at: <a href='https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation' target=\"_blank\">https://wandb.ai/at-bay-data-science/covid-tweet-sentiment-distillation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250820_004201-e407tgiz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KNOWLEDGE DISTILLATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 MODEL COMPRESSION:\")\n",
    "print(f\"Teacher Model Size: {teacher_size:.2f} MB\")\n",
    "print(f\"Student Model Size: {student_size:.2f} MB\")\n",
    "print(f\"Compression Ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n⚡ INFERENCE SPEED:\")\n",
    "print(f\"Teacher Model: {teacher_time*1000:.2f} ms\")\n",
    "print(f\"Student Model: {student_time*1000:.2f} ms\")\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n",
    "\n",
    "print(f\"\\n🎯 VALIDATION SET PERFORMANCE:\")\n",
    "print(f\"                      Teacher     Student     Difference\")\n",
    "print(f\"Accuracy:             {val_results_teacher['eval_accuracy']:.4f}      {val_results_student['eval_accuracy']:.4f}      {val_results_student['eval_accuracy'] - val_results_teacher['eval_accuracy']:+.4f}\")\n",
    "print(f\"F1-Score:             {val_results_teacher['eval_f1']:.4f}      {val_results_student['eval_f1']:.4f}      {val_results_student['eval_f1'] - val_results_teacher['eval_f1']:+.4f}\")\n",
    "print(f\"QWK:                  {val_results_teacher['eval_quadratic_weighted_kappa']:.4f}      {val_results_student['eval_quadratic_weighted_kappa']:.4f}      {val_results_student['eval_quadratic_weighted_kappa'] - val_results_teacher['eval_quadratic_weighted_kappa']:+.4f}\")\n",
    "print(f\"MAE:                  {val_results_teacher['eval_mae']:.4f}      {val_results_student['eval_mae']:.4f}      {val_results_student['eval_mae'] - val_results_teacher['eval_mae']:+.4f}\")\n",
    "\n",
    "print(f\"\\n🧪 TEST SET PERFORMANCE:\")\n",
    "print(f\"                      Teacher     Student     Difference\")\n",
    "print(f\"Accuracy:             {test_results_teacher['eval_accuracy']:.4f}      {test_results_student['eval_accuracy']:.4f}      {test_results_student['eval_accuracy'] - test_results_teacher['eval_accuracy']:+.4f}\")\n",
    "print(f\"F1-Score:             {test_results_teacher['eval_f1']:.4f}      {test_results_student['eval_f1']:.4f}      {test_results_student['eval_f1'] - test_results_teacher['eval_f1']:+.4f}\")\n",
    "print(f\"QWK:                  {test_results_teacher['eval_quadratic_weighted_kappa']:.4f}      {test_results_student['eval_quadratic_weighted_kappa']:.4f}      {test_results_student['eval_quadratic_weighted_kappa'] - test_results_teacher['eval_quadratic_weighted_kappa']:+.4f}\")\n",
    "print(f\"MAE:                  {test_results_teacher['eval_mae']:.4f}      {test_results_student['eval_mae']:.4f}      {test_results_student['eval_mae'] - test_results_teacher['eval_mae']:+.4f}\")\n",
    "\n",
    "# Calculate performance retention\n",
    "acc_retention = (test_results_student['eval_accuracy'] / test_results_teacher['eval_accuracy']) * 100\n",
    "f1_retention = (test_results_student['eval_f1'] / test_results_teacher['eval_f1']) * 100\n",
    "qwk_retention = (test_results_student['eval_quadratic_weighted_kappa'] / test_results_teacher['eval_quadratic_weighted_kappa']) * 100\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE RETENTION:\")\n",
    "print(f\"Accuracy Retention: {acc_retention:.1f}%\")\n",
    "print(f\"F1-Score Retention: {f1_retention:.1f}%\")\n",
    "print(f\"QWK Retention: {qwk_retention:.1f}%\")\n",
    "\n",
    "print(f\"\\n💡 DISTILLATION SUMMARY:\")\n",
    "print(f\"• Temperature: {TEMPERATURE}\")\n",
    "print(f\"• Alpha (hard loss weight): {ALPHA}\")\n",
    "print(f\"• Achieved {compression_ratio:.1f}x model compression with {speedup:.1f}x inference speedup\")\n",
    "print(f\"• Performance drop: {abs(test_results_student['eval_f1'] - test_results_teacher['eval_f1']):.4f} F1-score points\")\n",
    "print(f\"• Knowledge retention: {f1_retention:.1f}% of teacher's performance\")\n",
    "\n",
    "# Final wandb log with summary metrics\n",
    "wandb.log({\n",
    "    \"final_compression_ratio\": compression_ratio,\n",
    "    \"final_speedup\": speedup,\n",
    "    \"final_f1_retention\": f1_retention,\n",
    "    \"final_accuracy_retention\": acc_retention,\n",
    "    \"final_qwk_retention\": qwk_retention,\n",
    "    \"temperature\": TEMPERATURE,\n",
    "    \"alpha\": ALPHA\n",
    "})\n",
    "\n",
    "print(f\"\\n✅ Knowledge distillation complete! Results logged to W&B.\")\n",
    "\n",
    "# Save the distilled model\n",
    "trainer.save_model(\"./distilled_model_final\")\n",
    "print(f\"✅ Distilled model saved to ./distilled_model_final\")\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
